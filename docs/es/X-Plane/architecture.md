# Descripci√≥n de la Arquitectura

Este documento detalla la arquitectura del sistema, los principios t√©cnicos y la filosof√≠a de dise√±o del proyecto Nav-data.

## üèóÔ∏è Arquitectura General

Nav-data adopta un dise√±o modular, compuesto por cuatro m√≥dulos principales, cada uno de los cuales funciona de forma independiente y se puede combinar de manera flexible.

```mermaid
graph TB
    subgraph "Capa de Fuente de Datos"
        A1[Datos CSV de NAIP]
        A2[Archivos de Procedimientos PDF]
        A3[Datos Nativos de X-Plane]
    end
    
    subgraph "Capa de Procesamiento"
        B1[M√≥dulo de Procesamiento de Aerov√≠as<br/>Airway]
        B2[M√≥dulo de Extracci√≥n de PDF<br/>PDF Extract]
        B3[M√≥dulo de Reparaci√≥n de Terminales<br/>Terminal Patch]
        B4[M√≥dulo de Generaci√≥n CIFP<br/>X-Plane CIFP]
    end
    
    subgraph "Capa de Salida"
        C1[earth_awy.dat]
        C2[Archivos de Base de Datos de Procedimientos]
        C3[Datos de Terminales Reparados]
        C4[Archivos X-Plane CIFP]
    end
    
    subgraph "Capa de Herramientas"
        D1[Validaci√≥n de Datos]
        D2[Conversi√≥n de Formato]
        D3[Procesamiento de Coordenadas]
        D4[Sistema de Registro]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B4
    B2 --> B3
    
    B1 --> C1
    B2 --> C2
    B3 --> C3
    B4 --> C4
    
    B1 -.-> D1
    B2 -.-> D2
    B3 -.-> D3
    B4 -.-> D4
```

## üìã Principios de Dise√±o

### 1. Dise√±o Modular
- **Independencia**: Cada m√≥dulo puede funcionar de forma independiente, sin una fuerte dependencia de otros m√≥dulos.
- **Componibilidad**: Los m√≥dulos se pueden combinar de forma flexible para formar diferentes flujos de procesamiento.
- **Extensibilidad**: Los nuevos m√≥dulos se pueden integrar sin problemas en la arquitectura existente.

### 2. Impulsado por el Flujo de Datos
- **Flujo de datos unidireccional**: Los datos fluyen desde el origen hasta el destino, evitando dependencias circulares.
- **Guardado de estado intermedio**: Cada paso de procesamiento guarda resultados intermedios para facilitar la depuraci√≥n y recuperaci√≥n.
- **Estandarizaci√≥n de formato**: Un formato de datos unificado garantiza la compatibilidad entre m√≥dulos.

### 3. Tolerancia a Fallos y Recuperaci√≥n
- **Procesamiento por pasos**: Las tareas complejas se dividen en pasos m√°s peque√±os para reducir el riesgo de fallos.
- **Aislamiento de errores**: El fallo en el procesamiento de un solo archivo no afecta a toda la tarea de procesamiento por lotes.
- **Guardado de estado**: La informaci√≥n de estado clave se mantiene persistente, lo que permite reanudar el procesamiento desde el √∫ltimo punto.

### 4. Optimizaci√≥n del Rendimiento
- **Uso eficiente de la memoria**: Procesamiento de archivos grandes mediante streaming para evitar el desbordamiento de memoria.
- **Operaciones por lotes**: El procesamiento por lotes mejora la eficiencia de E/S.
- **Soporte de concurrencia**: Admite procesamiento concurrente multihilo/multiproceso.

## üõ†Ô∏è Arquitectura de M√≥dulos Centrales

### M√≥dulo de Procesamiento de Aerov√≠as (Airway)

```mermaid
graph TD
    A[Entrada CSV] --> B{Validaci√≥n de Datos}
    B -->|Validaci√≥n Aprobada| C[An√°lisis de Campos CSV]
    B -->|Validaci√≥n Fallida| X[Manejo de Errores]
    
    C --> D[Carga de Datos de Referencia]
    D --> E[earth_fix.dat]
    D --> F[earth_nav.dat]
    
    E --> G[Coincidencia de Puntos de Navegaci√≥n]
    F --> G
    C --> G
    
    G --> H{Filtrado por √Årea}
    H -->|Espacio A√©reo Chino| I[Generaci√≥n de Segmentos de Aerov√≠a]
    H -->|Otras Regiones| J[Omitir Procesamiento]
    
    I --> K[Conversi√≥n de Formato]
    K --> L[Formato X-Plane DAT]
    L --> M[Salida Unificada]
    M --> N[earth_awy.dat]
```

**Caracter√≠sticas T√©cnicas:**
- **Algoritmo de coincidencia de datos**: Coincidencia inteligente basada en identificadores y coordenadas.
- **Mecanismo de filtrado por √°rea**: Admite una configuraci√≥n flexible de filtrado por √°rea geogr√°fica.
- **Motor de conversi√≥n de formato**: Conversi√≥n precisa de CSV a formato X-Plane DAT.
- **Gesti√≥n del ciclo AIRAC**: C√°lculo y gesti√≥n autom√°tica de los ciclos de validez de los datos aeron√°uticos.

**Clases e Interfaces Principales:**
```python
class NavigationType(Enum):
    """Enumeraci√≥n de tipos de puntos de navegaci√≥n"""
    DESIGNATED_POINT = ('DESIGNATED_POINT', '11')
    VORDME = ('VORDME', '3') 
    NDB = ('NDB', '2')

@dataclass
class NavigationPoint:
    """Estructura de datos para puntos de navegaci√≥n"""
    identifier: str
    type: NavigationType
    area_code: str

def process_navigation_point(identifier: str, code_type: str, 
                           earth_fix_data: Dict, earth_nav_data: Dict) -> Optional[NavigationPoint]:
    """Algoritmo central de procesamiento de puntos de navegaci√≥n"""
    pass

def convert_csv_to_dat(csv_file: str, earth_fix_path: str, 
                      earth_nav_path: str, earth_awy_path: str) -> None:
    """Funci√≥n principal de conversi√≥n"""
    pass
```

### M√≥dulo de Extracci√≥n de PDF (PDF Extract)

```mermaid
graph TD
    A[Entrada PDF] --> B[Motor de An√°lisis de PDF]
    B --> C{Tipo de Contenido}
    
    C -->|Datos de Procedimientos| D[Extracci√≥n de Procedimientos de Terminal]
    C -->|Datos de Coordenadas| E[Extracci√≥n de Puntos de Ruta]
    
    D --> F[An√°lisis de Estructura de Texto]
    F --> G[Identificaci√≥n de Secciones de Procedimiento]
    G --> H[Estandarizaci√≥n de Formato]
    H --> I[Salida de Datos de Procedimientos]
    
    E --> J[Reconocimiento de Formato de Coordenadas]
    J --> K[Conversi√≥n de Grados, Minutos, Segundos]
    K --> L[Manejo de Precisi√≥n]
    L --> M[Salida de Datos de Coordenadas]
    
    I --> N[Validaci√≥n de Datos]
    M --> N
    N --> O[Informe de Calidad]
```

**Caracter√≠sticas T√©cnicas:**
- **An√°lisis multinivel**: Admite varios elementos PDF como texto, l√≠neas y tablas.
- **Reconocimiento inteligente**: Identificaci√≥n autom√°tica de formatos de coordenadas y estructuras de procedimientos.
- **Mecanismo de tolerancia a fallos**: Manejo de inconsistencias en el formato PDF y problemas de datos faltantes.
- **Control de calidad**: Mecanismos integrados de verificaci√≥n y generaci√≥n de informes de calidad de datos.

**Componentes Principales:**
```python
class Line:
    """Clase de elemento de l√≠nea"""
    def __init__(self, line: dict):
        self.is_horizontal = True if line["width"] > 5 else False
        self.top = line["top"]
        self.left = line["x0"]
        self.length = line["width"] if self.is_horizontal else line["height"]

class Word:
    """Clase de elemento de texto"""
    def __init__(self, info: dict):
        self.content = info["text"]
        self.center = ((info["x0"] + info["x1"]) / 2, (info["top"] + info["bottom"]) / 2)

class Unit:
    """Clase de unidad de procesamiento"""
    def __init__(self):
        self.words = []
        self.lines = []
    
    def match_underline(self):
        """Algoritmo de coincidencia de subrayado"""
        pass

def extract(pdf: pdfplumber.PDF) -> List[str]:
    """Funci√≥n principal de extracci√≥n de PDF"""
    pass
```

### M√≥dulo de Reparaci√≥n de Terminales (Terminal Patch)

```mermaid
graph TD
    A[Entrada Tdatabase] --> B[Verificaci√≥n de Formato]
    B --> C{Tipo de Codificaci√≥n}
    
    C -->|Necesita Codificaci√≥n| D[Codificador de Terminales]
    C -->|Necesita Reparaci√≥n| E[Reparador de Formato]
    
    D --> F[Identificaci√≥n de Puntos IF]
    F --> G[Marcado de Segmentos de Transici√≥n]
    G --> H[Codificaci√≥n de Procedimientos]
    H --> I[Salida Codificada]
    
    E --> J[Coincidencia de Reglas]
    J --> K{Reglas de Reparaci√≥n}
    K -->|APPCH GY M| L[Reparaci√≥n de Aproximaci√≥n]
    K -->|Regla de Solo Letras| M[Reparaci√≥n de Identificador]
    K -->|Regla SID RW| N[Reparaci√≥n de Salida]
    
    L --> O[Salida Reparada]
    M --> O
    N --> O
    
    I --> P[Validaci√≥n de Calidad]
    O --> P
    P --> Q[Salida Final]
```

**Caracter√≠sticas T√©cnicas:**
- **Motor de reglas**: Motor de reglas de reparaci√≥n basado en configuraci√≥n.
- **Reconocimiento de patrones**: Identificaci√≥n inteligente de diferentes tipos de procedimientos e identificadores.
- **Procesamiento por lotes**: Admite la reparaci√≥n por lotes a nivel de carpeta.
- **Compatibilidad con versiones anteriores**: Mantiene la compatibilidad con los formatos de datos existentes.

**Sistema de Reglas de Reparaci√≥n:**
```python
class FixRule:
    """Clase base para reglas de reparaci√≥n"""
    def __init__(self, name: str, pattern: str, action: callable):
        self.name = name
        self.pattern = pattern
        self.action = action
    
    def apply(self, line: str) -> str:
        """Aplica la regla de reparaci√≥n"""
        pass

class RuleEngine:
    """Motor de reglas"""
    def __init__(self):
        self.rules = []
    
    def add_rule(self, rule: FixRule):
        """Agrega una regla de reparaci√≥n"""
        self.rules.append(rule)
    
    def apply_rules(self, content: str) -> str:
        """Aplica todas las reglas"""
        pass

# Reglas de reparaci√≥n predefinidas
APPCH_GY_M_RULE = FixRule(
    name="APPCH_GY_M",
    pattern=r"APPCH.*GY M",
    action=lambda line: fix_appch_gy_m(line)
)
```

### M√≥dulo X-Plane CIFP (X-Plane CIFP)

```mermaid
graph TD
    A[Entrada Multifuente] --> B{Tipo de Datos}
    B -->|Equipo de Navegaci√≥n| C[Procesador NavAid]
    B -->|Puntos de Ruta| D[Procesador Waypoint]
    B -->|Procedimientos de Terminal| E[Procesador Terminal]
    
    C --> F[Conversi√≥n VOR/NDB]
    F --> G[Procesamiento de Frecuencia]
    G --> H[Conversi√≥n de Coordenadas]
    H --> I[Salida NavAid]
    
    D --> J[Base de Datos de Puntos de Ruta]
    J --> K[Procesamiento de Deduplicaci√≥n]
    K --> L[Codificaci√≥n de √Årea]
    L --> M[Salida Waypoint]
    
    E --> N[An√°lisis de Procedimientos]
    N --> O[SID/STAR/APPCH]
    O --> P[Codificaci√≥n de Segmentos]
    P --> Q[Generaci√≥n de Informaci√≥n de Pista]
    Q --> R[Salida CIFP]
    
    I --> S[Integraci√≥n de Datos]
    M --> S
    R --> S
    S --> T[Verificaci√≥n de Compatibilidad con X-Plane]
    T --> U[Archivo CIFP Final]
```

**Caracter√≠sticas T√©cnicas:**
- **Integraci√≥n de datos de m√∫ltiples fuentes**: Integra m√∫ltiples fuentes de datos como NAIP y datos nativos de X-Plane.
- **Deduplicaci√≥n inteligente**: Algoritmo de deduplicaci√≥n inteligente basado en coordenadas e identificadores.
- **Compatibilidad de versiones**: Admite formatos de X-Plane 11 y X-Plane 12.
- **Integridad de datos**: Asegura que los datos CIFP generados sean completos y cumplan con los est√°ndares.

**Estructuras de Datos Principales:**
```python
class Waypoint:
    """Clase de punto de ruta"""
    def __init__(self, la: float, long: float, ident: str, cat: int, 
                 airport: str = '', area: str = '', changeable: bool = True):
        self.latitude = la
        self.longitude = long
        self.ident = ident
        self.cat = cat  # -1:No disponible 1:Punto de ruta 2:VHF 3:NDB
        self.airport = airport
        self.area = area
        self.changeable = changeable
    
    def is_same(self, fix: "Waypoint", change: bool = False) -> bool:
        """Determina si es el mismo punto de ruta"""
        pass

class WaypointSystem:
    """Sistema de gesti√≥n de puntos de ruta"""
    def __init__(self):
        self.base = {}  # Base de datos principal
    
    def add_point(self, point: Waypoint):
        """Agrega un punto de ruta"""
        pass
    
    def query(self, point: Waypoint, change: bool = False) -> int:
        """Consulta un punto de ruta"""
        pass

class Procedure:
    """Clase de procedimiento"""
    def __init__(self, ptype: int):
        self.ptype = "SID" if ptype == 1 else ("STAR" if ptype == 2 else "APPCH")
        self.airport = None
        self.runway = None
        self.name = None
        self.legs = []
    
    def encode(self):
        """Codifica el procedimiento"""
        pass
    
    def output(self) -> str:
        """Genera la salida en formato CIFP"""
        pass
```

## üîÑ Arquitectura del Flujo de Datos

### Diagrama de Flujo de Datos

```mermaid
flowchart LR
    subgraph "Datos Fuente"
        A1[NAIP CSV]
        A2[Archivos PDF]
        A3[Datos X-Plane]
    end
    
    subgraph "Preprocesamiento"
        B1[An√°lisis CSV]
        B2[Extracci√≥n PDF]
        B3[Carga de Datos]
    end
    
    subgraph "Procesamiento Central"
        C1[Conversi√≥n de Aerov√≠as]
        C2[Estandarizaci√≥n de Procedimientos]
        C3[Reparaci√≥n de Formato]
        C4[Generaci√≥n CIFP]
    end
    
    subgraph "Postprocesamiento"
        D1[Validaci√≥n de Datos]
        D2[Verificaci√≥n de Formato]
        D3[Control de Calidad]
    end
    
    subgraph "Salida"
        E1[Archivos DAT]
        E2[Archivos de Base de Datos]
        E3[Archivos CIFP]
    end
    
    A1 --> B1 --> C1 --> D1 --> E1
    A2 --> B2 --> C2 --> D2 --> E2
    A3 --> B3 --> C4 --> D3 --> E3
    C2 --> C3 --> D2
```

### Cadena de Conversi√≥n de Formato de Datos

```mermaid
graph TD
    A[PDF Original] -->|pdfplumber| B[Texto Estructurado]
    B -->|Analizador| C[P√°rrafos de Procedimiento]
    C -->|Codificador| D[Procedimiento Estandarizado]
    D -->|Reparador| E[Formato Compatible con CIFP]
    
    F[NAIP CSV] -->|pandas| G[Tabla de Datos]
    G -->|Validador| H[Registros V√°lidos]
    H -->|Convertidor| I[X-Plane DAT]
    
    J[X-Plane Nativo] -->|Cargador| K[Datos de Referencia]
    K -->|Coincidencia| L[Informaci√≥n Asociada]
    L -->|Integrador| M[Conjunto de Datos Completo]
```

## ‚öôÔ∏è Arquitectura de la Pila Tecnol√≥gica

### Componentes Tecnol√≥gicos Clave

```mermaid
graph TB
    subgraph "Lenguaje de Programaci√≥n"
        A1[Python 3.6+]
    end
    
    subgraph "Procesamiento de Datos"
        B1[pandas - An√°lisis de Datos]
        B2[numpy - C√°lculo Num√©rico]
        B3[csv - Procesamiento CSV]
    end
    
    subgraph "Procesamiento de PDF"
        C1[pdfplumber - An√°lisis de PDF]
        C2[Expresiones Regulares - Coincidencia de Patrones]
    end
    
    subgraph "C√°lculo Geogr√°fico"
        D1[geopy - C√°lculo de Distancia Geogr√°fica]
        D2[Algoritmos de Conversi√≥n de Coordenadas]
    end
    
    subgraph "Interfaz de Usuario"
        E1[tqdm - Barra de Progreso]
        E2[colorama - Salida en Color]
        E3[logging - Sistema de Registro]
    end
    
    subgraph "Base de Datos"
        F1[sqlite3 - Base de Datos Ligera]
        F2[Sistema de Archivos - Persistencia de Datos]
    end
    
    A1 --> B1
    A1 --> B2
    A1 --> C1
    A1 --> D1
    A1 --> E1
    A1 --> F1
```

### Gesti√≥n de Dependencias

```python
# Niveles de dependencia en requirements.txt
# Dependencias principales
pandas>=1.3.0          # Base para el procesamiento de datos
numpy>=1.21.0          # Base para c√°lculos num√©ricos

# Procesamiento de PDF
pdfplumber>=0.7.0      # Motor de an√°lisis de PDF

# Experiencia de usuario
tqdm>=4.60.0           # Visualizaci√≥n de progreso
colorama>=0.4.4        # Salida en color

# C√°lculos geogr√°ficos
geopy>=2.2.0           # C√°lculo de distancia geogr√°fica

# Procesamiento de chino
pypinyin>=0.44.0       # Conversi√≥n de pinyin chino

# Herramientas de desarrollo (opcional)
pytest>=6.0.0          # Framework de pruebas
black>=21.0.0          # Formateador de c√≥digo
flake8>=3.9.0          # Linter de c√≥digo
```

## üèõÔ∏è Patrones de Dise√±o

### 1. Patr√≥n Factory (Factory Pattern)
Utilizado para crear diferentes tipos de procesadores de datos:

```python
class ProcessorFactory:
    """F√°brica de procesadores de datos"""
    
    @staticmethod
    def create_processor(data_type: str):
        if data_type == "airway":
            return AirwayProcessor()
        elif data_type == "pdf":
            return PDFProcessor()
        elif data_type == "terminal":
            return TerminalProcessor()
        elif data_type == "cifp":
            return CIFPProcessor()
        else:
            raise ValueError(f"Unknown processor type: {data_type}")

# Ejemplo de uso
processor = ProcessorFactory.create_processor("airway")
result = processor.process(input_data)
```

### 2. Patr√≥n Strategy (Strategy Pattern)
Utilizado para implementar diferentes estrategias de conversi√≥n de datos:

```python
class ConversionStrategy:
    """Interfaz de estrategia de conversi√≥n"""
    def convert(self, data): pass

class CSVToDAT(ConversionStrategy):
    """Estrategia de conversi√≥n de CSV a DAT"""
    def convert(self, csv_data):
        # L√≥gica de conversi√≥n CSV
        pass

class PDFToText(ConversionStrategy):
    """Estrategia de conversi√≥n de PDF a texto"""
    def convert(self, pdf_data):
        # L√≥gica de conversi√≥n PDF
        pass

class DataConverter:
    """Convertidor de datos"""
    def __init__(self, strategy: ConversionStrategy):
        self.strategy = strategy
    
    def convert(self, data):
        return self.strategy.convert(data)
```

### 3. Patr√≥n Observer (Observer Pattern)
Utilizado para implementar el monitoreo del progreso del procesamiento:

```python
class ProgressObserver:
    """Interfaz de observador de progreso"""
    def update(self, progress: float, message: str): pass

class ConsoleProgressObserver(ProgressObserver):
    """Visualizaci√≥n del progreso en la consola"""
    def update(self, progress: float, message: str):
        print(f"Progress: {progress:.1%} - {message}")

class TqdmProgressObserver(ProgressObserver):
    """Visualizaci√≥n de barra de progreso tqdm"""
    def __init__(self):
        self.pbar = None
    
    def update(self, progress: float, message: str):
        if self.pbar:
            self.pbar.set_description(message)
            self.pbar.update()

class DataProcessor:
    """Clase base del procesador de datos"""
    def __init__(self):
        self.observers = []
    
    def add_observer(self, observer: ProgressObserver):
        self.observers.append(observer)
    
    def notify_progress(self, progress: float, message: str):
        for observer in self.observers:
            observer.update(progress, message)
```

### 4. Patr√≥n Chain of Responsibility (Chain of Responsibility)
Utilizado para implementar la cadena de validaci√≥n de datos:

```python
class ValidationHandler:
    """Interfaz de manejador de validaci√≥n"""
    def __init__(self):
        self.next_handler = None
    
    def set_next(self, handler):
        self.next_handler = handler
        return handler
    
    def handle(self, data):
        result = self.validate(data)
        if result and self.next_handler:
            return self.next_handler.handle(data)
        return result
    
    def validate(self, data):
        pass

class FormatValidator(ValidationHandler):
    """Validador de formato"""
    def validate(self, data):
        # L√≥gica de validaci√≥n de formato
        return True

class RangeValidator(ValidationHandler):
    """Validador de rango"""
    def validate(self, data):
        # L√≥gica de validaci√≥n de rango
        return True

class IntegrityValidator(ValidationHandler):
    """Validador de integridad"""
    def validate(self, data):
        # L√≥gica de validaci√≥n de integridad
        return True

# Construir la cadena de validaci√≥n
format_validator = FormatValidator()
range_validator = RangeValidator()
integrity_validator = IntegrityValidator()

format_validator.set_next(range_validator).set_next(integrity_validator)

# Usar la cadena de validaci√≥n
is_valid = format_validator.handle(input_data)
```

## üìä Arquitectura de Rendimiento

### Estrategias de Gesti√≥n de Memoria

```mermaid
graph TD
    A[Entrada de Archivos Grandes] --> B{Tama√±o del Archivo}
    B -->|Menor que el Umbral| C[Carga Directa]
    B -->|Excede el Umbral| D[Procesamiento por Streaming]
    
    C --> E[Procesamiento en Memoria]
    D --> F[Lectura por Bloques]
    F --> G[Procesamiento por Lotes]
    G --> H[Salida Incremental]
    
    E --> I[Recolecci√≥n de Basura]
    H --> I
    I --> J[Liberaci√≥n de Memoria]
```

**Estrategias de Optimizaci√≥n de Memoria:**
```python
import gc
from typing import Iterator, List

class MemoryEfficientProcessor:
    """Procesador de datos eficiente en memoria"""
    
    def __init__(self, chunk_size: int = 1000):
        self.chunk_size = chunk_size
    
    def process_large_file(self, file_path: str) -> Iterator[List]:
        """Procesa archivos grandes en bloques"""
        chunk = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                chunk.append(line.strip())
                
                if len(chunk) >= self.chunk_size:
                    yield self.process_chunk(chunk)
                    chunk.clear()
                    gc.collect()  # Recolecci√≥n de basura forzada
            
            if chunk:  # Procesa los datos restantes
                yield self.process_chunk(chunk)
    
    def process_chunk(self, chunk: List[str]) -> List[str]:
        """Procesa un solo bloque de datos"""
        # L√≥gica de procesamiento de datos
        return [self.process_line(line) for line in chunk]
    
    def process_line(self, line: str) -> str:
        """Procesa una sola l√≠nea de datos"""
        # L√≥gica de procesamiento espec√≠fica
        return line
```

### Arquitectura de Procesamiento Concurrente

```python
import concurrent.futures
from multiprocessing import Pool
import threading

class ConcurrentProcessor:
    """Procesador de datos concurrente"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
    
    def process_files_threaded(self, file_list: List[str]) -> List:
        """Procesa una lista de archivos usando m√∫ltiples hilos"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Enviar tareas
            future_to_file = {
                executor.submit(self.process_single_file, file): file 
                for file in file_list
            }
            
            results = []
            for future in concurrent.futures.as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as exc:
                    print(f'File {file} generated an exception: {exc}')
            
            return results
    
    def process_files_multiprocess(self, file_list: List[str]) -> List:
        """Procesa una lista de archivos usando m√∫ltiples procesos"""
        with Pool(processes=self.max_workers) as pool:
            results = pool.map(self.process_single_file, file_list)
        return results
    
    def process_single_file(self, file_path: str):
        """Procesa un solo archivo"""
        # L√≥gica de procesamiento de archivos
        pass
```

### Arquitectura de Cach√©

```python
import functools
import hashlib
import pickle
from pathlib import Path

class CacheManager:
    """Administrador de cach√©"""
    
    def __init__(self, cache_dir: str = "cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, *args, **kwargs) -> str:
        """Genera una clave de cach√©"""
        content = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(content.encode()).hexdigest()
    
    def get(self, key: str):
        """Obtiene un elemento de la cach√©"""
        cache_file = self.cache_dir / f"{key}.cache"
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def set(self, key: str, value):
        """Establece un elemento en la cach√©"""
        cache_file = self.cache_dir / f"{key}.cache"
        with open(cache_file, 'wb') as f:
            pickle.dump(value, f)
    
    def cached(self, ttl: int = 3600):
        """Decorador de cach√©"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                cache_key = self.get_cache_key(func.__name__, *args, **kwargs)
                result = self.get(cache_key)
                
                if result is None:
                    result = func(*args, **kwargs)
                    self.set(cache_key, result)
                
                return result
            return wrapper
        return decorator

# Ejemplo de uso
cache_manager = CacheManager()

@cache_manager.cached(ttl=3600)
def expensive_processing(data):
    """Funci√≥n de procesamiento de datos costosa"""
    # L√≥gica de procesamiento compleja
    return processed_data
```

## üîí Arquitectura de Seguridad

### Capa de Validaci√≥n de Entrada

```python
import re
from pathlib import Path
from typing import Any, Dict

class InputValidator:
    """Validador de entrada"""
    
    # Extensiones de archivo seguras
    SAFE_EXTENSIONS = {'.csv', '.dat', '.txt', '.pdf'}
    
    # Patr√≥n de restricci√≥n de ruta
    SAFE_PATH_PATTERN = re.compile(r'^[a-zA-Z0-9._/\-\s]+$')
    
    @classmethod
    def validate_file_path(cls, file_path: str) -> bool:
        """Valida la seguridad de la ruta de un archivo"""
        path = Path(file_path)
        
        # Verifica la extensi√≥n del archivo
        if path.suffix.lower() not in cls.SAFE_EXTENSIONS:
            raise ValueError(f"Unsafe file extension: {path.suffix}")
        
        # Verifica los caracteres de la ruta
        if not cls.SAFE_PATH_PATTERN.match(file_path):
            raise ValueError(f"Unsafe characters in path: {file_path}")
        
        # Verifica ataques de Path Traversal
        if '..' in file_path or file_path.startswith('/'):
            raise ValueError(f"Path traversal detected: {file_path}")
        
        return True
    
    @classmethod
    def validate_coordinate(cls, lat: float, lon: float) -> bool:
        """Valida el rango de las coordenadas"""
        if not (-90 <= lat <= 90):
            raise ValueError(f"Invalid latitude: {lat}")
        
        if not (-180 <= lon <= 180):
            raise ValueError(f"Invalid longitude: {lon}")
        
        return True
    
    @classmethod
    def sanitize_string(cls, input_str: str) -> str:
        """Limpia la cadena de entrada"""
        # Elimina caracteres potencialmente peligrosos
        sanitized = re.sub(r'[<>"\';\\]', '', input_str)
        # Limita la longitud
        return sanitized[:1000]
```

### Arquitectura de Gesti√≥n de Errores

```python
import logging
from enum import Enum
from typing import Optional

class ErrorLevel(Enum):
    """Nivel de error"""
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class NavDataError(Exception):
    """Clase base de excepci√≥n personalizada de Nav-data"""
    def __init__(self, message: str, error_code: str = None, level: ErrorLevel = ErrorLevel.ERROR):
        super().__init__(message)
        self.message = message
        self.error_code = error_code
        self.level = level

class FileProcessingError(NavDataError):
    """Excepci√≥n de procesamiento de archivo"""
    pass

class DataValidationError(NavDataError):
    """Excepci√≥n de validaci√≥n de datos"""
    pass

class ErrorHandler:
    """Manejador de errores"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def handle_error(self, error: Exception, context: Optional[Dict] = None):
        """Maneja una excepci√≥n"""
        if isinstance(error, NavDataError):
            self.handle_nav_data_error(error, context)
        else:
            self.handle_unexpected_error(error, context)
    
    def handle_nav_data_error(self, error: NavDataError, context: Optional[Dict] = None):
        """Maneja excepciones personalizadas"""
        log_message = f"[{error.error_code}] {error.message}"
        if context:
            log_message += f" Context: {context}"
        
        if error.level == ErrorLevel.WARNING:
            self.logger.warning(log_message)
        elif error.level == ErrorLevel.ERROR:
            self.logger.error(log_message)
        elif error.level == ErrorLevel.CRITICAL:
            self.logger.critical(log_message)
            # Puede que sea necesario detener la ejecuci√≥n del programa
    
    def handle_unexpected_error(self, error: Exception, context: Optional[Dict] = None):
        """Maneja excepciones inesperadas"""
        log_message = f"Unexpected error: {str(error)}"
        if context:
            log_message += f" Context: {context}"
        
        self.logger.error(log_message, exc_info=True)
```

## üß™ Arquitectura de Pruebas

### Estrategia de Pruebas

```mermaid
graph TD
    A[Pir√°mide de Pruebas] --> B[Pruebas Unitarias]
    A --> C[Pruebas de Integraci√≥n]
    A --> D[Pruebas End-to-End]
    
    B --> B1[Pruebas de Funci√≥n]
    B --> B2[Pruebas de Clase]
    B --> B3[Pruebas de M√≥dulo]
    
    C --> C1[Interacci√≥n entre M√≥dulos]
    C --> C2[Pruebas de Flujo de Datos]
    C --> C3[Pruebas de API]
    
    D --> D1[Pruebas de Proceso Completo]
    D --> D2[Pruebas de Escenario de Usuario]
    D --> D3[Pruebas de Rendimiento]
```

### C√≥digo del Framework de Pruebas

```python
import pytest
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch

class TestDataFixtures:
    """Dispositivos de datos de prueba"""
    
    @pytest.fixture
    def sample_csv_data(self):
        """Datos CSV de ejemplo"""
        return """CODE_POINT_START,CODE_TYPE_START,CODE_POINT_END,CODE_TYPE_END,CODE_DIR,TXT_DESIG
ABCDE,DESIGNATED_POINT,FGHIJ,VOR/DME,N,A123
KLMNO,NDB,PQRST,DESIGNATED_POINT,N,B456"""
    
    @pytest.fixture
    def temp_directory(self):
        """Directorio temporal"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield Path(temp_dir)
    
    @pytest.fixture
    def mock_earth_fix_data(self):
        """Datos simulados de earth_fix"""
        return {
            'ABCDE': 'ZB',
            'PQRST': 'ZG'
        }
    
    @pytest.fixture
    def mock_earth_nav_data(self):
        """Datos simulados de earth_nav"""
        return {
            'FGHIJ': 'ZG',
            'KLMNO': 'ZB'
        }

class TestAirwayModule(TestDataFixtures):
    """Pruebas del m√≥dulo Airway"""
    
    def test_navigation_type_enum(self):
        """Prueba la enumeraci√≥n de tipo de navegaci√≥n"""
        from Airway.airway import NavigationType
        
        assert NavigationType.DESIGNATED_POINT.type_code == '11'
        assert NavigationType.VORDME.type_code == '3'
        assert NavigationType.NDB.type_code == '2'
    
    def test_process_navigation_point(self, mock_earth_fix_data, mock_earth_nav_data):
        """Prueba el procesamiento de puntos de navegaci√≥n"""
        from Airway.airway import process_navigation_point
        
        # Prueba el procesamiento de un punto designado
        result = process_navigation_point(
            'ABCDE', 'DESIGNATED_POINT', 
            mock_earth_fix_data, mock_earth_nav_data
        )
        
        assert result is not None
        assert result.identifier == 'ABCDE'
        assert result.area_code == 'ZB'
    
    @patch('Airway.airway.load_fixed_width_data')
    @patch('pandas.read_csv')
    def test_csv_to_dat_conversion(self, mock_read_csv, mock_load_data, 
                                 sample_csv_data, temp_directory):
        """Prueba la conversi√≥n de CSV a DAT"""
        # Configura datos simulados
        mock_df = Mock()
        mock_read_csv.return_value = mock_df
        mock_load_data.return_value = {'ABCDE': 'ZB'}
        
        # Crea archivo temporal
        csv_file = temp_directory / "test.csv"
        csv_file.write_text(sample_csv_data)
        
        # Prueba la funci√≥n de conversi√≥n
        from Airway.airway import convert_csv_to_dat
        
        # Aqu√≠ es necesario ajustar seg√∫n la firma de la funci√≥n real
        # convert_csv_to_dat(str(csv_file), ...)
        
        # Verifica el resultado
        assert True  # Afirmar seg√∫n el resultado real

class TestPDFModule(TestDataFixtures):
    """Pruebas del m√≥dulo PDF"""
    
    @patch('pdfplumber.open')
    def test_pdf_extraction(self, mock_pdf_open):
        """Prueba la funci√≥n de extracci√≥n de PDF"""
        # Configura un PDF simulado
        mock_pdf = Mock()
        mock_page = Mock()
        mock_page.extract_text_lines.return_value = [
            {'text': 'ZBAA N39¬∞48\'35.6" E116¬∞34\'46.7"'}
        ]
        mock_pdf.pages = [mock_page]
        mock_pdf_open.return_value.__enter__.return_value = mock_pdf
        
        # Prueba la funci√≥n de extracci√≥n
        import sys
        sys.path.append('PDF extract')
        from waypoint_1_pdf import extract
        
        result = extract(mock_pdf)
        assert len(result) > 0
```

## üìà Arquitectura de Monitoreo y Registro

### Dise√±o del Sistema de Registro

```python
import logging
import logging.handlers
from enum import Enum
from pathlib import Path

class LogLevel(Enum):
    """Nivel de registro"""
    DEBUG = logging.DEBUG
    INFO = logging.INFO
    WARNING = logging.WARNING
    ERROR = logging.ERROR
    CRITICAL = logging.CRITICAL

class StructuredLogger:
    """Registrador estructurado"""
    
    def __init__(self, name: str, log_dir: str = "logs"):
        self.logger = logging.getLogger(name)
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.setup_handlers()
    
    def setup_handlers(self):
        """Configura los manejadores de registro"""
        # Manejador de consola
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        
        # Manejador de archivo (rotaci√≥n por fecha)
        file_handler = logging.handlers.TimedRotatingFileHandler(
            filename=self.log_dir / 'nav-data.log',
            when='midnight',
            interval=1,
            backupCount=30,
            encoding='utf-8'
        )
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # Manejador de archivo de errores
        error_handler = logging.FileHandler(
            filename=self.log_dir / 'errors.log',
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(file_formatter)
        
        # Agrega los manejadores
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(error_handler)
        
        self.logger.setLevel(logging.INFO)
    
    def log_with_context(self, level: LogLevel, message: str, **context):
        """Registra mensajes con contexto"""
        if context:
            message = f"{message} | Context: {context}"
        
        self.logger.log(level.value, message)
    
    def log_performance(self, operation: str, duration: float, **metrics):
        """Registra el rendimiento"""
        perf_message = f"Performance | Operation: {operation} | Duration: {duration:.3f}s"
        if metrics:
            perf_message += f" | Metrics: {metrics}"
        
        self.logger.info(perf_message)
```

### Monitoreo de Rendimiento

```python
import time
import psutil
from contextlib import contextmanager
from typing import Dict, Any

class PerformanceMonitor:
    """Monitor de rendimiento"""
    
    def __init__(self, logger: StructuredLogger):
        self.logger = logger
        self.metrics = {}
    
    @contextmanager
    def measure_time(self, operation_name: str):
        """Mide el tiempo de una operaci√≥n"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            duration = end_time - start_time
            memory_delta = end_memory - start_memory
            
            self.logger.log_performance(
                operation=operation_name,
                duration=duration,
                memory_start=start_memory,
                memory_end=end_memory,
                memory_delta=memory_delta
            )
    
    def collect_system_metrics(self) -> Dict[str, Any]:
        """Recopila m√©tricas del sistema"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'process_memory': psutil.Process().memory_info().rss / 1024 / 1024
        }

# Ejemplo de uso
logger = StructuredLogger("nav-data")
monitor = PerformanceMonitor(logger)

with monitor.measure_time("csv_processing"):
    # Ejecutar operaci√≥n de procesamiento CSV
    process_csv_file("large_file.csv")

# Registrar m√©tricas del sistema
system_metrics = monitor.collect_system_metrics()
logger.log_with_context(LogLevel.INFO, "System metrics collected", **system_metrics)
```

## üîÆ Arquitectura de Extensibilidad

### Dise√±o del Sistema de Plugins

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import importlib
import os

class Plugin(ABC):
    """Interfaz de plugin"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Nombre del plugin"""
        pass
    
    @property
    @abstractmethod
    def version(self) -> str:
        """Versi√≥n del plugin"""
        pass
    
    @abstractmethod
    def initialize(self, config: Dict[str, Any]):
        """Inicializa el plugin"""
        pass
    
    @abstractmethod
    def process(self, data: Any) -> Any:
        """Procesa datos"""
        pass
    
    @abstractmethod
    def cleanup(self):
        """Libera recursos"""
        pass

class PluginManager:
    """Administrador de plugins"""
    
    def __init__(self, plugin_dir: str = "plugins"):
        self.plugin_dir = plugin_dir
        self.plugins: Dict[str, Plugin] = {}
    
    def load_plugins(self):
        """Carga todos los plugins"""
        if not os.path.exists(self.plugin_dir):
            return
        
        for filename in os.listdir(self.plugin_dir):
            if filename.endswith('.py') and not filename.startswith('__'):
                module_name = filename[:-3]
                try:
                    module = importlib.import_module(f"{self.plugin_dir}.{module_name}")
                    plugin_class = getattr(module, 'Plugin', None)
                    
                    if plugin_class and issubclass(plugin_class, Plugin):
                        plugin = plugin_class()
                        self.plugins[plugin.name] = plugin
                        print(f"Loaded plugin: {plugin.name} v{plugin.version}")
                
                except Exception as e:
                    print(f"Failed to load plugin {module_name}: {e}")
    
    def get_plugin(self, name: str) -> Plugin:
        """Obtiene un plugin"""
        return self.plugins.get(name)
    
    def list_plugins(self) -> List[str]:
        """Lista todos los plugins"""
        return list(self.plugins.keys())
    
    def execute_plugin(self, name: str, data: Any, config: Dict[str, Any] = None) -> Any:
        """Ejecuta un plugin"""
        plugin = self.get_plugin(name)
        if not plugin:
            raise ValueError(f"Plugin not found: {name}")
        
        try:
            if config:
                plugin.initialize(config)
            
            result = plugin.process(data)
            plugin.cleanup()
            return result
        
        except Exception as e:
            plugin.cleanup()
            raise e

# Ejemplo de implementaci√≥n de plugin
class CustomDataProcessor(Plugin):
    """Plugin de procesamiento de datos personalizado"""
    
    @property
    def name(self) -> str:
        return "custom_processor"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    def initialize(self, config: Dict[str, Any]):
        self.config = config
    
    def process(self, data: Any) -> Any:
        # L√≥gica de procesamiento personalizada
        return processed_data
    
    def cleanup(self):
        # Libera recursos
        pass
```

---

**Resumen**: Nav-data adopta un dise√±o arquitect√≥nico modular y en capas, lo que garantiza la mantenibilidad, extensibilidad y rendimiento del sistema. Mediante la aplicaci√≥n de patrones de dise√±o adecuados, mecanismos completos de manejo de errores y un sistema de monitoreo, se proporcionan servicios de conversi√≥n de datos de navegaci√≥n a√©rea estables y confiables a los usuarios. ‚úàÔ∏è