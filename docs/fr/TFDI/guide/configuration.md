# ‚öôÔ∏è Guide de configuration du convertisseur de donn√©es de navigation TFDI

Ce guide d√©taille les diverses options de configuration du convertisseur de donn√©es de navigation TFDI, vous aidant √† optimiser le processus de conversion et les r√©sultats de sortie en fonction de vos besoins.

## üéØ Aper√ßu de la configuration

Le convertisseur TFDI utilise un syst√®me de configuration flexible, offrant :
- **üìÅ Configuration de la sortie** - Personnalisation du r√©pertoire de sortie et du format des fichiers
- **üìä Param√®tres de traitement des donn√©es** - Ajustement de la pr√©cision des coordonn√©es et du filtrage des donn√©es
- **‚ö° Optimisation des performances** - Gestion de la m√©moire et r√©glage de la vitesse de traitement
- **üîç Options de validation** - Param√®tres d'int√©grit√© des donn√©es et de contr√¥le qualit√©

## üìã M√©thodes de configuration

### 1. Configuration par d√©faut (Recommand√© pour les d√©butants)
```python
# Ex√©cuter avec la configuration par d√©faut
python Fenix2TFDINavDataConverter.py
# Le convertisseur utilisera la configuration optimale pr√©d√©finie
```

### 2. Configuration dans le code
```python
from dataclasses import dataclass

@dataclass
class ConverterConfig:
    """Classe de configuration du convertisseur"""
    output_dir: str = "Primary"
    procedure_legs_dir: str = "Primary/ProcedureLegs" 
    archive_name: str = "Primary.7z"
    coordinate_precision: int = 8
    vnav_threshold: float = 2.5
```

### 3. Configuration interactive
```python
# Configuration interactive lors de l'ex√©cution du convertisseur
# L'utilisateur peut d√©finir les param√®tres cl√©s pendant l'ex√©cution
```

## üîß Options de configuration principales

### Configuration des chemins de sortie

#### R√©glage du r√©pertoire de sortie
**Nom du param√®tre**: `output_dir`  
**Valeur par d√©faut**: `"Primary"`  
**Description**: R√©pertoire de sortie pour tous les fichiers JSON

**Exemple d'utilisation :**
```python
config = ConverterConfig(
    output_dir="TFDI_NavData",  # Nom du r√©pertoire de sortie personnalis√©
)
```

**Structure du r√©pertoire :**
```
TFDI_NavData/           # R√©pertoire de sortie principal
‚îú‚îÄ‚îÄ Airports.json       # Donn√©es d'a√©roports
‚îú‚îÄ‚îÄ Runways.json        # Donn√©es de pistes
‚îú‚îÄ‚îÄ Waypoints.json      # Donn√©es de waypoints
‚îú‚îÄ‚îÄ ...                 # Autres fichiers JSON
‚îî‚îÄ‚îÄ ProcedureLegs/      # Sous-r√©pertoire des segments de proc√©dure
    ‚îú‚îÄ‚îÄ TermID_1.json
    ‚îú‚îÄ‚îÄ TermID_2.json
    ‚îî‚îÄ‚îÄ ...
```

#### R√©pertoire des segments de proc√©dure
**Nom du param√®tre**: `procedure_legs_dir`  
**Valeur par d√©faut**: `"Primary/ProcedureLegs"`  
**Description**: R√©pertoire de sortie pour les fichiers des segments de proc√©dure terminale

**Exemple de configuration :**
```python
config = ConverterConfig(
    output_dir="NavData",
    procedure_legs_dir="NavData/Procedures",  # R√©pertoire des segments de proc√©dure personnalis√©
)
```

#### Nom de l'archive compress√©e
**Nom du param√®tre**: `archive_name`  
**Valeur par d√©faut**: `"Primary.7z"`  
**Description**: Nom du fichier de l'archive compress√©e g√©n√©r√©e

**Conventions de nommage :**
```python
# Nommage incluant un horodatage
import datetime
now = datetime.datetime.now()
config = ConverterConfig(
    archive_name=f"TFDI_NavData_{now.strftime('%Y%m%d_%H%M')}.7z"
)

# Nommage incluant des informations de version
config = ConverterConfig(
    archive_name="TFDI_NavData_v1.0.7z"
)
```

### Configuration du traitement des donn√©es

#### R√©glage de la pr√©cision des coordonn√©es
**Nom du param√®tre**: `coordinate_precision`  
**Valeur par d√©faut**: `8`  
**Plage**: `4 - 12`  
**Description**: Nombre de d√©cimales pour les coordonn√©es g√©ographiques

**Tableau comparatif des pr√©cisions :**
| Pr√©cision   | Marge d'erreur     | Sc√©nario applicable      | Impact sur la taille du fichier |
|-------------|--------------------|--------------------------|---------------------------------|
| 4 d√©cimales | ~11 m√®tres         | Navigation de base       | Minimal                         |
| 6 d√©cimales | ~1.1 m√®tre         | Navigation standard      | Faible                          |
| 8 d√©cimales | ~1.1 centim√®tre    | Navigation haute pr√©cision | Par d√©faut                      |
| 10 d√©cimales| ~1.1 millim√®tre    | Tr√®s haute pr√©cision     | √âlev√©                           |
| 12 d√©cimales| ~0.1 millim√®tre    | Pr√©cision de niveau topographique | Maximal                         |

**Exemple de configuration :**
```python
# Configuration haute pr√©cision (recommand√©e)
config = ConverterConfig(coordinate_precision=8)

# Configuration √©quilibr√©e (taille de fichier r√©duite)
config = ConverterConfig(coordinate_precision=6)

# Configuration tr√®s haute pr√©cision (taille de fichier plus importante)
config = ConverterConfig(coordinate_precision=10)
```

#### R√©glage du seuil VNAV
**Nom du param√®tre**: `vnav_threshold`  
**Valeur par d√©faut**: `2.5`  
**Unit√©**: Degr√©s  
**Description**: Seuil d'angle VNAV pour la d√©tection des points FAF

**Signification du seuil :**
```python
# D√©tection FAF stricte (moins de points FAF, mais plus pr√©cis)
config = ConverterConfig(vnav_threshold=2.0)

# D√©tection FAF standard (√©quilibre entre pr√©cision et couverture)
config = ConverterConfig(vnav_threshold=2.5)

# D√©tection FAF souple (plus de points FAF, peut inclure des faux positifs)
config = ConverterConfig(vnav_threshold=3.0)
```

**Logique de d√©tection FAF :**
```python
def is_faf_point(vnav_angle: float, vnav_threshold: float) -> bool:
    """D√©termine si un point est un FAF"""
    return (vnav_angle is not None and 
            vnav_angle <= vnav_threshold and 
            vnav_angle > 0)
```

## üöÄ Configuration des performances

### Optimisation de la base de donn√©es SQLite

#### Param√®tres de connexion √† la base de donn√©es
```python
# Configuration d'optimisation des performances SQLite
sqlite_pragmas = {
    "journal_mode": "WAL",          # Mode journalisation avant √©criture
    "synchronous": "NORMAL",        # √âquilibre entre performance et s√©curit√©
    "cache_size": "10000",          # Nombre de pages en cache (environ 40 Mo)
    "temp_store": "MEMORY",         # Stockage des donn√©es temporaires en m√©moire
    "mmap_size": "268435456",       # Taille de la m√©moire mapp√©e (256 Mo)
}

def optimize_database_connection(conn):
    """Optimise la connexion √† la base de donn√©es"""
    for pragma, value in sqlite_pragmas.items():
        conn.execute(f"PRAGMA {pragma}={value}")
```

#### Param√®tres de traitement par lots
**Param√®tre**: Taille du lot  
**Valeur par d√©faut**: `1000`  
**Description**: Nombre d'enregistrements trait√©s en une seule fois

**Strat√©gie de configuration :**
```python
import psutil

def get_optimal_batch_size():
    """Ajuste automatiquement la taille du lot en fonction de la m√©moire syst√®me"""
    available_memory_gb = psutil.virtual_memory().available / (1024**3)
    
    if available_memory_gb < 4:
        return 500      # Syst√®me √† faible m√©moire
    elif available_memory_gb < 8:
        return 1000     # Configuration standard
    else:
        return 2000     # Syst√®me √† haute m√©moire

# Exemple d'utilisation
batch_size = get_optimal_batch_size()
```

### Configuration de la gestion de la m√©moire

#### Param√®tres de surveillance de la m√©moire
```python
class MemoryMonitor:
    """Configuration de la surveillance de la m√©moire"""
    
    def __init__(self):
        self.memory_limit_gb = 6        # Limite d'utilisation de la m√©moire
        self.warning_threshold = 0.8    # Seuil d'avertissement (80%)
        self.critical_threshold = 0.9   # Seuil critique (90%)
    
    def check_memory_usage(self):
        """V√©rifie l'utilisation de la m√©moire"""
        memory = psutil.virtual_memory()
        usage_ratio = memory.used / memory.total
        
        if usage_ratio > self.critical_threshold:
            return "CRITICAL"
        elif usage_ratio > self.warning_threshold:
            return "WARNING"
        else:
            return "NORMAL"
```

#### Configuration du ramasse-miettes
```python
import gc

def configure_garbage_collection():
    """Configure le ramasse-miettes"""
    # D√©finit les seuils du ramasse-miettes
    gc.set_threshold(700, 10, 10)
    
    # Active le d√©bogage du ramasse-miettes (√† utiliser uniquement lors du d√©bogage)
    # gc.set_debug(gc.DEBUG_STATS)

def force_cleanup():
    """Force le nettoyage de la m√©moire"""
    gc.collect()
    gc.collect()  # Ex√©cuter deux fois pour assurer un nettoyage complet
    gc.collect()
```

## üîç Validation et contr√¥le qualit√©

### Configuration de la validation des donn√©es

#### R√©glage du niveau de validation
```python
class ValidationConfig:
    """Configuration de la validation des donn√©es"""
    
    def __init__(self, level="standard"):
        self.level = level
        self.checks = self._get_checks_for_level(level)
    
    def _get_checks_for_level(self, level):
        """Obtient les √©l√©ments de v√©rification en fonction du niveau"""
        base_checks = [
            "file_exists",
            "database_format", 
            "required_tables"
        ]
        
        if level == "basic":
            return base_checks
        
        elif level == "standard":
            return base_checks + [
                "coordinate_ranges",
                "data_types",
                "foreign_keys"
            ]
        
        elif level == "strict":
            return base_checks + [
                "coordinate_ranges",
                "data_types", 
                "foreign_keys",
                "data_consistency",
                "duplicate_detection",
                "business_rules"
            ]
```

#### Configuration de la validation des coordonn√©es
```python
class CoordinateValidator:
    """Configuration de la validation des coordonn√©es"""
    
    def __init__(self):
        # Plage de coordonn√©es valides
        self.lat_min = -90.0
        self.lat_max = 90.0
        self.lon_min = -180.0
        self.lon_max = 180.0
        
        # Plage de coordonn√©es suspectes (peut s'agir de donn√©es erron√©es)
        self.suspicious_zones = [
            {"lat": (0, 0), "lon": (0, 0)},      # Les coordonn√©es √† l'origine peuvent √™tre erron√©es
            {"lat": (90, 90), "lon": (0, 0)},    # Les coordonn√©es polaires n√©cessitent une v√©rification sp√©ciale
        ]
    
    def validate_coordinate(self, lat, lon):
        """Valide une seule coordonn√©e"""
        # V√©rifie la plage de base
        if not (self.lat_min <= lat <= self.lat_max):
            return False, f"Latitude hors plage: {lat}"
        
        if not (self.lon_min <= lon <= self.lon_max):
            return False, f"Longitude hors plage: {lon}"
        
        # V√©rifie les coordonn√©es suspectes
        for zone in self.suspicious_zones:
            if (zone["lat"][0] <= lat <= zone["lat"][1] and 
                zone["lon"][0] <= lon <= zone["lon"][1]):
                return True, f"Coordonn√©e suspecte: ({lat}, {lon})"
        
        return True, "Coordonn√©e valide"
```

### Contr√¥le qualit√© de la sortie

#### Validation du format des fichiers
```python
import json

class OutputValidator:
    """Configuration de la validation des fichiers de sortie"""
    
    def __init__(self):
        self.required_files = [
            "Airports.json",
            "Runways.json", 
            "Waypoints.json",
            "Navaids.json",
            "Airways.json",
            "AirwayLegs.json",
            "Terminals.json",
            "ILSes.json"
        ]
        
        self.min_file_sizes = {
            "Airports.json": 1024,      # Au moins 1 Ko
            "Waypoints.json": 10240,    # Au moins 10 Ko
        }
    
    def validate_json_file(self, file_path):
        """Valide le format du fichier JSON"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if not isinstance(data, (dict, list)):
                return False, "L'objet racine JSON doit √™tre un dictionnaire ou une liste"
            
            if isinstance(data, dict) and len(data) == 0:
                return False, "L'objet JSON est vide"
            
            return True, "Format JSON valide"
            
        except json.JSONDecodeError as e:
            return False, f"Erreur de format JSON: {e}"
        except Exception as e:
            return False, f"Erreur de lecture du fichier: {e}"
```

## üéõÔ∏è Configuration avanc√©e

### Configuration des journaux

#### Niveau et format des journaux
```python
import logging
from rich.logging import RichHandler

class LoggingConfig:
    """Classe de configuration des journaux"""
    
    def __init__(self, level="INFO"):
        self.level = level
        self.format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        self.file_name = "tfdi_converter.log"
        self.max_file_size = 10 * 1024 * 1024  # 10 Mo
        self.backup_count = 3
    
    def setup_logging(self):
        """Configure le syst√®me de journalisation"""
        # Cr√©e le logger
        logger = logging.getLogger("TFDIConverter")
        logger.setLevel(getattr(logging, self.level))
        
        # Gestionnaire de console Rich
        console_handler = RichHandler(rich_tracebacks=True)
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter("%(message)s")
        console_handler.setFormatter(console_formatter)
        
        # Gestionnaire de fichiers
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            self.file_name, 
            maxBytes=self.max_file_size,
            backupCount=self.backup_count,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(self.format)
        file_handler.setFormatter(file_formatter)
        
        # Ajoute les gestionnaires
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        
        return logger
```

### Configuration de la compression

#### R√©glage du niveau de compression
```python
import py7zr

class CompressionConfig:
    """Classe de configuration de la compression"""
    
    def __init__(self):
        self.compression_level = 5      # Niveau de compression (1-9)
        self.method = "LZMA2"          # Algorithme de compression
        self.solid = True              # Compression solide
        self.multi_threading = True    # Compression multi-thread
    
    def create_archive(self, source_dir, archive_path):
        """Cr√©e une archive compress√©e"""
        filters = [
            {"id": py7zr.FILTER_LZMA2, "preset": self.compression_level}
        ]
        
        with py7zr.SevenZipFile(
            archive_path, 
            'w', 
            filters=filters,
            mp=self.multi_threading
        ) as archive:
            archive.writeall(source_dir, ".")
```

### Configuration de d√©bogage

#### R√©glage du mode de d√©bogage
```python
class DebugConfig:
    """Classe de configuration de d√©bogage"""
    
    def __init__(self, debug_mode=False):
        self.debug_mode = debug_mode
        self.save_intermediate_files = debug_mode
        self.verbose_logging = debug_mode
        self.performance_profiling = debug_mode
        self.memory_tracking = debug_mode
    
    def enable_debug_features(self):
        """Active les fonctionnalit√©s de d√©bogage"""
        if self.debug_mode:
            # Active la journalisation d√©taill√©e
            logging.getLogger().setLevel(logging.DEBUG)
            
            # Active le profilage des performances
            if self.performance_profiling:
                import cProfile
                self.profiler = cProfile.Profile()
                self.profiler.enable()
            
            # Active le suivi de la m√©moire
            if self.memory_tracking:
                import tracemalloc
                tracemalloc.start()
```

## üìù Exemples de configuration compl√®te

### Exemple de configuration de base
```python
# Configuration simple pour les d√©butants
config = ConverterConfig(
    output_dir="TFDI_Output",
    coordinate_precision=8,
    vnav_threshold=2.5
)
```

### Exemple de configuration haute performance
```python
# Configuration optimis√©e pour le mat√©riel haut de gamme
config = ConverterConfig(
    output_dir="Primary_HighPerf",
    coordinate_precision=8,
    vnav_threshold=2.5
)

# Associ√©e aux param√®tres d'optimisation des performances
batch_size = 2000
memory_limit_gb = 8
enable_multi_threading = True
```

### Exemple de configuration haute qualit√©
```python
# Adapt√©e aux sc√©narios exigeant une qualit√© de donn√©es tr√®s √©lev√©e
config = ConverterConfig(
    output_dir="Primary_HighQuality", 
    coordinate_precision=10,        # Plus haute pr√©cision
    vnav_threshold=2.0             # D√©tection FAF plus stricte
)

# Associ√©e √† une validation stricte
validation_level = "strict"
enable_duplicate_detection = True
enable_consistency_check = True
```

### Exemple de configuration de d√©bogage
```python
# Configuration pour le d√©veloppement et le d√©bogage
config = ConverterConfig(
    output_dir="Debug_Output",
    coordinate_precision=6,         # R√©duction de la pr√©cision pour acc√©l√©rer le traitement
    vnav_threshold=3.0             # Seuil plus souple pour faciliter le d√©bogage
)

# Options de d√©bogage
debug_config = DebugConfig(debug_mode=True)
save_intermediate_files = True
verbose_logging = True
```

## üîß Gestion des fichiers de configuration

### Format du fichier de configuration
```python
# config.py
from dataclasses import dataclass, asdict
import json

@dataclass 
class TFDIConverterConfig:
    """Configuration compl√®te du convertisseur TFDI"""
    # Configuration de la sortie
    output_dir: str = "Primary"
    procedure_legs_dir: str = "Primary/ProcedureLegs"
    archive_name: str = "Primary.7z"
    
    # Configuration du traitement des donn√©es
    coordinate_precision: int = 8
    vnav_threshold: float = 2.5
    
    # Configuration des performances
    batch_size: int = 1000
    memory_limit_gb: int = 6
    
    # Configuration de la validation
    validation_level: str = "standard"
    enable_coordinate_check: bool = True
    
    # Configuration des journaux
    log_level: str = "INFO"
    log_file: str = "tfdi_converter.log"
    
    def save_to_file(self, file_path: str):
        """Enregistre la configuration dans un fichier"""
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(self), f, indent=2)
    
    @classmethod
    def load_from_file(cls, file_path: str):
        """Charge la configuration depuis un fichier"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return cls(**data)
```

### Mod√®les de configuration
```python
# Cr√©e des mod√®les de configuration
def create_config_templates():
    """Cr√©e divers mod√®les de configuration"""
    
    # Configuration par d√©faut
    default_config = TFDIConverterConfig()
    default_config.save_to_file("config_default.json")
    
    # Configuration haute performance
    performance_config = TFDIConverterConfig(
        batch_size=2000,
        memory_limit_gb=8,
        coordinate_precision=6
    )
    performance_config.save_to_file("config_performance.json")
    
    # Configuration haute qualit√©
    quality_config = TFDIConverterConfig(
        coordinate_precision=10,
        vnav_threshold=2.0,
        validation_level="strict"
    )
    quality_config.save_to_file("config_quality.json")

# Utiliser la configuration
config = TFDIConverterConfig.load_from_file("config_performance.json")
```

---

**√âtape suivante** : Une fois la configuration termin√©e, veuillez consulter [les instructions d'utilisation](usage.md) pour d√©marrer votre conversion de donn√©es TFDI ! üöÅ‚ú®