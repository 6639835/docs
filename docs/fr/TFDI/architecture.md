# üèóÔ∏è Architecture du convertisseur de donn√©es de navigation TFDI

## Aper√ßu du syst√®me

Le convertisseur de donn√©es de navigation TFDI est un outil professionnel de conversion de donn√©es de navigation a√©ronautiques, sp√©cialement con√ßu pour convertir les bases de donn√©es de navigation du Fenix A320 au format JSON compatible avec le TFDI MD-11. Cet outil adopte une conception architecturale moderne, offrant des services de conversion de donn√©es efficaces et fiables.

## üéØ Principes de conception

### 1. Priorit√© √† l'int√©grit√© des donn√©es
- **Validation stricte** : M√©canismes de validation de donn√©es multicouches
- **Maintien des relations** : Pr√©serve les d√©pendances entre les donn√©es de navigation
- **Garantie de pr√©cision** : Maintient une haute pr√©cision pour les coordonn√©es et les calculs
- **V√©rification de la coh√©rence** : Assure la coh√©rence logique des donn√©es apr√®s conversion

### 2. Ax√© sur l'optimisation des performances
- **Optimisation SQLite** : Mode WAL et r√©glage des performances
- **Traitement par lots** : Strat√©gie de traitement par lots √©conome en m√©moire
- **M√©canisme de cache** : Cache et r√©utilisation intelligents des donn√©es
- **Optimisation de la compression** : Compression et nettoyage rapides 7z

### 3. Exp√©rience utilisateur primordiale
- **Rich CLI** : Interface de terminal couleur modernis√©e
- **Retour en temps r√©el** : Affichage d√©taill√© de la progression et mises √† jour de l'√©tat
- **Alertes conviviales** : Gestion professionnelle des erreurs et suggestions de r√©cup√©ration
- **Conception interactive** : Guidage intuitif du flux op√©rationnel

## üèóÔ∏è Architecture du syst√®me

### Diagramme d'architecture global

```mermaid
graph TB
    A[Couche Interface Utilisateur] --> B[Couche Logique M√©tier]
    B --> C[Couche Traitement des Donn√©es]
    C --> D[Couche Acc√®s au Stockage]
    
    A --> A1[Interface Rich CLI]
    A --> A2[Gestionnaire de Progression]
    A --> A3[Interaction Utilisateur]
    
    B --> B1[Contr√¥leur de Conversion]
    B --> B2[Gestionnaire de Configuration]
    B --> B3[Moteur de Validation]
    B --> B4[D√©tecteur FAF]
    
    C --> C1[Processeur SQLite]
    C --> C2[Normalisateur de Coordonn√©es]
    C --> C3[S√©rialiseur JSON]
    C --> C4[Gestionnaire de Compression]
    
    D --> D1[Base de Donn√©es Fenix]
    D --> D2[Fichiers JSON]
    D --> D3[Archive compress√©e 7z]
```

### D√©tail des composants cl√©s

#### 1. Couche Interface Utilisateur (UI Layer)
**Responsabilit√©s** : Fournit l'interface d'interaction utilisateur et le feedback
```python
class RichInterface:
    """Gestionnaire d'interface Rich CLI"""
    - progress_tracking: Gestion de la barre de progression
    - status_display: Affichage des informations d'√©tat
    - error_presentation: Pr√©sentation des messages d'erreur
    - user_input: Traitement des entr√©es utilisateur
```

#### 2. Couche Logique M√©tier (Business Layer)
**Responsabilit√©s** : Logique m√©tier centrale et contr√¥le de flux
```python
class FenixToTFDIConverter:
    """Classe principale du convertisseur"""
    - database_validation: Validation de la base de donn√©es
    - conversion_orchestration: Orchestration du processus de conversion
    - faf_detection: D√©tection des points FAF
    - data_normalization: Normalisation des donn√©es
```

#### 3. Couche Traitement des Donn√©es (Data Layer)
**Responsabilit√©s** : Algorithmes de conversion et de traitement des donn√©es
```python
class DataProcessor:
    """Noyau de traitement des donn√©es"""
    - coordinate_precision: Gestion de la pr√©cision des coordonn√©es
    - column_standardization: Standardisation des noms de colonnes
    - relationship_mapping: Mappage des relations
    - format_conversion: Conversion de format
```

#### 4. Couche Acc√®s au Stockage (Storage Layer)
**Responsabilit√©s** : Acc√®s √† la base de donn√©es et op√©rations sur les fichiers
```python
class StorageManager:
    """Gestionnaire de stockage"""
    - sqlite_optimization: Optimisation des performances SQLite
    - file_operations: Op√©rations de lecture/√©criture de fichiers
    - compression_handling: Gestion des fichiers compress√©s
    - backup_management: Gestion des sauvegardes
```

## üìä Architecture du flux de donn√©es

### Pipeline de conversion

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant UI as Couche Interface
    participant BL as Couche M√©tier
    participant DL as Couche Donn√©es
    participant SL as Couche Stockage
    
    U->>UI: D√©marrer la conversion
    UI->>BL: Initialiser le convertisseur
    BL->>SL: Valider la base de donn√©es
    SL->>BL: Renvoyer le r√©sultat de la validation
    BL->>DL: Commencer le traitement des donn√©es
    
    loop Pour chaque table de donn√©es
        DL->>SL: Lire les donn√©es
        DL->>DL: Traitement de normalisation
        DL->>DL: Ajustement de la pr√©cision des coordonn√©es
        DL->>SL: √âcrire en JSON
        DL->>UI: Mettre √† jour la progression
    end
    
    DL->>BL: Traitement termin√©
    BL->>SL: Cr√©er l'archive compress√©e
    SL->>UI: Renvoyer le r√©sultat
    UI->>U: Afficher l'√©tat d'ach√®vement
```

### Architecture de mappage des donn√©es

```mermaid
graph LR
    A[Base de donn√©es SQLite Fenix] --> B[Couche d'extraction de donn√©es]
    B --> C[Couche de normalisation]
    C --> D[Couche de validation]
    D --> E[Couche de conversion]
    E --> F[Couche de s√©rialisation]
    F --> G[Jeu de fichiers JSON]
    G --> H[Couche de compression]
    H --> I[Paquet compatible TFDI]
```

## üîß Pile technologique

### Technologies cl√©s

| Composant | Choix technologique | Exigences de version | Utilisation |
|-----------|---------------------|----------------------|-------------|
| **Python**    | Python 3.8+         | ‚â• 3.8.0              | Langage de programmation principal |
| **Rich**      | Rich Library        | ‚â• 12.0.0             | Embellissement de l'interface CLI |
| **SQLite3**   | Module int√©gr√©      | Int√©gr√© √† Python     | Acc√®s √† la base de donn√©es |
| **Pandas**    | DataFrame           | ‚â• 1.3.0              | Traitement des donn√©es |
| **JSON**      | Module int√©gr√©      | Int√©gr√© √† Python     | S√©rialisation des donn√©es |
| **py7zr**     | 7-Zip Python        | ‚â• 0.18.0             | Traitement de compression |

### Caract√©ristiques architecturales

#### 1. Conception modulaire
```python
fenix_to_tfdi/
‚îú‚îÄ‚îÄ core/                  # Modules principaux
‚îÇ   ‚îú‚îÄ‚îÄ converter.py       # Convertisseur principal
‚îÇ   ‚îú‚îÄ‚îÄ validator.py       # Validateur de donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Gestion de la configuration
‚îú‚îÄ‚îÄ data/                  # Traitement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ processor.py       # Processeur de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py      # Outil de normalisation
‚îÇ   ‚îî‚îÄ‚îÄ serializer.py     # Outil de s√©rialisation
‚îú‚îÄ‚îÄ ui/                    # Interface utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ cli.py            # Interface en ligne de commande
‚îÇ   ‚îî‚îÄ‚îÄ progress.py       # Gestion de la progression
‚îî‚îÄ‚îÄ utils/                 # Modules utilitaires
    ‚îú‚îÄ‚îÄ storage.py        # Outils de stockage
    ‚îî‚îÄ‚îÄ compression.py    # Outils de compression
```

#### 2. Architecture bas√©e sur la configuration
```python
@dataclass
class ConverterConfig:
    """Classe de configuration du convertisseur"""
    output_dir: str = "Primary"
    procedure_legs_dir: str = "Primary/ProcedureLegs"
    archive_name: str = "Primary.7z"
    coordinate_precision: int = 8
    vnav_threshold: float = 2.5
    
    # Configuration d'optimisation SQLite
    sqlite_pragmas: Dict[str, str] = field(default_factory=lambda: {
        "journal_mode": "WAL",
        "synchronous": "NORMAL",
        "cache_size": "10000",
        "temp_store": "MEMORY"
    })
```

## üöÄ Architecture de performance

### Strat√©gies de gestion de la m√©moire

#### 1. Traitement en flux
```python
def process_large_table(table_name: str, batch_size: int = 1000):
    """Traite les donn√©es de grandes tables en flux"""
    offset = 0
    while True:
        query = f"""
        SELECT * FROM {table_name} 
        LIMIT {batch_size} OFFSET {offset}
        """
        
        batch = execute_query(query)
        if not batch:
            break
            
        process_batch(batch)
        offset += batch_size
```

#### 2. Optimisation du cache
```python
class WaypointCache:
    """Gestion du cache des waypoints"""
    def __init__(self, max_size: int = 10000):
        self._cache: Dict[str, WaypointData] = {}
        self._max_size = max_size
        self._access_times: Dict[str, float] = {}
    
    def get_waypoint(self, waypoint_id: str) -> Optional[WaypointData]:
        """R√©cup√®re les donn√©es de waypoint mises en cache"""
        if waypoint_id in self._cache:
            self._access_times[waypoint_id] = time.time()
            return self._cache[waypoint_id]
        return None
```

### Architecture de traitement concurrent

#### 1. Conception multithread
```python
class ConcurrentProcessor:
    """Processeur concurrent"""
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def process_tables_parallel(self, tables: List[str]):
        """Traite plusieurs tables en parall√®le"""
        futures = []
        for table in tables:
            future = self.executor.submit(self.process_table, table)
            futures.append(future)
        
        # Attendre que toutes les t√¢ches soient termin√©es
        concurrent.futures.wait(futures)
```

#### 2. Gestion des pools de ressources
```python
class DatabaseConnectionPool:
    """Pool de connexions √† la base de donn√©es"""
    def __init__(self, db_path: str, pool_size: int = 5):
        self.db_path = db_path
        self.pool_size = pool_size
        self.connections: Queue = Queue(maxsize=pool_size)
        self._init_pool()
    
    def get_connection(self) -> sqlite3.Connection:
        """Obtient une connexion √† la base de donn√©es"""
        return self.connections.get()
    
    def return_connection(self, conn: sqlite3.Connection):
        """Lib√®re une connexion √† la base de donn√©es"""
        self.connections.put(conn)
```

## üîí Architecture de s√©curit√©

### M√©canismes de protection des donn√©es

#### 1. Validation des entr√©es
```python
class InputValidator:
    """Validateur d'entr√©es"""
    
    @staticmethod
    def validate_database_path(path: str) -> bool:
        """Valide la s√©curit√© du chemin de la base de donn√©es"""
        # V√©rifier les attaques par travers√©e de r√©pertoire
        if ".." in path or path.startswith("/"):
            return False
        
        # Valider l'extension du fichier
        if not path.endswith(('.db', '.db3', '.sqlite')):
            return False
        
        return True
    
    @staticmethod  
    def validate_terminal_id(terminal_id: int) -> bool:
        """Valide la plage de l'ID de terminal"""
        return 1 <= terminal_id <= 999999
```

#### 2. Isolation des erreurs
```python
class SafeConverter:
    """Convertisseur s√©curis√©"""
    
    def safe_convert_table(self, table_name: str) -> bool:
        """Conversion de table s√©curis√©e"""
        try:
            with self.create_transaction() as transaction:
                result = self.convert_table(table_name)
                transaction.commit()
                return result
        except DatabaseError as e:
            self.logger.error(f"Erreur de base de donn√©es: {e}")
            transaction.rollback()
            return False
        except Exception as e:
            self.logger.error(f"Erreur inconnue: {e}")
            return False
```

## üìà Architecture √©volutive

### Conception du syst√®me de plugins

#### 1. Interface de plugin de convertisseur
```python
class ConverterPlugin(ABC):
    """Classe de base abstraite pour les plugins de convertisseur"""
    
    @abstractmethod
    def get_name(self) -> str:
        """Obtient le nom du plugin"""
        pass
    
    @abstractmethod
    def get_supported_formats(self) -> List[str]:
        """Obtient les formats support√©s"""
        pass
    
    @abstractmethod
    def convert_data(self, data: Any, config: ConverterConfig) -> Any:
        """Convertit les donn√©es"""
        pass
```

#### 2. M√©canisme d'extension de format
```python
class FormatRegistry:
    """Registre des formats"""
    
    def __init__(self):
        self._converters: Dict[str, ConverterPlugin] = {}
    
    def register_converter(self, format_name: str, converter: ConverterPlugin):
        """Enregistre un convertisseur"""
        self._converters[format_name] = converter
    
    def get_converter(self, format_name: str) -> Optional[ConverterPlugin]:
        """Obtient un convertisseur"""
        return self._converters.get(format_name)
```

### Extension de la source de donn√©es

#### 1. Abstraction de la source de donn√©es
```python
class DataSource(ABC):
    """Classe de base abstraite pour la source de donn√©es"""
    
    @abstractmethod
    def connect(self) -> bool:
        """Connecte la source de donn√©es"""
        pass
    
    @abstractmethod
    def get_tables(self) -> List[str]:
        """Obtient la liste des tables"""
        pass
    
    @abstractmethod
    def query_data(self, query: str) -> Iterator[Dict]:
        """Interroge les donn√©es"""
        pass
```

## üîÑ Architecture de maintenabilit√©

### Syst√®me de journalisation

#### 1. Journalisation structur√©e
```python
class StructuredLogger:
    """Enregistreur de logs structur√©s"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # Gestionnaire de formatage Rich
        rich_handler = RichHandler(rich_tracebacks=True)
        rich_handler.setFormatter(
            logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
        )
        self.logger.addHandler(rich_handler)
    
    def log_conversion_start(self, table_name: str, record_count: int):
        """Enregistre le d√©but de la conversion"""
        self.logger.info(
            f"D√©but de la conversion de la table {table_name}",
            extra={
                "table": table_name,
                "record_count": record_count,
                "operation": "conversion_start"
            }
        )
```

#### 2. Surveillance des performances
```python
class PerformanceMonitor:
    """Moniteur de performance"""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = defaultdict(list)
    
    @contextmanager
    def measure_time(self, operation: str):
        """Mesure le temps d'ex√©cution d'une op√©ration"""
        start_time = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start_time
            self.metrics[operation].append(elapsed)
            self.logger.debug(f"{operation} Dur√©e: {elapsed:.2f}s")
```

## üìä Architecture de test

### Strat√©gies de test

#### 1. Test en couches
```python
# Tests unitaires
class TestDataProcessor(unittest.TestCase):
    def test_coordinate_normalization(self):
        """Teste la normalisation des coordonn√©es"""
        processor = DataProcessor()
        result = processor.normalize_coordinate(39.916667, 8)
        self.assertEqual(result, 39.91666700)

# Tests d'int√©gration  
class TestConverterIntegration(unittest.TestCase):
    def test_full_conversion_pipeline(self):
        """Teste le pipeline de conversion complet"""
        converter = FenixToTFDIConverter(test_config)
        result = converter.convert(test_database_path)
        self.assertTrue(result)

# Tests de performance
class TestPerformance(unittest.TestCase):
    def test_large_database_conversion(self):
        """Teste les performances de conversion de grandes bases de donn√©es"""
        start_time = time.time()
        converter.convert(large_test_database)
        elapsed = time.time() - start_time
        self.assertLess(elapsed, 300)  # Devrait √™tre termin√© en moins de 5 minutes
```

---

Cette conception architecturale assure la **fiabilit√©**, la **performance** et la **maintenabilit√©** du convertisseur de donn√©es de navigation TFDI, fournissant une solution de conversion de donn√©es de niveau professionnel √† la communaut√© de simulation de vol du TFDI MD-11. üöÅ‚ú®