# Description de l'Architecture

Ce document d√©taille l'architecture syst√®me, les principes techniques et les concepts de conception du projet Nav-data.

## üèóÔ∏è Architecture G√©n√©rale

Nav-data adopte une conception modulaire, compos√©e de quatre modules principaux, chacun fonctionnant ind√©pendamment et pouvant √™tre combin√© de mani√®re flexible.

```mermaid
graph TB
    subgraph "Couche des sources de donn√©es"
        A1[Donn√©es CSV NAIP]
        A2[Fichiers de proc√©dures PDF]
        A3[Donn√©es natives X-Plane]
    end
    
    subgraph "Couche de traitement"
        B1[Module de traitement des routes a√©riennes<br/>Airway]
        B2[Module d'extraction PDF<br/>PDF Extract]
        B3[Module de correction de terminaux<br/>Terminal Patch]
        B4[Module de g√©n√©ration CIFP<br/>X-Plane CIFP]
    end
    
    subgraph "Couche de sortie"
        C1[earth_awy.dat]
        C2[Fichier de base de donn√©es des proc√©dures]
        C3[Donn√©es de terminaux corrig√©es]
        C4[Fichier X-Plane CIFP]
    end
    
    subgraph "Couche d'outils"
        D1[Validation des donn√©es]
        D2[Conversion de format]
        D3[Traitement des coordonn√©es]
        D4[Syst√®me de journalisation]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B4
    B2 --> B3
    
    B1 --> C1
    B2 --> C2
    B3 --> C3
    B4 --> C4
    
    B1 -.-> D1
    B2 -.-> D2
    B3 -.-> D3
    B4 -.-> D4
```

## üìã Principes de Conception

### 1. Conception modulaire
- **Ind√©pendance** : Chaque module peut fonctionner ind√©pendamment, sans forte d√©pendance vis-√†-vis des autres modules.
- **Composabilit√©** : Les modules peuvent √™tre combin√©s de mani√®re flexible pour former diff√©rents flux de traitement.
- **Extensibilit√©** : De nouveaux modules peuvent √™tre int√©gr√©s de mani√®re transparente √† l'architecture existante.

### 2. Pilot√© par le flux de donn√©es
- **Flux de donn√©es unidirectionnel** : Les donn√©es circulent de la source vers la cible, √©vitant les d√©pendances circulaires.
- **Sauvegarde des √©tats interm√©diaires** : Chaque √©tape de traitement sauvegarde les r√©sultats interm√©diaires, facilitant le d√©bogage et la r√©cup√©ration.
- **Standardisation des formats** : Des sp√©cifications de format de donn√©es uniformes garantissent la compatibilit√© entre les modules.

### 3. Tol√©rance aux pannes et r√©cup√©ration
- **Traitement par √©tapes** : Les t√¢ches complexes sont d√©compos√©es en petites √©tapes, r√©duisant le risque d'√©chec.
- **Isolation des erreurs** : L'√©chec du traitement d'un seul fichier n'affecte pas l'ensemble de la t√¢che de traitement par lots.
- **Persistance de l'√©tat** : Les informations d'√©tat critiques sont persistantes, permettant la reprise apr√®s interruption.

### 4. Optimisation des performances
- **Faible consommation m√©moire** : Traitement en flux des fichiers volumineux pour √©viter les d√©bordements de m√©moire.
- **Op√©rations par lots** : Le traitement par lots am√©liore l'efficacit√© des E/S.
- **Support de la concurrence** : Prise en charge du traitement concurrent en multithreading/multiprocessus.

## üõ†Ô∏è Architecture des Modules Principaux

### Module de traitement des routes a√©riennes (Airway)

```mermaid
graph TD
    A[Entr√©e CSV] --> B{Validation des donn√©es}
    B -->|Validation r√©ussie| C[Analyse des champs CSV]
    B -->|Validation √©chou√©e| X[Gestion des erreurs]
    
    C --> D[Chargement des donn√©es de r√©f√©rence]
    D --> E[earth_fix.dat]
    D --> F[earth_nav.dat]
    
    E --> G[Correspondance des points de navigation]
    F --> G
    C --> G
    
    G --> H{Filtrage par zone}
    H -->|Espace a√©rien chinois| I[G√©n√©ration des segments de routes a√©riennes]
    H -->|Autres zones| J[Ignorer le traitement]
    
    I --> K[Conversion de format]
    K --> L[Format X-Plane DAT]
    L --> M[Fusion de la sortie]
    M --> N[earth_awy.dat]
```

**Caract√©ristiques techniques :**
- **Algorithme de correspondance de donn√©es** : Correspondance intelligente bas√©e sur les identifiants et les coordonn√©es.
- **M√©canisme de filtrage par zone** : Prend en charge la configuration flexible du filtrage par zone g√©ographique.
- **Moteur de conversion de format** : Conversion pr√©cise du format CSV vers X-Plane DAT.
- **Gestion des cycles AIRAC** : Calcul et gestion automatiques des p√©riodes de validit√© des donn√©es a√©ronautiques.

**Classes et interfaces principales :**
```python
class NavigationType(Enum):
    """ÂØºËà™ÁÇπÁ±ªÂûãÊûö‰∏æ"""
    DESIGNATED_POINT = ('DESIGNATED_POINT', '11')
    VORDME = ('VORDME', '3') 
    NDB = ('NDB', '2')

@dataclass
class NavigationPoint:
    """ÂØºËà™ÁÇπÊï∞ÊçÆÁªìÊûÑ"""
    identifier: str
    type: NavigationType
    area_code: str

def process_navigation_point(identifier: str, code_type: str, 
                           earth_fix_data: Dict, earth_nav_data: Dict) -> Optional[NavigationPoint]:
    """ÂØºËà™ÁÇπÂ§ÑÁêÜÊ†∏ÂøÉÁÆóÊ≥ï"""
    pass

def convert_csv_to_dat(csv_file: str, earth_fix_path: str, 
                      earth_nav_path: str, earth_awy_path: str) -> None:
    """‰∏ªË¶ÅËΩ¨Êç¢ÂáΩÊï∞"""
    pass
```

### Module d'extraction PDF (PDF Extract)

```mermaid
graph TD
    A[Entr√©e PDF] --> B[Moteur d'analyse PDF]
    B --> C{Type de contenu}
    
    C -->|Donn√©es de proc√©dures| D[Extraction de proc√©dures de terminaux]
    C -->|Donn√©es de coordonn√©es| E[Extraction de points de cheminement]
    
    D --> F[Analyse de la structure du texte]
    F --> G[Reconnaissance des sections de proc√©dures]
    G --> H[Standardisation du format]
    H --> I[Sortie des donn√©es de proc√©dures]
    
    E --> J[Reconnaissance du format de coordonn√©es]
    J --> K[Conversion Degr√©s-Minutes-Secondes]
    K --> L[Traitement de la pr√©cision]
    L --> M[Sortie des donn√©es de coordonn√©es]
    
    I --> N[Validation des donn√©es]
    M --> N
    N --> O[Rapport de qualit√©]
```

**Caract√©ristiques techniques :**
- **Analyse multi-niveaux** : Prend en charge plusieurs √©l√©ments PDF tels que le texte, les lignes et les tableaux.
- **Reconnaissance intelligente** : Identifie automatiquement les formats de coordonn√©es et les structures de proc√©dures.
- **M√©canisme de tol√©rance aux pannes** : G√®re les incoh√©rences de format PDF et les probl√®mes de donn√©es manquantes.
- **Contr√¥le qualit√©** : M√©canisme int√©gr√© de v√©rification et de rapport de la qualit√© des donn√©es.

**Composants principaux :**
```python
class Line:
    """Á∫øÊù°ÂÖÉÁ¥†Á±ª"""
    def __init__(self, line: dict):
        self.is_horizontal = True if line["width"] > 5 else False
        self.top = line["top"]
        self.left = line["x0"]
        self.length = line["width"] if self.is_horizontal else line["height"]

class Word:
    """ÊñáÊú¨ÂÖÉÁ¥†Á±ª"""
    def __init__(self, info: dict):
        self.content = info["text"]
        self.center = ((info["x0"] + info["x1"]) / 2, (info["top"] + info["bottom"]) / 2)

class Unit:
    """Â§ÑÁêÜÂçïÂÖÉÁ±ª"""
    def __init__(self):
        self.words = []
        self.lines = []
    
    def match_underline(self):
        """‰∏ãÂàíÁ∫øÂåπÈÖçÁÆóÊ≥ï"""
        pass

def extract(pdf: pdfplumber.PDF) -> List[str]:
    """PDF ÊèêÂèñ‰∏ªÂáΩÊï∞"""
    pass
```

### Module de correction de terminaux (Terminal Patch)

```mermaid
graph TD
    A[Entr√©e Tdatabase] --> B[V√©rification du format]
    B --> C{Type d'encodage}
    
    C -->|N√©cessite encodage| D[Encodeur de terminaux]
    C -->|N√©cessite correction| E[Correcteur de format]
    
    D --> F[Identification des points IF]
    F --> G[Marquage des segments de transition]
    G --> H[Encodage de proc√©dure]
    H --> I[Sortie encod√©e]
    
    E --> J[Correspondance des r√®gles]
    J --> K{R√®gles de correction}
    K -->|APPCH GY M| L[Correction d'approche]
    K -->|R√®gles purement alphab√©tiques| M[Correction d'identifiant]
    K -->|R√®gles SID RW| N[Correction de d√©part]
    
    L --> O[Sortie corrig√©e]
    M --> O
    N --> O
    
    I --> P[Validation qualit√©]
    O --> P
    P --> Q[Sortie finale]
```

**Caract√©ristiques techniques :**
- **Moteur de r√®gles** : Moteur de r√®gles de correction bas√© sur la configuration.
- **Reconnaissance de motifs** : Reconnaissance intelligente des diff√©rents types de proc√©dures et d'identifiants.
- **Traitement par lots** : Prend en charge la correction par lots au niveau du dossier.
- **R√©trocompatibilit√©** : Maintient la compatibilit√© avec les formats de donn√©es existants.

**Syst√®me de r√®gles de correction :**
```python
class FixRule:
    """‰øÆÂ§çËßÑÂàôÂü∫Á±ª"""
    def __init__(self, name: str, pattern: str, action: callable):
        self.name = name
        self.pattern = pattern
        self.action = action
    
    def apply(self, line: str) -> str:
        """Â∫îÁî®‰øÆÂ§çËßÑÂàô"""
        pass

class RuleEngine:
    """ËßÑÂàôÂºïÊìé"""
    def __init__(self):
        self.rules = []
    
    def add_rule(self, rule: FixRule):
        """Ê∑ªÂä†‰øÆÂ§çËßÑÂàô"""
        self.rules.append(rule)
    
    def apply_rules(self, content: str) -> str:
        """Â∫îÁî®ÊâÄÊúâËßÑÂàô"""
        pass

# È¢ÑÂÆö‰πâ‰øÆÂ§çËßÑÂàô
APPCH_GY_M_RULE = FixRule(
    name="APPCH_GY_M",
    pattern=r"APPCH.*GY M",
    action=lambda line: fix_appch_gy_m(line)
)
```

### Module X-Plane CIFP (X-Plane CIFP)

```mermaid
graph TD
    A[Entr√©es multiples] --> B{Type de donn√©es}
    B -->|√âquipements de navigation| C[Processeur NavAid]
    B -->|Points de cheminement| D[Processeur Waypoint]
    B -->|Proc√©dures de terminaux| E[Processeur de terminaux]
    
    C --> F[Conversion VOR/NDB]
    F --> G[Traitement des fr√©quences]
    G --> H[Conversion des coordonn√©es]
    H --> I[Sortie NavAid]
    
    D --> J[Base de donn√©es des points de cheminement]
    J --> K[D√©duplication]
    K --> L[Encodage de zone]
    L --> M[Sortie Waypoint]
    
    E --> N[Analyse des proc√©dures]
    N --> O[SID/STAR/APPCH]
    O --> P[Encodage des segments]
    P --> Q[G√©n√©ration des informations de piste]
    Q --> R[Sortie CIFP]
    
    I --> S[Int√©gration des donn√©es]
    M --> S
    R --> S
    S --> T[V√©rification de la compatibilit√© X-Plane]
    T --> U[Fichier CIFP final]
```

**Caract√©ristiques techniques :**
- **Int√©gration de donn√©es multi-sources** : Int√®gre plusieurs sources de donn√©es comme NAIP et les donn√©es natives X-Plane.
- **Algorithme de d√©duplication intelligent** : Algorithme de d√©duplication intelligent bas√© sur les coordonn√©es et les identifiants.
- **Compatibilit√© des versions** : Prend en charge les formats X-Plane 11 et X-Plane 12.
- **Int√©grit√© des donn√©es** : Assure que les donn√©es CIFP g√©n√©r√©es sont compl√®tes et conformes aux standards.

**Structures de donn√©es principales :**
```python
class Waypoint:
    """Ëà™Ë∑ØÁÇπÁ±ª"""
    def __init__(self, la: float, long: float, ident: str, cat: int, 
                 airport: str = '', area: str = '', changeable: bool = True):
        self.latitude = la
        self.longitude = long
        self.ident = ident
        self.cat = cat  # -1:‰∏çÂèØÁî® 1:Ëà™Ë∑ØÁÇπ 2:VHF 3:NDB
        self.airport = airport
        self.area = area
        self.changeable = changeable
    
    def is_same(self, fix: "Waypoint", change: bool = False) -> bool:
        """Âà§Êñ≠ÊòØÂê¶‰∏∫Áõ∏ÂêåËà™Ë∑ØÁÇπ"""
        pass

class WaypointSystem:
    """Ëà™Ë∑ØÁÇπÁÆ°ÁêÜÁ≥ªÁªü"""
    def __init__(self):
        self.base = {}  # ‰∏ªÊï∞ÊçÆÂ∫ì
    
    def add_point(self, point: Waypoint):
        """Ê∑ªÂä†Ëà™Ë∑ØÁÇπ"""
        pass
    
    def query(self, point: Waypoint, change: bool = False) -> int:
        """Êü•ËØ¢Ëà™Ë∑ØÁÇπ"""
        pass

class Procedure:
    """Á®ãÂ∫èÁ±ª"""
    def __init__(self, ptype: int):
        self.ptype = "SID" if ptype == 1 else ("STAR" if ptype == 2 else "APPCH")
        self.airport = None
        self.runway = None
        self.name = None
        self.legs = []
    
    def encode(self):
        """Á®ãÂ∫èÁºñÁ†Å"""
        pass
    
    def output(self) -> str:
        """ËæìÂá∫ CIFP Ê†ºÂºè"""
        pass
```

## üîÑ Architecture du Flux de Donn√©es

### Diagramme de flux de donn√©es

```mermaid
flowchart LR
    subgraph "Donn√©es sources"
        A1[CSV NAIP]
        A2[Fichiers PDF]
        A3[Donn√©es X-Plane]
    end
    
    subgraph "Pr√©traitement"
        B1[Analyse CSV]
        B2[Extraction PDF]
        B3[Chargement des donn√©es]
    end
    
    subgraph "Traitement principal"
        C1[Conversion des routes a√©riennes]
        C2[Standardisation des proc√©dures]
        C3[Correction du format]
        C4[G√©n√©ration CIFP]
    end
    
    subgraph "Post-traitement"
        D1[Validation des donn√©es]
        D2[V√©rification du format]
        D3[Contr√¥le qualit√©]
    end
    
    subgraph "Sortie"
        E1[Fichiers DAT]
        E2[Fichiers de base de donn√©es]
        E3[Fichiers CIFP]
    end
    
    A1 --> B1 --> C1 --> D1 --> E1
    A2 --> B2 --> C2 --> D2 --> E2
    A3 --> B3 --> C4 --> D3 --> E3
    C2 --> C3 --> D2
```

### Cha√Æne de conversion des formats de donn√©es

```mermaid
graph TD
    A[PDF original] -->|pdfplumber| B[Texte structur√©]
    B -->|Analyseur| C[Paragraphes de proc√©dures]
    C -->|Encodeur| D[Proc√©dures standardis√©es]
    D -->|Correcteur| E[Format compatible CIFP]
    
    F[CSV NAIP] -->|pandas| G[Tableaux de donn√©es]
    G -->|Validateur| H[Enregistrements valides]
    H -->|Convertisseur| I[X-Plane DAT]
    
    J[X-Plane natif] -->|Chargeur| K[Donn√©es de r√©f√©rence]
    K -->|Correspondant| L[Informations associ√©es]
    L -->|Int√©grateur| M[Jeu de donn√©es complet]
```

## ‚öôÔ∏è Architecture de la Pile Technologique

### Composants techniques principaux

```mermaid
graph TB
    subgraph "Langage de programmation"
        A1[Python 3.6+]
    end
    
    subgraph "Traitement des donn√©es"
        B1[pandas - Analyse de donn√©es]
        B2[numpy - Calcul num√©rique]
        B3[csv - Traitement CSV]
    end
    
    subgraph "Traitement PDF"
        C1[pdfplumber - Analyse PDF]
        C2[Expressions r√©guli√®res - Correspondance de motifs]
    end
    
    subgraph "Calculs g√©ographiques"
        D1[geopy - Calcul de distances g√©ographiques]
        D2[Algorithmes de conversion de coordonn√©es]
    end
    
    subgraph "Interface utilisateur"
        E1[tqdm - Barres de progression]
        E2[colorama - Sortie color√©e]
        E3[logging - Syst√®me de journalisation]
    end
    
    subgraph "Base de donn√©es"
        F1[sqlite3 - Base de donn√©es l√©g√®re]
        F2[Syst√®me de fichiers - Persistance des donn√©es]
    end
    
    A1 --> B1
    A1 --> B2
    A1 --> C1
    A1 --> D1
    A1 --> E1
    A1 --> F1
```

### Gestion des d√©pendances

```python
# requirements.txt D√©pendances
# D√©pendances principales
pandas>=1.3.0          # Base de traitement des donn√©es
numpy>=1.21.0          # Base de calcul num√©rique

# Traitement PDF
pdfplumber>=0.7.0      # Moteur d'analyse PDF

# Exp√©rience utilisateur
tqdm>=4.60.0           # Affichage de la progression
colorama>=0.4.4        # Sortie color√©e

# Calculs g√©ographiques
geopy>=2.2.0           # Calcul de distances g√©ographiques

# Traitement du chinois
pypinyin>=0.44.0       # Conversion Pinyin du chinois

# Outils de d√©veloppement (optionnel)
pytest>=6.0.0          # Framework de test
black>=21.0.0          # Formatage de code
flake8>=3.9.0          # Analyse de code
```

## üèõÔ∏è Mod√®les de Conception

### 1. Mod√®le de fabrique (Factory Pattern)
Utilis√© pour cr√©er diff√©rents types de processeurs de donn√©es :

```python
class ProcessorFactory:
    """Êï∞ÊçÆÂ§ÑÁêÜÂô®Â∑•ÂéÇ"""
    
    @staticmethod
    def create_processor(data_type: str):
        if data_type == "airway":
            return AirwayProcessor()
        elif data_type == "pdf":
            return PDFProcessor()
        elif data_type == "terminal":
            return TerminalProcessor()
        elif data_type == "cifp":
            return CIFPProcessor()
        else:
            raise ValueError(f"Unknown processor type: {data_type}")

# Exemple d'utilisation
processor = ProcessorFactory.create_processor("airway")
result = processor.process(input_data)
```

### 2. Mod√®le de strat√©gie (Strategy Pattern)
Utilis√© pour impl√©menter diff√©rentes strat√©gies de conversion de donn√©es :

```python
class ConversionStrategy:
    """ËΩ¨Êç¢Á≠ñÁï•Êé•Âè£"""
    def convert(self, data): pass

class CSVToDAT(ConversionStrategy):
    """CSV Âà∞ DAT ËΩ¨Êç¢Á≠ñÁï•"""
    def convert(self, csv_data):
        # Logique de conversion CSV
        pass

class PDFToText(ConversionStrategy):
    """PDF Âà∞ÊñáÊú¨ËΩ¨Êç¢Á≠ñÁï•"""
    def convert(self, pdf_data):
        # Logique de conversion PDF
        pass

class DataConverter:
    """Êï∞ÊçÆËΩ¨Êç¢Âô®"""
    def __init__(self, strategy: ConversionStrategy):
        self.strategy = strategy
    
    def convert(self, data):
        return self.strategy.convert(data)
```

### 3. Mod√®le d'observateur (Observer Pattern)
Utilis√© pour surveiller la progression du traitement :

```python
class ProgressObserver:
    """ËøõÂ∫¶ËßÇÂØüËÄÖÊé•Âè£"""
    def update(self, progress: float, message: str): pass

class ConsoleProgressObserver(ProgressObserver):
    """ÊéßÂà∂Âè∞ËøõÂ∫¶ÊòæÁ§∫"""
    def update(self, progress: float, message: str):
        print(f"Progress: {progress:.1%} - {message}")

class TqdmProgressObserver(ProgressObserver):
    """tqdm ËøõÂ∫¶Êù°ÊòæÁ§∫"""
    def __init__(self):
        self.pbar = None
    
    def update(self, progress: float, message: str):
        if self.pbar:
            self.pbar.set_description(message)
            self.pbar.update()

class DataProcessor:
    """Êï∞ÊçÆÂ§ÑÁêÜÂô®Âü∫Á±ª"""
    def __init__(self):
        self.observers = []
    
    def add_observer(self, observer: ProgressObserver):
        self.observers.append(observer)
    
    def notify_progress(self, progress: float, message: str):
        for observer in self.observers:
            observer.update(progress, message)
```

### 4. Mod√®le de cha√Æne de responsabilit√© (Chain of Responsibility)
Utilis√© pour impl√©menter une cha√Æne de validation de donn√©es :

```python
class ValidationHandler:
    """È™åËØÅÂ§ÑÁêÜÂô®Êé•Âè£"""
    def __init__(self):
        self.next_handler = None
    
    def set_next(self, handler):
        self.next_handler = handler
        return handler
    
    def handle(self, data):
        result = self.validate(data)
        if result and self.next_handler:
            return self.next_handler.handle(data)
        return result
    
    def validate(self, data):
        pass

class FormatValidator(ValidationHandler):
    """Ê†ºÂºèÈ™åËØÅÂô®"""
    def validate(self, data):
        # Logique de validation du format
        return True

class RangeValidator(ValidationHandler):
    """ËåÉÂõ¥È™åËØÅÂô®"""
    def validate(self, data):
        # Logique de validation de la port√©e
        return True

class IntegrityValidator(ValidationHandler):
    """ÂÆåÊï¥ÊÄßÈ™åËØÅÂô®"""
    def validate(self, data):
        # Logique de validation de l'int√©grit√©
        return True

# Construction de la cha√Æne de validation
format_validator = FormatValidator()
range_validator = RangeValidator()
integrity_validator = IntegrityValidator()

format_validator.set_next(range_validator).set_next(integrity_validator)

# Utilisation de la cha√Æne de validation
is_valid = format_validator.handle(input_data)
```

## üìä Architecture de Performance

### Strat√©gies de gestion de la m√©moire

```mermaid
graph TD
    A[Entr√©e de fichier volumineux] --> B{Taille du fichier}
    B -->|Inf√©rieur au seuil| C[Chargement direct]
    B -->|D√©passe le seuil| D[Traitement en flux]
    
    C --> E[Traitement en m√©moire]
    D --> F[Lecture par blocs]
    F --> G[Traitement par lots]
    G --> H[Sortie incr√©mentielle]
    
    E --> I[Collecte des d√©chets]
    H --> I
    I --> J[Lib√©ration de m√©moire]
```

**Strat√©gies d'optimisation de la m√©moire :**
```python
import gc
from typing import Iterator, List

class MemoryEfficientProcessor:
    """ÂÜÖÂ≠òÈ´òÊïàÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂô®"""
    
    def __init__(self, chunk_size: int = 1000):
        self.chunk_size = chunk_size
    
    def process_large_file(self, file_path: str) -> Iterator[List]:
        """ÂàÜÂùóÂ§ÑÁêÜÂ§ßÊñá‰ª∂"""
        chunk = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                chunk.append(line.strip())
                
                if len(chunk) >= self.chunk_size:
                    yield self.process_chunk(chunk)
                    chunk.clear()
                    gc.collect()  # Force la collecte des d√©chets
            
            if chunk:  # Traite les donn√©es restantes
                yield self.process_chunk(chunk)
    
    def process_chunk(self, chunk: List[str]) -> List[str]:
        """Â§ÑÁêÜÂçï‰∏™Êï∞ÊçÆÂùó"""
        # Logique de traitement des donn√©es
        return [self.process_line(line) for line in chunk]
    
    def process_line(self, line: str) -> str:
        """Â§ÑÁêÜÂçïË°åÊï∞ÊçÆ"""
        # Logique de traitement sp√©cifique
        return line
```

### Architecture de traitement concurrent

```python
import concurrent.futures
from multiprocessing import Pool
import threading

class ConcurrentProcessor:
    """Âπ∂ÂèëÊï∞ÊçÆÂ§ÑÁêÜÂô®"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
    
    def process_files_threaded(self, file_list: List[str]) -> List:
        """Â§öÁ∫øÁ®ãÂ§ÑÁêÜÊñá‰ª∂ÂàóË°®"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Soumettre les t√¢ches
            future_to_file = {
                executor.submit(self.process_single_file, file): file 
                for file in file_list
            }
            
            results = []
            for future in concurrent.futures.as_completed(future_to_file):
                file = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as exc:
                    print(f'File {file} generated an exception: {exc}')
            
            return results
    
    def process_files_multiprocess(self, file_list: List[str]) -> List:
        """Â§öËøõÁ®ãÂ§ÑÁêÜÊñá‰ª∂ÂàóË°®"""
        with Pool(processes=self.max_workers) as pool:
            results = pool.map(self.process_single_file, file_list)
        return results
    
    def process_single_file(self, file_path: str):
        """Â§ÑÁêÜÂçï‰∏™Êñá‰ª∂"""
        # Logique de traitement de fichier
        pass
```

### Architecture de cache

```python
import functools
import hashlib
import pickle
from pathlib import Path

class CacheManager:
    """ÁºìÂ≠òÁÆ°ÁêÜÂô®"""
    
    def __init__(self, cache_dir: str = "cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, *args, **kwargs) -> str:
        """ÁîüÊàêÁºìÂ≠òÈîÆ"""
        content = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(content.encode()).hexdigest()
    
    def get(self, key: str):
        """Ëé∑ÂèñÁºìÂ≠ò"""
        cache_file = self.cache_dir / f"{key}.cache"
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def set(self, key: str, value):
        """ËÆæÁΩÆÁºìÂ≠ò"""
        cache_file = self.cache_dir / f"{key}.cache"
        with open(cache_file, 'wb') as f:
            pickle.dump(value, f)
    
    def cached(self, ttl: int = 3600):
        """ÁºìÂ≠òË£ÖÈ•∞Âô®"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                cache_key = self.get_cache_key(func.__name__, *args, **kwargs)
                result = self.get(cache_key)
                
                if result is None:
                    result = func(*args, **kwargs)
                    self.set(cache_key, result)
                
                return result
            return wrapper
        return decorator

# Exemple d'utilisation
cache_manager = CacheManager()

@cache_manager.cached(ttl=3600)
def expensive_processing(data):
    """ËÄóÊó∂ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂáΩÊï∞"""
    # Logique de traitement complexe
    return processed_data
```

## üîí Architecture de S√©curit√©

### Couche de validation des entr√©es

```python
import re
from pathlib import Path
from typing import Any, Dict

class InputValidator:
    """ËæìÂÖ•È™åËØÅÂô®"""
    
    # Extensions de fichiers s√©curis√©es
    SAFE_EXTENSIONS = {'.csv', '.dat', '.txt', '.pdf'}
    
    # Mod√®le de restriction de chemin
    SAFE_PATH_PATTERN = re.compile(r'^[a-zA-Z0-9._/\-\s]+$')
    
    @classmethod
    def validate_file_path(cls, file_path: str) -> bool:
        """È™åËØÅÊñá‰ª∂Ë∑ØÂæÑÂÆâÂÖ®ÊÄß"""
        path = Path(file_path)
        
        # V√©rifier l'extension du fichier
        if path.suffix.lower() not in cls.SAFE_EXTENSIONS:
            raise ValueError(f"Unsafe file extension: {path.suffix}")
        
        # V√©rifier les caract√®res du chemin
        if not cls.SAFE_PATH_PATTERN.match(file_path):
            raise ValueError(f"Unsafe characters in path: {file_path}")
        
        # V√©rifier les attaques par travers√©e de chemin
        if '..' in file_path or file_path.startswith('/'):
            raise ValueError(f"Path traversal detected: {file_path}")
        
        return True
    
    @classmethod
    def validate_coordinate(cls, lat: float, lon: float) -> bool:
        """È™åËØÅÂùêÊ†áËåÉÂõ¥"""
        if not (-90 <= lat <= 90):
            raise ValueError(f"Invalid latitude: {lat}")
        
        if not (-180 <= lon <= 180):
            raise ValueError(f"Invalid longitude: {lon}")
        
        return True
    
    @classmethod
    def sanitize_string(cls, input_str: str) -> str:
        """Ê∏ÖÁêÜËæìÂÖ•Â≠óÁ¨¶‰∏≤"""
        # Supprimer les caract√®res potentiellement dangereux
        sanitized = re.sub(r'[<>"\';\\]', '', input_str)
        # Limiter la longueur
        return sanitized[:1000]
```

### Architecture de gestion des erreurs

```python
import logging
from enum import Enum
from typing import Optional

class ErrorLevel(Enum):
    """ÈîôËØØÁ∫ßÂà´"""
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class NavDataError(Exception):
    """Nav-data Ëá™ÂÆö‰πâÂºÇÂ∏∏Âü∫Á±ª"""
    def __init__(self, message: str, error_code: str = None, level: ErrorLevel = ErrorLevel.ERROR):
        super().__init__(message)
        self.message = message
        self.error_code = error_code
        self.level = level

class FileProcessingError(NavDataError):
    """Êñá‰ª∂Â§ÑÁêÜÂºÇÂ∏∏"""
    pass

class DataValidationError(NavDataError):
    """Êï∞ÊçÆÈ™åËØÅÂºÇÂ∏∏"""
    pass

class ErrorHandler:
    """ÈîôËØØÂ§ÑÁêÜÂô®"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def handle_error(self, error: Exception, context: Optional[Dict] = None):
        """Â§ÑÁêÜÂºÇÂ∏∏"""
        if isinstance(error, NavDataError):
            self.handle_nav_data_error(error, context)
        else:
            self.handle_unexpected_error(error, context)
    
    def handle_nav_data_error(self, error: NavDataError, context: Optional[Dict] = None):
        """Â§ÑÁêÜËá™ÂÆö‰πâÂºÇÂ∏∏"""
        log_message = f"[{error.error_code}] {error.message}"
        if context:
            log_message += f" Context: {context}"
        
        if error.level == ErrorLevel.WARNING:
            self.logger.warning(log_message)
        elif error.level == ErrorLevel.ERROR:
            self.logger.error(log_message)
        elif error.level == ErrorLevel.CRITICAL:
            self.logger.critical(log_message)
            # Peut n√©cessiter l'arr√™t de l'ex√©cution du programme
    
    def handle_unexpected_error(self, error: Exception, context: Optional[Dict] = None):
        """Â§ÑÁêÜÊú™È¢ÑÊúüÁöÑÂºÇÂ∏∏"""
        log_message = f"Unexpected error: {str(error)}"
        if context:
            log_message += f" Context: {context}"
        
        self.logger.error(log_message, exc_info=True)
```

## üß™ Architecture de Test

### Strat√©gie de test

```mermaid
graph TD
    A[Pyramide de tests] --> B[Tests unitaires]
    A --> C[Tests d'int√©gration]
    A --> D[Tests de bout en bout]
    
    B --> B1[Tests de fonctions]
    B --> B2[Tests de classes]
    B --> B3[Tests de modules]
    
    C --> C1[Interaction inter-modules]
    C --> C2[Tests de flux de donn√©es]
    C --> C3[Tests d'API]
    
    D --> D1[Tests de processus complet]
    D --> D2[Tests de sc√©narios utilisateur]
    D --> D3[Tests de performance]
```

### Code du framework de test

```python
import pytest
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch

class TestDataFixtures:
    """ÊµãËØïÊï∞ÊçÆË£ÖÁΩÆ"""
    
    @pytest.fixture
    def sample_csv_data(self):
        """Exemple de donn√©es CSV"""
        return """CODE_POINT_START,CODE_TYPE_START,CODE_POINT_END,CODE_TYPE_END,CODE_DIR,TXT_DESIG
ABCDE,DESIGNATED_POINT,FGHIJ,VOR/DME,N,A123
KLMNO,NDB,PQRST,DESIGNATED_POINT,N,B456"""
    
    @pytest.fixture
    def temp_directory(self):
        """R√©pertoire temporaire"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield Path(temp_dir)
    
    @pytest.fixture
    def mock_earth_fix_data(self):
        """Donn√©es earth_fix simul√©es"""
        return {
            'ABCDE': 'ZB',
            'PQRST': 'ZG'
        }
    
    @pytest.fixture
    def mock_earth_nav_data(self):
        """Donn√©es earth_nav simul√©es"""
        return {
            'FGHIJ': 'ZG',
            'KLMNO': 'ZB'
        }

class TestAirwayModule(TestDataFixtures):
    """Tests du module Airway"""
    
    def test_navigation_type_enum(self):
        """Tester l'√©num√©ration du type de navigation"""
        from Airway.airway import NavigationType
        
        assert NavigationType.DESIGNATED_POINT.type_code == '11'
        assert NavigationType.VORDME.type_code == '3'
        assert NavigationType.NDB.type_code == '2'
    
    def test_process_navigation_point(self, mock_earth_fix_data, mock_earth_nav_data):
        """Tester le traitement des points de navigation"""
        # Tester le traitement des points d√©sign√©s
        from Airway.airway import process_navigation_point
        
        result = process_navigation_point(
            'ABCDE', 'DESIGNATED_POINT', 
            mock_earth_fix_data, mock_earth_nav_data
        )
        
        assert result is not None
        assert result.identifier == 'ABCDE'
        assert result.area_code == 'ZB'
    
    @patch('Airway.airway.load_fixed_width_data')
    @patch('pandas.read_csv')
    def test_csv_to_dat_conversion(self, mock_read_csv, mock_load_data, 
                                 sample_csv_data, temp_directory):
        """Tester la conversion CSV vers DAT"""
        # Configurer les donn√©es simul√©es
        mock_df = Mock()
        mock_read_csv.return_value = mock_df
        mock_load_data.return_value = {'ABCDE': 'ZB'}
        
        # Cr√©er un fichier temporaire
        csv_file = temp_directory / "test.csv"
        csv_file.write_text(sample_csv_data)
        
        # Tester la fonction de conversion
        from Airway.airway import convert_csv_to_dat
        
        # Ceci doit √™tre ajust√© en fonction de la signature de fonction r√©elle
        # convert_csv_to_dat(str(csv_file), ...)
        
        # V√©rifier le r√©sultat
        assert True  # Assert en fonction du r√©sultat r√©el

class TestPDFModule(TestDataFixtures):
    """Tests du module PDF"""
    
    @patch('pdfplumber.open')
    def test_pdf_extraction(self, mock_pdf_open):
        """Tester la fonction d'extraction PDF"""
        # Configurer le PDF simul√©
        mock_pdf = Mock()
        mock_page = Mock()
        mock_page.extract_text_lines.return_value = [
            {'text': 'ZBAA N39¬∞48\'35.6" E116¬∞34\'46.7"'}
        ]
        mock_pdf.pages = [mock_page]
        mock_pdf_open.return_value.__enter__.return_value = mock_pdf
        
        # Tester la fonction d'extraction
        import sys
        sys.path.append('PDF extract')
        from waypoint_1_pdf import extract
        
        result = extract(mock_pdf)
        assert len(result) > 0
```

## üìà Architecture de Surveillance et de Journalisation

### Conception du syst√®me de journalisation

```python
import logging
import logging.handlers
from enum import Enum
from pathlib import Path

class LogLevel(Enum):
    """Êó•ÂøóÁ∫ßÂà´"""
    DEBUG = logging.DEBUG
    INFO = logging.INFO
    WARNING = logging.WARNING
    ERROR = logging.ERROR
    CRITICAL = logging.CRITICAL

class StructuredLogger:
    """ÁªìÊûÑÂåñÊó•ÂøóÂô®"""
    
    def __init__(self, name: str, log_dir: str = "logs"):
        self.logger = logging.getLogger(name)
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.setup_handlers()
    
    def setup_handlers(self):
        """Configurer les gestionnaires de journalisation"""
        # Gestionnaire de console
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        
        # Gestionnaire de fichiers (rotation par date)
        file_handler = logging.handlers.TimedRotatingFileHandler(
            filename=self.log_dir / 'nav-data.log',
            when='midnight',
            interval=1,
            backupCount=30,
            encoding='utf-8'
        )
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # Gestionnaire de fichiers d'erreurs
        error_handler = logging.FileHandler(
            filename=self.log_dir / 'errors.log',
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(file_formatter)
        
        # Ajouter les gestionnaires
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(error_handler)
        
        self.logger.setLevel(logging.INFO)
    
    def log_with_context(self, level: LogLevel, message: str, **context):
        """Journalisation avec contexte"""
        if context:
            message = f"{message} | Context: {context}"
        
        self.logger.log(level.value, message)
    
    def log_performance(self, operation: str, duration: float, **metrics):
        """Journal de performance"""
        perf_message = f"Performance | Operation: {operation} | Duration: {duration:.3f}s"
        if metrics:
            perf_message += f" | Metrics: {metrics}"
        
        self.logger.info(perf_message)
```

### Surveillance des performances

```python
import time
import psutil
from contextlib import contextmanager
from typing import Dict, Any

class PerformanceMonitor:
    """ÊÄßËÉΩÁõëÊéßÂô®"""
    
    def __init__(self, logger: StructuredLogger):
        self.logger = logger
        self.metrics = {}
    
    @contextmanager
    def measure_time(self, operation_name: str):
        """Mesurer la dur√©e de l'op√©ration"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            duration = end_time - start_time
            memory_delta = end_memory - start_memory
            
            self.logger.log_performance(
                operation=operation_name,
                duration=duration,
                memory_start=start_memory,
                memory_end=end_memory,
                memory_delta=memory_delta
            )
    
    def collect_system_metrics(self) -> Dict[str, Any]:
        """Collecter les m√©triques syst√®me"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'process_memory': psutil.Process().memory_info().rss / 1024 / 1024
        }

# Exemple d'utilisation
logger = StructuredLogger("nav-data")
monitor = PerformanceMonitor(logger)

with monitor.measure_time("csv_processing"):
    # Ex√©cuter l'op√©ration de traitement CSV
    process_csv_file("large_file.csv")

# Enregistrer les m√©triques syst√®me
system_metrics = monitor.collect_system_metrics()
logger.log_with_context(LogLevel.INFO, "System metrics collected", **system_metrics)
```

## üîÆ Architecture d'Extension

### Conception du syst√®me de plugins

```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import importlib
import os

class Plugin(ABC):
    """Êèí‰ª∂Êé•Âè£"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Nom du plugin"""
        pass
    
    @property
    @abstractmethod
    def version(self) -> str:
        """Version du plugin"""
        pass
    
    @abstractmethod
    def initialize(self, config: Dict[str, Any]):
        """Initialiser le plugin"""
        pass
    
    @abstractmethod
    def process(self, data: Any) -> Any:
        """Traiter les donn√©es"""
        pass
    
    @abstractmethod
    def cleanup(self):
        """Nettoyer les ressources"""
        pass

class PluginManager:
    """Êèí‰ª∂ÁÆ°ÁêÜÂô®"""
    
    def __init__(self, plugin_dir: str = "plugins"):
        self.plugin_dir = plugin_dir
        self.plugins: Dict[str, Plugin] = {}
    
    def load_plugins(self):
        """Charger tous les plugins"""
        if not os.path.exists(self.plugin_dir):
            return
        
        for filename in os.listdir(self.plugin_dir):
            if filename.endswith('.py') and not filename.startswith('__'):
                module_name = filename[:-3]
                try:
                    module = importlib.import_module(f"{self.plugin_dir}.{module_name}")
                    plugin_class = getattr(module, 'Plugin', None)
                    
                    if plugin_class and issubclass(plugin_class, Plugin):
                        plugin = plugin_class()
                        self.plugins[plugin.name] = plugin
                        print(f"Loaded plugin: {plugin.name} v{plugin.version}")
                
                except Exception as e:
                    print(f"Failed to load plugin {module_name}: {e}")
    
    def get_plugin(self, name: str) -> Plugin:
        """Obtenir un plugin"""
        return self.plugins.get(name)
    
    def list_plugins(self) -> List[str]:
        """Lister tous les plugins"""
        return list(self.plugins.keys())
    
    def execute_plugin(self, name: str, data: Any, config: Dict[str, Any] = None) -> Any:
        """Ex√©cuter un plugin"""
        plugin = self.get_plugin(name)
        if not plugin:
            raise ValueError(f"Plugin not found: {name}")
        
        try:
            if config:
                plugin.initialize(config)
            
            result = plugin.process(data)
            plugin.cleanup()
            return result
        
        except Exception as e:
            plugin.cleanup()
            raise e

# Exemple d'impl√©mentation de plugin
class CustomDataProcessor(Plugin):
    """Plugin de traitement de donn√©es personnalis√©"""
    
    @property
    def name(self) -> str:
        return "custom_processor"
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    def initialize(self, config: Dict[str, Any]):
        self.config = config
    
    def process(self, data: Any) -> Any:
        # Logique de traitement personnalis√©e
        return processed_data
    
    def cleanup(self):
        # Nettoyer les ressources
        pass
```

---

**R√©sum√©** : Nav-data adopte une conception architecturale modulaire et stratifi√©e, garantissant la maintenabilit√©, l'extensibilit√© et la performance du syst√®me. Gr√¢ce √† l'application judicieuse de mod√®les de conception, √† un m√©canisme complet de gestion des erreurs et √† un syst√®me de surveillance, il fournit aux utilisateurs un service stable et fiable de conversion de donn√©es de navigation a√©rienne. ‚úàÔ∏è