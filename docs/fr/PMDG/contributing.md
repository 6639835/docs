# ü§ù Guide de contribution

Bienvenue dans le d√©veloppement du projet Nav-data ! Ce guide vous aidera √† comprendre comment contribuer au projet, y compris les standards de code, le processus de d√©veloppement et les meilleures pratiques.

## üéØ Comment contribuer

### Nous accueillons les types de contributions suivants :

- **üêõ Signalement et correction de bugs** - D√©tecter et corriger les probl√®mes dans le projet
- **‚ú® D√©veloppement de nouvelles fonctionnalit√©s** - Ajouter de nouvelles fonctionnalit√©s ou optimisations de traitement de donn√©es
- **üìö Am√©lioration de la documentation** - Compl√©ter la documentation, ajouter des exemples, corriger des erreurs
- **üîß Optimisation des performances** - Am√©liorer l'efficacit√© du traitement des donn√©es et l'utilisation de la m√©moire
- **üß™ Cas de test** - Augmenter la couverture des tests, am√©liorer la qualit√© du code
- **üåç Prise en charge de l'internationalisation** - Ajouter la prise en charge multilingue ou des donn√©es r√©gionales suppl√©mentaires
- **üé® Am√©lioration de l'exp√©rience utilisateur** - Optimiser la convivialit√© de l'outil et le format de sortie

## üöÄ D√©marrage rapide

### 1. Pr√©paration de l'environnement

```bash
# Forker le projet sur votre compte GitHub
# Cloner votre fork
git clone https://github.com/[votre_nom_utilisateur]/Nav-data.git
cd Nav-data

# Ajouter le d√©p√¥t en amont
git remote add upstream https://github.com/Âéü‰ΩúËÄÖ/Nav-data.git

# Cr√©er un environnement virtuel
python -m venv nav-data-dev
source nav-data-dev/bin/activate  # Linux/macOS
# Ou nav-data-dev\Scripts\activate  # Windows

# Installer les d√©pendances de d√©veloppement
pip install -r requirements.txt
pip install -r requirements-dev.txt  # D√©pendances de d√©veloppement (si elles existent)
```

### 2. Validation de l'environnement de d√©veloppement

```bash
# Ex√©cuter les tests de base
python -m pytest tests/ -v

# V√©rifier le style du code
flake8 *.py

# Ex√©cuter la v√©rification de type (si utilis√©e)
mypy *.py
```

## üìã Conventions de d√©veloppement

### Style de code

Nous suivons les standards et les meilleures pratiques de la communaut√© Python :

#### 1. Style de code PEP 8

```python
# ‚úÖ Bon exemple
class AirportDataProcessor:
    """Processeur de donn√©es d'a√©roport
    
    Traite les donn√©es d'a√©roport au format NAIP et les convertit en un format compatible PMDG.
    """
    
    def __init__(self, csv_file_path: str, output_db_path: str):
        self.csv_file_path = csv_file_path
        self.output_db_path = output_db_path
        self.processed_count = 0
    
    def process_airport_data(self) -> ProcessingResult:
        """M√©thode principale pour traiter les donn√©es d'a√©roport
        
        Returns:
            ProcessingResult: Un objet de r√©sultat contenant des statistiques de traitement
            
        Raises:
            FileNotFoundError: Lorsque le fichier d'entr√©e n'existe pas
            DatabaseError: Lorsque l'op√©ration de base de donn√©es √©choue
        """
        try:
            data = self._load_csv_data()
            processed_data = self._transform_data(data)
            self._save_to_database(processed_data)
            
            return ProcessingResult(
                success=True,
                processed_count=self.processed_count,
                message="Traitement des donn√©es d'a√©roport termin√©"
            )
        except Exception as e:
            logging.error(f"Erreur lors du traitement des donn√©es d'a√©roport : {e}")
            raise

# ‚ùå √âcriture √† √©viter
def processAirports(file,db):  # Nom de fonction non conforme, types de param√®tres non clairs
    d=pd.read_csv(file)       # Noms de variables non clairs
    for i in d.iterrows():    # Pas de gestion d'erreurs
        # Logique de traitement...
        pass
```

#### 2. Annotations de type

```python
from typing import List, Dict, Optional, Union, Tuple
from dataclasses import dataclass

@dataclass
class ProcessingResult:
    """Classe de donn√©es de r√©sultat de traitement"""
    success: bool
    processed_count: int
    failed_count: int = 0
    errors: List[str] = None
    message: Optional[str] = None

def convert_coordinates(
    dms_latitude: str, 
    dms_longitude: str
) -> Tuple[Optional[float], Optional[float]]:
    """Convertit les coordonn√©es au format DMS en degr√©s d√©cimaux
    
    Args:
        dms_latitude: Cha√Æne de caract√®res de latitude au format DMS (ex: N390308.00)
        dms_longitude: Cha√Æne de caract√®res de longitude au format DMS (ex: E1162930.00)
    
    Returns:
        Un tuple (latitude, longitude), ou (None, None) si la conversion √©choue
    """
    try:
        lat = parse_dms_coordinate(dms_latitude, coord_type='latitude')
        lon = parse_dms_coordinate(dms_longitude, coord_type='longitude')
        return lat, lon
    except ValueError as e:
        logging.warning(f"√âchec de la conversion des coordonn√©es : {e}")
        return None, None
```

#### 3. Gestion des erreurs et journalisation

```python
import logging
from enum import Enum

class ProcessingError(Exception):
    """Classe de base pour les erreurs li√©es au traitement des donn√©es"""
    pass

class ValidationError(ProcessingError):
    """Erreur de validation des donn√©es"""
    pass

class CoordinateError(ValidationError):
    """Erreur li√©e aux coordonn√©es"""
    pass

def process_with_error_handling(data: Dict) -> bool:
    """Exemple de traitement de donn√©es avec gestion compl√®te des erreurs"""
    try:
        # Validation des donn√©es
        if not validate_required_fields(data):
            raise ValidationError("Champs obligatoires manquants")
        
        # Traitement des coordonn√©es
        lat, lon = convert_coordinates(
            data.get('latitude'),
            data.get('longitude')
        )
        
        if lat is None or lon is None:
            raise CoordinateError("√âchec de la conversion des coordonn√©es")
        
        # Sauvegarde des donn√©es
        save_to_database(data)
        logging.info(f"Enregistrement trait√© avec succ√®s : {data.get('identifier')}")
        return True
        
    except ValidationError as e:
        logging.warning(f"√âchec de la validation des donn√©es : {e}")
        return False
    except CoordinateError as e:
        logging.error(f"Erreur de traitement des coordonn√©es : {e}")
        return False
    except Exception as e:
        logging.critical(f"Erreur inattendue : {e}")
        raise
```

### Standards de documentation

#### 1. Documentation de fonctions et de classes

```python
def parse_dat_file(
    file_path: str, 
    batch_size: int = 1000,
    encoding: str = 'utf-8'
) -> List[Dict[str, Any]]:
    """Analyse un fichier DAT au format X-Plane
    
    Cette fonction lit un fichier de donn√©es de navigation X-Plane, analyse les informations 
    de points de cheminement qu'il contient et retourne une liste de donn√©es structur√©es.
    Elle prend en charge le traitement par lots pour les grands fichiers.
    
    Args:
        file_path: Le chemin complet du fichier DAT
        batch_size: La taille du lot pour l'optimisation de la m√©moire, par d√©faut 1000
        encoding: L'encodage du fichier, par d√©faut utf-8
    
    Returns:
        Une liste de dictionnaires contenant les informations des points de cheminement,
        chaque dictionnaire contient les cl√©s suivantes :
        - waypoint_identifier: Identifiant du point de cheminement
        - latitude: Latitude (degr√©s d√©cimaux)
        - longitude: Longitude (degr√©s d√©cimaux)
        - waypoint_type: Type de point de cheminement
        - icao_code: Code r√©gional OACI
    
    Raises:
        FileNotFoundError: Lorsque le fichier sp√©cifi√© n'existe pas
        ValueError: Lorsque le format du fichier est incorrect
        MemoryError: Lorsque la m√©moire disponible est insuffisante
    
    Examples:
        Utilisation de base :
        >>> waypoints = parse_dat_file('data/earth_fix.dat')
        >>> print(f"Analys√© {len(waypoints)} points de cheminement")
        
        Traitement de grands fichiers :
        >>> waypoints = parse_dat_file(
        ...     'large_file.dat', 
        ...     batch_size=5000
        ... )
    
    Note:
        Cette fonction ignore automatiquement les lignes de commentaire en d√©but de fichier
        et ne traite que les lignes de donn√©es valides. Pour les lignes de donn√©es corrompues,
        un journal d'avertissement sera enregistr√© mais le traitement ne sera pas interrompu.
    """
    # Impl√©mentation...
```

#### 2. Documentation de module

```python
"""
Module de traitement des donn√©es d'a√©roport PMDG

Ce module est responsable du traitement des donn√©es d'a√©roport au format NAIP
et de leur conversion au format de base de donn√©es SQLite compatible PMDG.
Les fonctions principales incluent :

- Lecture et analyse de fichiers CSV
- Conversion de coordonn√©es au format DMS
- Recherche et correspondance de noms d'a√©roport
- Validation et nettoyage des donn√©es
- √âcriture dans la base de donn√©es SQLite

Formats de fichier d'entr√©e pris en charge :
- AD_HP.csv: Donn√©es d'a√©roport de base (format NAIP)
- Airport.dat: Table de recherche de noms d'a√©roport

Format de sortie :
- Base de donn√©es SQLite, contenant la table tbl_airports

Author: Nav-data Team
Version: 2.0.0
License: MIT

Examples:
    Utilisation en ligne de commande :
    $ python PMDG_APT.py
    
    Interface de programmation :
    >>> from PMDG_APT import AirportProcessor
    >>> processor = AirportProcessor(
    ...     csv_path='data/AD_HP.csv',
    ...     output_path='output/airports.s3db'
    ... )
    >>> result = processor.process()
    >>> print(f"Traitement termin√© : {result.processed_count} a√©roports")
"""

import pandas as pd
import sqlite3
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

# Constantes de niveau module
DEFAULT_AREA_CODE = 'EEU'
DEFAULT_ENCODING = 'latin1'
SUPPORTED_ICAO_REGIONS = {'ZB', 'ZG', 'ZS', 'ZJ', 'ZY', 'ZL', 'ZH', 'ZU', 'ZP', 'ZW'}

# ... Reste du code
```

### Standards de test

#### 1. Tests unitaires

```python
import unittest
from unittest.mock import patch, mock_open
import pandas as pd
from PMDG_APT import AirportProcessor, convert_dms_to_decimal

class TestCoordinateConversion(unittest.TestCase):
    """Test des fonctionnalit√©s de conversion de coordonn√©es"""
    
    def test_valid_north_latitude(self):
        """Teste la conversion d'une coordonn√©e de latitude nord valide"""
        result, error = convert_dms_to_decimal("N390308.00")
        self.assertIsNone(error)
        self.assertAlmostEqual(result, 39.0522222, places=6)
    
    def test_valid_east_longitude(self):
        """Teste la conversion d'une coordonn√©e de longitude est valide"""
        result, error = convert_dms_to_decimal("E1162930.00")
        self.assertIsNone(error)
        self.assertAlmostEqual(result, 116.4916667, places=6)
    
    def test_invalid_format(self):
        """Teste le format de coordonn√©e invalide"""
        result, error = convert_dms_to_decimal("INVALID")
        self.assertIsNone(result)
        self.assertIsNotNone(error)
        self.assertIn("Format DMS invalide", error)
    
    def test_boundary_coordinates(self):
        """Teste les coordonn√©es limites"""
        # Test du p√¥le Nord
        result, error = convert_dms_to_decimal("N900000.00")
        self.assertIsNone(error)
        self.assertEqual(result, 90.0)

class TestAirportProcessor(unittest.TestCase):
    """Test du processeur de donn√©es d'a√©roport"""
    
    def setUp(self):
        """Initialisation du test"""
        self.processor = AirportProcessor(
            csv_file_path="test_data/AD_HP.csv",
            lookup_file_path="test_data/Airport.dat",
            output_db_path="test_output/test.s3db"
        )
    
    @patch('pandas.read_csv')
    def test_csv_loading(self, mock_read_csv):
        """Teste le chargement du fichier CSV"""
        # Simuler les donn√©es CSV
        mock_data = pd.DataFrame({
            'CODE_ID': ['ZBAA', 'ZSPD'],
            'GEO_LAT_ACCURACY': ['N390308.00', 'N311133.00'],
            'GEO_LONG_ACCURACY': ['E1162930.00', 'E1211056.00']
        })
        mock_read_csv.return_value = mock_data
        
        result = self.processor._load_csv_data()
        self.assertEqual(len(result), 2)
        self.assertEqual(result.iloc[0]['CODE_ID'], 'ZBAA')
    
    @patch('sqlite3.connect')
    def test_database_creation(self, mock_connect):
        """Teste la cr√©ation de la base de donn√©es"""
        mock_connection = mock_connect.return_value
        mock_cursor = mock_connection.cursor.return_value
        
        self.processor._create_database_tables()
        
        # V√©rifier que le SQL de cr√©ation de table a √©t√© ex√©cut√©
        mock_cursor.execute.assert_called()
        create_table_calls = [call[0][0] for call in mock_cursor.execute.call_args_list]
        self.assertTrue(any('CREATE TABLE' in call for call in create_table_calls))
```

#### 2. Tests d'int√©gration

```python
import tempfile
import os
import sqlite3
from pathlib import Path

class TestIntegration(unittest.TestCase):
    """Tests d'int√©gration"""
    
    def setUp(self):
        """Cr√©e un environnement de test temporaire"""
        self.test_dir = tempfile.mkdtemp()
        self.csv_file = Path(self.test_dir) / "test_airports.csv"
        self.lookup_file = Path(self.test_dir) / "airports.dat"
        self.output_db = Path(self.test_dir) / "output.s3db"
        
        # Cr√©er les fichiers de donn√©es de test
        self.create_test_csv()
        self.create_test_lookup()
    
    def tearDown(self):
        """Nettoie l'environnement de test"""
        import shutil
        shutil.rmtree(self.test_dir)
    
    def create_test_csv(self):
        """Cr√©e un fichier CSV de test"""
        test_data = """CODE_ID,GEO_LAT_ACCURACY,GEO_LONG_ACCURACY
ZBAA,N390308.00,E1162930.00
ZSPD,N311133.00,E1211056.00"""
        
        with open(self.csv_file, 'w', encoding='latin1') as f:
            f.write(test_data)
    
    def create_test_lookup(self):
        """Cr√©e un fichier de recherche de test"""
        lookup_data = """ZBAA BEIJING/CAPITAL
ZSPD SHANGHAI/PUDONG INTL"""
        
        with open(self.lookup_file, 'w') as f:
            f.write(lookup_data)
    
    def test_end_to_end_processing(self):
        """Teste le traitement de bout en bout"""
        processor = AirportProcessor(
            csv_file_path=str(self.csv_file),
            lookup_file_path=str(self.lookup_file),
            output_db_path=str(self.output_db)
        )
        
        result = processor.process()
        
        # V√©rifier les r√©sultats du traitement
        self.assertTrue(result.success)
        self.assertEqual(result.processed_count, 2)
        
        # V√©rifier le contenu de la base de donn√©es
        self.assertTrue(self.output_db.exists())
        
        conn = sqlite3.connect(str(self.output_db))
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM tbl_airports")
        count = cursor.fetchone()[0]
        self.assertEqual(count, 2)
        
        cursor.execute("SELECT airport_identifier, airport_name FROM tbl_airports ORDER BY airport_identifier")
        airports = cursor.fetchall()
        
        self.assertEqual(airports[0][0], 'ZBAA')
        self.assertEqual(airports[0][1], 'BEIJING/CAPITAL')
        
        conn.close()
```

## üîÑ Processus de d√©veloppement

### Workflow Git

Nous utilisons le workflow **Git Flow** :

```bash
# 1. Cr√©er une branche de fonctionnalit√© √† partir de la derni√®re branche main
git checkout main
git pull upstream main
git checkout -b feature/optimisation-traitement-itineraires

# 2. Effectuer le travail de d√©veloppement
# √âcrire du code, ajouter des tests, mettre √† jour la documentation

# 3. Commiter les modifications
git add .
git commit -m "feat: Optimisation des performances du traitement des donn√©es d'itin√©raire

- Impl√©mentation du traitement par lots pour r√©duire l'utilisation de la m√©moire
- Ajout d'une barre de progression pour afficher l'√©tat du traitement
- Optimisation des op√©rations d'√©criture dans la base de donn√©es

Closes #123"

# 4. Pousser vers votre fork
git push origin feature/optimisation-traitement-itineraires

# 5. Cr√©er une Pull Request
```

### Convention des messages de commit

Nous utilisons la convention **Conventional Commits** :

```bash
# Format : <type>(<port√©e>) : <description>
#
# <Corps facultatif>
#
# <Pied de page facultatif>

# Exemple :
git commit -m "feat(airport): Ajout de la fonction de recherche automatique de noms d'a√©roport

Impl√©mentation de la recherche automatique de noms d'a√©roport bas√©e sur les codes OACI,
prenant en charge l'obtention d'informations de noms d'a√©roport √† partir de plusieurs sources de donn√©es.

- Ajout de la classe AirportNameResolver
- Prise en charge du cache pour am√©liorer les performances de recherche
- Ajout de tests unitaires correspondants

Closes #45"

# Description des types :
# feat : Nouvelle fonctionnalit√©
# fix : Correction de bug
# docs : Mise √† jour de la documentation
# style : Ajustement du formatage du code (n'affecte pas la fonctionnalit√©)
# refactor : Refactorisation du code
# perf : Optimisation des performances
# test : Ajout ou modification de tests
# chore : Modifications au processus de build ou aux outils auxiliaires
```

### Processus de Pull Request

#### 1. Liste de contr√¥le PR

Avant de soumettre une PR, assurez-vous que :

- [ ] Le code respecte les conventions de codage du projet
- [ ] Les cas de test n√©cessaires ont √©t√© ajout√©s
- [ ] Tous les tests ont r√©ussi
- [ ] La documentation pertinente a √©t√© mise √† jour
- [ ] Le message de commit est conforme √† la convention
- [ ] Aucune nouvelle d√©pendance n'a √©t√© introduite (si oui, veuillez le mentionner dans la PR)

#### 2. Mod√®le de PR

```markdown
## üìù Description du changement
D√©crivez bri√®vement ce que cette PR modifie.

## üîß Type de changement
- [ ] Correction de bug
- [ ] Nouvelle fonctionnalit√©
- [ ] Optimisation des performances
- [ ] Refactorisation du code
- [ ] Mise √† jour de la documentation
- [ ] Am√©lioration des tests

## üß™ Tests
D√©crivez comment ces changements ont √©t√© test√©s :
- [ ] Nouveaux tests unitaires ajout√©s
- [ ] Tests d'int√©gration ajout√©s
- [ ] √âtapes de test manuel :
  1. √âtape 1
  2. √âtape 2

## üì∏ Captures d'√©cran (si applicable)
Si des modifications de l'interface utilisateur ou du format de sortie sont pr√©sentes, veuillez ajouter des captures d'√©cran.

## üîó Issue(s) associ√©e(s)
Fixes #123
Related to #456

## üìã Liste de contr√¥le
- [ ] Mon code respecte les conventions de codage du projet
- [ ] J'ai auto-r√©vis√© mon code
- [ ] J'ai ajout√© les tests correspondants
- [ ] Tous les tests nouveaux et existants ont r√©ussi
- [ ] J'ai mis √† jour la documentation pertinente

## üí¨ Remarques suppl√©mentaires
Ajoutez toute autre information n√©cessaire.
```

## üêõ Signalement de probl√®mes

### Mod√®le de rapport de bug

Lorsque vous trouvez un probl√®me, veuillez utiliser le mod√®le suivant pour cr√©er une Issue :

```markdown
**üêõ Description du bug**
D√©crivez succinctement et clairement le probl√®me rencontr√©.

**üîÑ √âtapes de reproduction**
1. Allez √† '...'
2. Cliquez sur '...'
3. Faites d√©filer jusqu'√† '...'
4. Observez l'erreur

**‚úÖ Comportement attendu**
D√©crivez ce que vous vous attendez √† voir.

**üíª Informations sur l'environnement**
- Syst√®me d'exploitation : [par exemple Windows 10, macOS 11.6, Ubuntu 20.04]
- Version Python : [par exemple 3.9.7]
- Version Nav-data : [par exemple 2.1.0]
- Autres versions de logiciels pertinents :

**üìÑ Journaux d'erreurs**
Si applicable, veuillez ajouter les journaux d'erreurs ou des captures d'√©cran.

```
[Coller le contenu du journal ici]
```

**üìÅ Donn√©es d'entr√©e**
Si le probl√®me est li√© √† des donn√©es d'entr√©e sp√©cifiques, veuillez fournir des exemples de donn√©es (en supprimant les informations sensibles).

**üîç Informations suppl√©mentaires**
Ajoutez toute autre information susceptible d'aider √† diagnostiquer le probl√®me.
```

### Mod√®le de demande de fonctionnalit√©

```markdown
**üöÄ Description de la fonctionnalit√©**
D√©crivez succinctement et clairement la fonctionnalit√© que vous souhaitez ajouter.

**üí° Cas d'utilisation**
D√©crivez le probl√®me que cette fonctionnalit√© r√©sout ou le processus qu'elle am√©liore.

**üìã Besoins d√©taill√©s**
- [ ] Besoin 1 : Description
- [ ] Besoin 2 : Description
- [ ] Besoin 3 : Description

**üé® Solutions d'impl√©mentation possibles**
Si vous avez des id√©es d'impl√©mentation, veuillez les d√©crire bri√®vement.

**üìö R√©f√©rences**
Fournissez des liens vers des documents, des standards ou des r√©f√©rences pertinents.

**üìä Priorit√©**
- [ ] Basse - √Ä faire quand le temps le permet
- [ ] Moyenne - Important mais non urgent
- [ ] Haute - √Ä impl√©menter d√®s que possible
- [ ] Urgente - Bloque d'autres travaux

**üí¨ Remarques suppl√©mentaires**
Autres informations √† noter.
```

## üìö Configuration de l'environnement de d√©veloppement

### Suggestions de configuration IDE

#### Visual Studio Code

Extensions recommand√©es :
```json
{
    "recommendations": [
        "ms-python.python",
        "ms-python.flake8",
        "ms-python.pylint",
        "ms-python.black-formatter",
        "njpwerner.autodocstring",
        "ms-python.isort",
        "charliermarsh.ruff"
    ]
}
```

Param√®tres de l'espace de travail (`.vscode/settings.json`) :
```json
{
    "python.defaultInterpreterPath": "./nav-data-dev/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.linting.pylintEnabled": false,
    "python.formatting.provider": "black",
    "python.formatting.blackArgs": ["--line-length=88"],
    "python.sortImports.args": ["--profile", "black"],
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/*.pyc": true
    }
}
```

#### PyCharm

1. Configurer le style de code :
   - File ‚Üí Settings ‚Üí Editor ‚Üí Code Style ‚Üí Python
   - S√©lectionner le pr√©r√©glage "Black"

2. Configurer le lanceur de tests :
   - File ‚Üí Settings ‚Üí Tools ‚Üí Python Integrated Tools
   - Lanceur de tests par d√©faut : pytest

### Configuration des outils de d√©veloppement

#### Hooks pre-commit

Cr√©er `.pre-commit-config.yaml` :
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict
  
  - repo: https://github.com/psf/black
    rev: 22.12.0
    hooks:
      - id: black
        language_version: python3
  
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203]
  
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: [--profile=black]
```

Installer et activer :
```bash
pip install pre-commit
pre-commit install
```

## üèÜ Bonnes pratiques

### Optimisation des performances

1. **Gestion de la m√©moire**
   ```python
   # ‚úÖ Bonne pratique : Utiliser des g√©n√©rateurs pour traiter les grands fichiers
   def process_large_file(file_path):
       with open(file_path, 'r') as f:
           for line in f:
               yield process_line(line)
   
   # ‚ùå √Ä √©viter : Charger l'int√©gralit√© du fichier en m√©moire en une seule fois
   def process_large_file_bad(file_path):
       with open(file_path, 'r') as f:
           lines = f.readlines()  # Peut consommer beaucoup de m√©moire
       return [process_line(line) for line in lines]
   ```

2. **Optimisation des op√©rations de base de donn√©es**
   ```python
   # ‚úÖ Bonne pratique : Insertion par lots
   def insert_records_batch(connection, records, batch_size=1000):
       cursor = connection.cursor()
       for i in range(0, len(records), batch_size):
           batch = records[i:i + batch_size]
           cursor.executemany(
               "INSERT INTO table (col1, col2) VALUES (?, ?)", 
               batch
           )
           connection.commit()
   
   # ‚ùå √Ä √©viter : Insertion ligne par ligne
   def insert_records_one_by_one(connection, records):
       cursor = connection.cursor()
       for record in records:
           cursor.execute("INSERT INTO table (col1, col2) VALUES (?, ?)", record)
           connection.commit()  # Chaque commit affecte les performances
   ```

### Gestion des erreurs

```python
# ‚úÖ Bonne gestion des erreurs
def process_coordinate(dms_string: str) -> float:
    """Traite une cha√Æne de caract√®res de coordonn√©es et retourne une valeur d√©cimale"""
    try:
        return convert_dms_to_decimal(dms_string)
    except ValueError as e:
        logging.warning(f"Erreur de format de coordonn√©e : {dms_string}, Erreur : {e}")
        raise CoordinateError(f"Impossible d'analyser la coordonn√©e : {dms_string}") from e
    except Exception as e:
        logging.error(f"Erreur inconnue lors du traitement de la coordonn√©e : {e}")
        raise

# ‚ùå Gestion des erreurs √† √©viter
def process_coordinate_bad(dms_string):
    try:
        return convert_dms_to_decimal(dms_string)
    except:  # Capture toutes les exceptions, difficile √† d√©boguer
        return None  # Perte d'informations sur l'erreur
```

### R√©daction de tests

```python
# ‚úÖ Bons tests
class TestCoordinateProcessing(unittest.TestCase):
    def test_valid_north_latitude_conversion(self):
        """Teste la conversion d'une coordonn√©e de latitude nord valide"""
        # Given
        dms_input = "N390308.00"
        expected_decimal = 39.0522222
        
        # When
        result = convert_dms_to_decimal(dms_input)
        
        # Then
        self.assertAlmostEqual(result, expected_decimal, places=6)
    
    def test_invalid_format_raises_error(self):
        """Teste qu'un format invalide l√®ve une erreur appropri√©e"""
        # Given
        invalid_input = "INVALID_FORMAT"
        
        # When/Then
        with self.assertRaises(CoordinateError) as context:
            convert_dms_to_decimal(invalid_input)
        
        self.assertIn("Impossible d'analyser la coordonn√©e", str(context.exception))

# ‚ùå Tests √† √©viter
def test_coordinate():  # Nom de test non clair
    result = convert_dms_to_decimal("N390308.00")
    assert result == 39.0522222  # La comparaison exacte de flottants peut √©chouer
```

## üìû Obtenir de l'aide

Si vous rencontrez des probl√®mes pendant le processus de contribution :

1.  **Consultez la documentation** - V√©rifiez d'abord la documentation du projet et ce guide de contribution
2.  **Recherchez les Issues existantes** - V√©rifiez si quelqu'un a d√©j√† rencontr√© un probl√®me similaire
3.  **Participez aux discussions** - Posez des questions dans les discussions GitHub (GitHub Discussions)
4.  **Contactez les mainteneurs** - Contactez les mainteneurs du projet via les Issues GitHub

### Lignes directrices de la communaut√©

Nous nous engageons √† cr√©er un environnement communautaire ouvert et convivial :

-   **Respecter les autres** - Restez courtois et respectueux envers tous les participants
-   **Retour constructif** - Fournissez des commentaires et des suggestions utiles et constructifs
-   **Apprentissage patient** - Aidez les d√©butants √† apprendre, partagez vos connaissances et votre exp√©rience
-   **Esprit de collaboration** - Travaillez ensemble pour am√©liorer le projet

## üéâ Reconnaissance des contributeurs

Nous reconnaissons les contributeurs aux endroits suivants :
-   Section des contributeurs de README.md
-   Historique des mises √† jour de version dans CHANGELOG.md
-   Liste de remerciements des versions GitHub (GitHub Releases)

Merci d'avoir envisag√© de contribuer au projet Nav-data ! Chaque contribution rend ce projet meilleur.

---

**Rappelez-vous** : Le bon code est √©crit pour √™tre lu par des humains, les machines ne font que l'ex√©cuter.