# ğŸ› ï¸ TFDI ë‚´ë¹„ê²Œì´ì…˜ ë°ì´í„° ë³€í™˜ê¸° ë¬¸ì œ í•´ê²°

## ğŸš¨ ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²°ì±…

### 1. í™˜ê²½ ë° ì„¤ì¹˜ ë¬¸ì œ

#### âŒ Python í™˜ê²½ ë¬¸ì œ

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
ModuleNotFoundError: No module named 'rich'
ImportError: No module named 'pandas'
```

**í•´ê²°ì±…:**
```bash
# 1. Python ë²„ì „ í™•ì¸
python --version  # 3.8 ì´ìƒì¸ì§€ í™•ì¸

# 2. pip ì—…ê·¸ë ˆì´ë“œ
python -m pip install --upgrade pip

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 4. ì„¤ì¹˜ í™•ì¸
python -c "import rich, pandas; print('ì˜ì¡´ì„± ì„¤ì¹˜ ì„±ê³µ')"
```

#### âŒ ê¶Œí•œ ì˜¤ë¥˜

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
PermissionError: [Errno 13] Permission denied
ì¶œë ¥ ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
```

**í•´ê²°ì±…:**
```bash
# Windows - ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰
# ëª…ë ¹ í”„ë¡¬í”„íŠ¸ ìš°í´ë¦­ â†’ "ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰"

# macOS/Linux - sudo ì‚¬ìš© ë˜ëŠ” ê¶Œí•œ ë³€ê²½
sudo python converter.py
# ë˜ëŠ”
chmod 755 /path/to/output/directory
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ë¬¸ì œ

#### âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì—†ìŒ

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
FileNotFoundError: [Errno 2] No such file or directory: 'nd.db3'
Fenix ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
```

**í•´ê²°ì±…:**
1.  **Fenix ì„¤ì¹˜ í™•ì¸**:
    ```bash
    # ì¼ë°˜ì ì¸ ê²½ë¡œ
    %APPDATA%\Microsoft Flight Simulator\Packages\fenix-a320\
    ```

2.  **íŒŒì¼ ìˆ˜ë™ ì°¾ê¸°**:
    ```bash
    # Windows
    dir /s nd.db3
    
    # macOS/Linux
    find ~ -name "nd.db3" 2>/dev/null
    ```

3.  **ë°ì´í„°ë² ì´ìŠ¤ ì¬ìƒì„±**:
    -   MSFS ì‹œì‘
    -   Fenix A320 ë¡œë“œ
    -   ë‚´ë¹„ê²Œì´ì…˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°

#### âŒ ë°ì´í„°ë² ì´ìŠ¤ ì†ìƒ

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
sqlite3.DatabaseError: database disk image is malformed
ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
```

**ì§„ë‹¨ ë°©ë²•:**
```python
import sqlite3

def check_database_integrity(db_path):
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("PRAGMA integrity_check")
        result = cursor.fetchone()
        if result[0] == "ok":
            print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ì •ìƒ")
        else:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì†ìƒ: {result[0]}")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ: {e}")
    finally:
        conn.close()
```

**ë³µêµ¬ ë°©ì•ˆ:**
```bash
# 1. ì†ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
cp nd.db3 nd.db3.backup

# 2. SQLite ë³µêµ¬ ì‹œë„
sqlite3 nd.db3 ".dump" | sqlite3 nd_repaired.db3

# 3. ë³µêµ¬ ì‹¤íŒ¨ ì‹œ, ë°ì´í„°ë² ì´ìŠ¤ ì¬íšë“
# íŒŒì¼ ì‚­ì œ í›„ Fenix ì¬ì‹œì‘
```

#### âŒ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” êµ¬ì¡° ë¹„í˜¸í™˜

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
sqlite3.OperationalError: no such table: Terminals
ë°ì´í„°ë² ì´ìŠ¤ì— í•„ìˆ˜ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.
```

**ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸:**
```python
def validate_database_schema(db_path):
    required_tables = [
        'Airports', 'Runways', 'Waypoints', 'Navaids',
        'Airways', 'AirwayLegs', 'Terminals', 'TerminalLegs',
        'ILSes', 'AirportLookup', 'NavaidLookup', 'WaypointLookup'
    ]
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    existing_tables = {row[0] for row in cursor.fetchall()}
    
    missing_tables = set(required_tables) - existing_tables
    if missing_tables:
        print(f"âŒ ëˆ„ë½ëœ í…Œì´ë¸”: {missing_tables}")
        return False
    
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ê²€ì¦ í†µê³¼")
    return True
```

### 3. ë©”ëª¨ë¦¬ ë° ì„±ëŠ¥ ë¬¸ì œ

#### âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
MemoryError: Unable to allocate array
ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
```

**ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§:**
```python
import psutil
import gc

def monitor_memory_usage():
    memory = psutil.virtual_memory()
    print(f"ì´ ë©”ëª¨ë¦¬: {memory.total // 1024**3} GB")
    print(f"ì‚¬ìš©ëœ ë©”ëª¨ë¦¬: {memory.used // 1024**3} GB")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {memory.available // 1024**3} GB")
    print(f"ì‚¬ìš©ë¥ : {memory.percent}%")

def optimize_memory():
    # ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    gc.collect()
    
    # pandas ìºì‹œ ì •ë¦¬
    import pandas as pd
    pd.reset_option('all')
```

**í•´ê²°ì±…:**
```python
# 1. ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° ê°ì†Œ
config = ConverterConfig(
    batch_size=500,  # ê¸°ë³¸ 1000ì—ì„œ ê°ì†Œ
    coordinate_precision=6  # ì •ë°€ë„ ë‚®ì¶”ê¸°
)

# 2. ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
def process_large_table_streaming(table_name):
    chunk_size = 1000
    offset = 0
    
    while True:
        query = f"""
        SELECT * FROM {table_name} 
        LIMIT {chunk_size} OFFSET {offset}
        """
        
        chunk = pd.read_sql_query(query, conn)
        if chunk.empty:
            break
            
        process_chunk(chunk)
        del chunk  # ë©”ëª¨ë¦¬ í•´ì œ
        gc.collect()
        
        offset += chunk_size
```

#### âŒ ì²˜ë¦¬ ì†ë„ ê³¼ë„í•˜ê²Œ ëŠë¦¼

**ì¦ìƒ:** ë³€í™˜ ê³¼ì •ì´ íŠ¹ì • ë‹¨ê³„ì—ì„œ ì˜¤ë«ë™ì•ˆ ë©ˆì¶¤

**ì„±ëŠ¥ ì§„ë‹¨:**
```python
import time
import cProfile

def profile_conversion():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # ë³€í™˜ ì‹¤í–‰
    converter.convert(db_path, terminal_id)
    
    profiler.disable()
    profiler.dump_stats('conversion_profile.prof')

# ì„±ëŠ¥ ë³‘ëª© í˜„ìƒ ë¶„ì„
# python -m cProfile -o profile.prof converter.py
# python -c "import pstats; pstats.Stats('profile.prof').sort_stats('cumulative').print_stats(10)"
```

**ìµœì í™” ì œì•ˆ:**
```python
# 1. SQLite ì„±ëŠ¥ ìµœì í™”
def optimize_sqlite_connection(conn):
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA synchronous=NORMAL")
    conn.execute("PRAGMA cache_size=10000")
    conn.execute("PRAGMA temp_store=MEMORY")

# 2. ë³‘ë ¬ ì²˜ë¦¬
from concurrent.futures import ThreadPoolExecutor

def parallel_table_processing():
    tables = ['Airports', 'Runways', 'Waypoints', 'Navaids']
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for table in tables:
            future = executor.submit(process_table, table)
            futures.append(future)
        
        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        for future in futures:
            future.result()
```

### 4. ë°ì´í„° ë³€í™˜ ë¬¸ì œ

#### âŒ ì¢Œí‘œ ë°ì´í„° ì´ìƒ

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
ValueError: Invalid coordinate value: latitude=91.5
ì¢Œí‘œê°€ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.
```

**ê²€ì¦ ë° ë³µêµ¬:**
```python
def validate_and_fix_coordinates(df):
    """ì¢Œí‘œ ë°ì´í„° ê²€ì¦ ë° ë³µêµ¬"""
    initial_count = len(df)
    
    # ìœ„ë„ ë²”ìœ„ [-90, 90] í™•ì¸
    invalid_lat = (df['Latitude'] < -90) | (df['Latitude'] > 90)
    if invalid_lat.any():
        print(f"ë°œê²¬ {invalid_lat.sum()}ê°œì˜ ìœ íš¨í•˜ì§€ ì•Šì€ ìœ„ë„ ê°’ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        df = df[~invalid_lat]
    
    # ê²½ë„ ë²”ìœ„ [-180, 180] í™•ì¸
    invalid_lon = (df['Longitude'] < -180) | (df['Longitude'] > 180)
    if invalid_lon.any():
        print(f"ë°œê²¬ {invalid_lon.sum()}ê°œì˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ë„ ê°’ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        df = df[~invalid_lon]
    
    removed_count = initial_count - len(df)
    if removed_count > 0:
        print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œí‘œ ê¸°ë¡ {removed_count}ê°œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
    
    return df
```

#### âŒ JSON ì§ë ¬í™” ì‹¤íŒ¨

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
TypeError: Object of type 'datetime' is not JSON serializable
JSON ì§ë ¬í™” ì˜¤ë¥˜
```

**í•´ê²°ì±…:**
```python
import json
from datetime import datetime
import numpy as np

class CustomJSONEncoder(json.JSONEncoder):
    """ì‚¬ìš©ì ì§€ì • JSON ì¸ì½”ë”"""
    
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

# ì‚¬ìš©ì ì§€ì • ì¸ì½”ë” ì‚¬ìš©
def safe_json_dump(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, cls=CustomJSONEncoder, 
                 ensure_ascii=False, indent=2)
```

#### âŒ ë¬¸ì ì¸ì½”ë”© ë¬¸ì œ

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
UnicodeDecodeError: 'utf-8' codec can't decode byte
ë¬¸ì ì¸ì½”ë”© ì˜¤ë¥˜
```

**í•´ê²°ì±…:**
```python
import chardet

def detect_and_convert_encoding(file_path):
    """íŒŒì¼ ì¸ì½”ë”© ê°ì§€ ë° ë³€í™˜"""
    # ì¸ì½”ë”© ê°ì§€
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        encoding = chardet.detect(raw_data)['encoding']
    
    print(f"ê°ì§€ëœ ì¸ì½”ë”©: {encoding}")
    
    # UTF-8ë¡œ ë³€í™˜
    with open(file_path, 'r', encoding=encoding) as f:
        content = f.read()
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)

def safe_string_handling(text):
    """ì•ˆì „í•œ ë¬¸ìì—´ ì²˜ë¦¬"""
    if isinstance(text, bytes):
        # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
        for encoding in ['utf-8', 'gbk', 'latin1']:
            try:
                return text.decode(encoding)
            except UnicodeDecodeError:
                continue
        # ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ ì˜¤ë¥˜ ì²˜ë¦¬ ì‚¬ìš©
        return text.decode('utf-8', errors='replace')
    return str(text)
```

### 5. ì¶œë ¥ íŒŒì¼ ë¬¸ì œ

#### âŒ ì••ì¶• íŒŒì¼ ìƒì„± ì‹¤íŒ¨

**ì˜¤ë¥˜ ë©”ì‹œì§€:**
```
py7zr.exceptions.Bad7zFile: not a 7z file
ì••ì¶• íŒŒì¼ ìƒì„± ì‹¤íŒ¨
```

**í•´ê²°ì±…:**
```python
import py7zr
import shutil
from pathlib import Path

def safe_create_archive(source_dir, archive_path):
    """ì•ˆì „í•œ ì••ì¶• íŒŒì¼ ìƒì„±"""
    try:
        # ì›ë³¸ ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not Path(source_dir).exists():
            raise FileNotFoundError(f"ì›ë³¸ ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.: {source_dir}")
        
        # ê¸°ì¡´ ì••ì¶• íŒŒì¼ ì‚­ì œ
        if Path(archive_path).exists():
            Path(archive_path).unlink()
        
        # ì••ì¶• íŒŒì¼ ìƒì„±
        with py7zr.SevenZipFile(archive_path, 'w') as archive:
            archive.writeall(source_dir, ".")
        
        print(f"âœ… ì••ì¶• íŒŒì¼ ìƒì„± ì„±ê³µ: {archive_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ì••ì¶• íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì²´ ë°©ì•ˆ: ZIP íŒŒì¼ ìƒì„±
        try:
            shutil.make_archive(
                str(Path(archive_path).with_suffix('')), 
                'zip', 
                source_dir
            )
            print("âœ… ZIP í˜•ì‹ ë°±ì—… íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as zip_error:
            print(f"âŒ ZIP ìƒì„±ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {zip_error}")
            return False
```

#### âŒ íŒŒì¼ í¬ê¸° ì´ìƒ

**ì¦ìƒ:** ì¶œë ¥ íŒŒì¼ì´ ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í¼

**í™•ì¸ ë°©ë²•:**
```python
def validate_output_files(output_dir):
    """ì¶œë ¥ íŒŒì¼ ê²€ì¦"""
    expected_files = [
        'Airports.json', 'Runways.json', 'Waypoints.json',
        'Navaids.json', 'Airways.json', 'AirwayLegs.json',
        'Terminals.json', 'ILSes.json'
    ]
    
    file_info = {}
    for file_name in expected_files:
        file_path = Path(output_dir) / file_name
        if file_path.exists():
            size = file_path.stat().st_size
            file_info[file_name] = {
                'exists': True,
                'size_mb': size / 1024 / 1024,
                'empty': size == 0
            }
        else:
            file_info[file_name] = {'exists': False}
    
    # íŒŒì¼ ì •ë³´ ì¶œë ¥
    print("ğŸ“ ì¶œë ¥ íŒŒì¼ í™•ì¸:")
    for file_name, info in file_info.items():
        if info['exists']:
            if info.get('empty', False):
                print(f"âš ï¸ {file_name}: ë¹ˆ íŒŒì¼")
            else:
                print(f"âœ… {file_name}: {info['size_mb']:.2f} MB")
        else:
            print(f"âŒ {file_name}: íŒŒì¼ ëˆ„ë½")
    
    return file_info
```

## ğŸ” ì§„ë‹¨ ë„êµ¬

### 1. ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸

```python
def system_diagnostics():
    """ì‹œìŠ¤í…œ í™˜ê²½ ì§„ë‹¨"""
    import platform
    import sys
    import psutil
    
    print("ğŸ” ì‹œìŠ¤í…œ í™˜ê²½ ì§„ë‹¨")
    print("=" * 50)
    
    # ìš´ì˜ ì²´ì œ ì •ë³´
    print(f"ìš´ì˜ ì²´ì œ: {platform.system()} {platform.release()}")
    print(f"ì•„í‚¤í…ì²˜: {platform.machine()}")
    
    # Python í™˜ê²½
    print(f"Python ë²„ì „: {sys.version}")
    print(f"Python ê²½ë¡œ: {sys.executable}")
    
    # í•˜ë“œì›¨ì–´ ì •ë³´
    print(f"CPU ì½”ì–´ ìˆ˜: {psutil.cpu_count()}")
    memory = psutil.virtual_memory()
    print(f"ì´ ë©”ëª¨ë¦¬: {memory.total // 1024**3} GB")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {memory.available // 1024**3} GB")
    
    # ë””ìŠ¤í¬ ê³µê°„
    disk = psutil.disk_usage('.')
    print(f"ì´ ë””ìŠ¤í¬ ê³µê°„: {disk.total // 1024**3} GB")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë””ìŠ¤í¬ ê³µê°„: {disk.free // 1024**3} GB")
```

### 2. ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ê²€ì¦

```python
def verify_dependencies():
    """ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ê²€ì¦"""
    required_packages = [
        'rich', 'pandas', 'py7zr', 'sqlite3'
    ]
    
    print("ğŸ“¦ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ê²€ì¦")
    print("=" * 30)
    
    for package in required_packages:
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'Unknown')
            print(f"âœ… {package}: {version}")
        except ImportError:
            print(f"âŒ {package}: ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        except Exception as e:
            print(f"âš ï¸ {package}: ì˜¤ë¥˜ - {e}")
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬

```python
import time
import threading
from contextlib import contextmanager

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.metrics = {}
        self.monitoring = False
    
    @contextmanager
    def measure(self, operation_name):
        """ì‘ì—… ì†Œìš” ì‹œê°„ ì¸¡ì •"""
        start_time = time.time()
        start_memory = psutil.virtual_memory().used
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.virtual_memory().used
            
            self.metrics[operation_name] = {
                'duration': end_time - start_time,
                'memory_delta': end_memory - start_memory
            }
    
    def start_monitoring(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring = True
        
        def monitor():
            while self.monitoring:
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                
                print(f"\rğŸ”„ CPU: {cpu_percent:5.1f}% | "
                      f"ë©”ëª¨ë¦¬: {memory.percent:5.1f}% | "
                      f"ì‚¬ìš© ê°€ëŠ¥: {memory.available//1024**2:,} MB", 
                      end='', flush=True)
                
                time.sleep(1)
        
        monitor_thread = threading.Thread(target=monitor, daemon=True)
        monitor_thread.start()
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
        print()  # ì¤„ë°”ê¿ˆ
    
    def print_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š ì„±ëŠ¥ ìš”ì•½:")
        print("-" * 40)
        
        for operation, metrics in self.metrics.items():
            duration = metrics['duration']
            memory_mb = metrics['memory_delta'] / 1024 / 1024
            
            print(f"{operation:20s}: {duration:8.2f}s | "
                  f"{memory_mb:+8.1f}MB")

# ì‚¬ìš© ì˜ˆì‹œ
monitor = PerformanceMonitor()
monitor.start_monitoring()

with monitor.measure("ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦"):
    validate_database(db_path)

with monitor.measure("ë°ì´í„° ë³€í™˜"):
    convert_data()

monitor.stop_monitoring()
monitor.print_summary()
```

## ğŸ“‹ ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸

### ğŸ”§ ë³€í™˜ ì „ í™•ì¸
- [ ] Python ë²„ì „ â‰¥ 3.8
- [ ] ëª¨ë“  ì˜ì¡´ì„± íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆìœ¼ë©° ë²„ì „ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
- [ ] Fenix ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ì™„ì „í•œì§€ í™•ì¸
- [ ] ì¶©ë¶„í•œ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ (ê¶Œì¥ 4GB ì´ìƒ)
- [ ] ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ (ê¶Œì¥ 1GB ì´ìƒ)
- [ ] ì¶œë ¥ ë””ë ‰í„°ë¦¬ì— ì“°ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸

### ğŸ“Š ë³€í™˜ ê³¼ì • í™•ì¸
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ
- [ ] ëª¨ë“  í•„ìˆ˜ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
- [ ] ì¢Œí‘œ ë°ì´í„°ê°€ ìœ íš¨ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í•©ë¦¬ì ì¸ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
- [ ] ê¶Œí•œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
- [ ] ì„ì‹œ íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸

### ğŸ“ ë³€í™˜ í›„ ê²€ì¦
- [ ] ëª¨ë“  JSON íŒŒì¼ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
- [ ] íŒŒì¼ í¬ê¸°ê°€ í•©ë¦¬ì ì¸ì§€ (ë¹„ì–´ìˆì§€ ì•Šê±°ë‚˜ ë¹„ì •ìƒì ìœ¼ë¡œ í¬ì§€ ì•Šì€ì§€) í™•ì¸
- [ ] JSON í˜•ì‹ì´ ìœ íš¨í•œì§€ í™•ì¸
- [ ] ì••ì¶• íŒŒì¼ ìƒì„± ì„±ê³µ
- [ ] ì„ì‹œ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
- [ ] ë¡œê·¸ì— ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ í™•ì¸

## ğŸ†˜ ë„ì›€ ë°›ê¸°

### ìê°€ ì§„ë‹¨
1.  **ì§„ë‹¨ ë„êµ¬ ì‹¤í–‰**:
    ```python
    from tfdi_converter.diagnostics import run_full_diagnostics
    run_full_diagnostics()
    ```

2.  **ìì„¸í•œ ë¡œê·¸ í™•ì¸**:
    ```bash
    tail -f converter.log
    grep -i error converter.log
    ```

3.  **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸**:
    ```bash
    # Windows
    taskmgr
    
    # macOS
    activity monitor
    
    # Linux
    top
    htop
    ```

### ì»¤ë®¤ë‹ˆí‹° ì§€ì›
-   **GitHub Issues**: ë²„ê·¸ ë° ê¸°ìˆ  ë¬¸ì œ ë³´ê³ 
-   **GitHub Discussions**: ì‚¬ìš© ë¬¸ì œ ë° ê²½í—˜ ê³µìœ 
-   **í”„ë¡œì íŠ¸ ë¬¸ì„œ**: ì „ì²´ ì‚¬ìš© ì„¤ëª…ì„œ ì°¸ì¡°

### ë¬¸ì œ ë³´ê³  ì‹œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì‹­ì‹œì˜¤:
-   **ì „ì²´ ì˜¤ë¥˜ ë¡œê·¸**
-   **ì‹œìŠ¤í…œ í™˜ê²½ ì •ë³´**
-   **ë³€í™˜ê¸° ë²„ì „**
-   **ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´** (í¬ê¸°, AIRAC ë“±)
-   **ì¬í˜„ ë‹¨ê³„**
-   **ê´€ë ¨ êµ¬ì„± íŒŒì¼**

---

**í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œê°€ ë°œìƒí–ˆë‚˜ìš”?**

[GitHub Issues](https://github.com/your-org/tfdi-converter/issues) ì— ìƒˆ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì‹œë©´, ìµœëŒ€í•œ ë¹¨ë¦¬ í•´ê²°ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!ğŸšâœ¨