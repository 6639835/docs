# üõ†Ô∏è Resoluci√≥n de Problemas del Conversor de Datos de Navegaci√≥n TFDI

## üö® Errores Comunes y Soluciones

### 1. Problemas de Entorno e Instalaci√≥n

#### ‚ùå Problemas de Entorno de Python

**Mensaje de error:**
```
ModuleNotFoundError: No module named 'rich'
ImportError: No module named 'pandas'
```

**Soluci√≥n:**
```bash
# 1. Verificar la versi√≥n de Python
python --version  # Asegurarse de que sea ‚â• 3.8

# 2. Actualizar pip
python -m pip install --upgrade pip

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Verificar la instalaci√≥n
python -c "import rich, pandas; print('Dependencias instaladas correctamente')"
```

#### ‚ùå Error de Permisos

**Mensaje de error:**
```
PermissionError: [Errno 13] Permission denied
No se pudo crear el directorio de salida
```

**Soluci√≥n:**
```bash
# Windows - Ejecutar como administrador
# Clic derecho en el S√≠mbolo del sistema ‚Üí "Ejecutar como administrador"

# macOS/Linux - Usar sudo o modificar permisos
sudo python converter.py
# o
chmod 755 /path/to/output/directory
```

### 2. Problemas de Acceso a la Base de Datos

#### ‚ùå Archivo de Base de Datos Inexistente

**Mensaje de error:**
```
FileNotFoundError: [Errno 2] No such file or directory: 'nd.db3'
No se pudo encontrar el archivo de base de datos de Fenix
```

**Soluci√≥n:**
1.  **Verificar la instalaci√≥n de Fenix**:
    ```bash
    # Ruta com√∫n
    %APPDATA%\Microsoft Flight Simulator\Packages\fenix-a320\
    ```

2.  **Localizar el archivo manualmente**:
    ```bash
    # Windows
    dir /s nd.db3
    
    # macOS/Linux
    find ~ -name "nd.db3" 2>/dev/null
    ```

3.  **Regenerar la base de datos**:
    -   Iniciar MSFS
    -   Cargar el Fenix A320
    -   Esperar a que se carguen los datos de navegaci√≥n

#### ‚ùå Base de Datos Corrupta

**Mensaje de error:**
```
sqlite3.DatabaseError: database disk image is malformed
El archivo de la base de datos est√° corrupto
```

**M√©todo de diagn√≥stico:**
```python
import sqlite3

def check_database_integrity(db_path):
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("PRAGMA integrity_check")
        result = cursor.fetchone()
        if result[0] == "ok":
            print("‚úÖ Integridad de la base de datos normal")
        else:
            print(f"‚ùå Base de datos corrupta: {result[0]}")
    except Exception as e:
        print(f"‚ùå No se puede acceder a la base de datos: {e}")
    finally:
        conn.close()
```

**Plan de reparaci√≥n:**
```bash
# 1. Hacer una copia de seguridad de la base de datos corrupta
cp nd.db3 nd.db3.backup

# 2. Intentar reparar con SQLite
sqlite3 nd.db3 ".dump" | sqlite3 nd_repaired.db3

# 3. Si la reparaci√≥n falla, obtener una nueva base de datos
# Eliminar el archivo y reiniciar Fenix
```

#### ‚ùå Estructura de Tabla de la Base de Datos Incompatible

**Mensaje de error:**
```
sqlite3.OperationalError: no such table: Terminals
La base de datos carece de tablas necesarias
```

**Script de validaci√≥n:**
```python
def validate_database_schema(db_path):
    required_tables = [
        'Airports', 'Runways', 'Waypoints', 'Navaids',
        'Airways', 'AirwayLegs', 'Terminals', 'TerminalLegs',
        'ILSes', 'AirportLookup', 'NavaidLookup', 'WaypointLookup'
    ]
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    existing_tables = {row[0] for row in cursor.fetchall()}
    
    missing_tables = set(required_tables) - existing_tables
    if missing_tables:
        print(f"‚ùå Tablas faltantes: {missing_tables}")
        return False
    
    print("‚úÖ Estructura de la base de datos validada correctamente")
    return True
```

### 3. Problemas de Memoria y Rendimiento

#### ‚ùå Memoria Insuficiente

**Mensaje de error:**
```
MemoryError: Unable to allocate array
Memoria insuficiente, no se pueden procesar los datos
```

**Monitorizar el uso de memoria:**
```python
import psutil
import gc

def monitor_memory_usage():
    memory = psutil.virtual_memory()
    print(f"Memoria total: {memory.total // 1024**3} GB")
    print(f"Memoria usada: {memory.used // 1024**3} GB")
    print(f"Memoria disponible: {memory.available // 1024**3} GB")
    print(f"Porcentaje de uso: {memory.percent}%")

def optimize_memory():
    # Forzar la recolecci√≥n de basura
    gc.collect()
    
    # Limpiar la cach√© de pandas
    import pandas as pd
    pd.reset_option('all')
```

**Soluci√≥n:**
```python
# 1. Reducir el tama√±o del lote
config = ConverterConfig(
    batch_size=500,  # Reducir desde el valor predeterminado de 1000
    coordinate_precision=6  # Reducir la precisi√≥n
)

# 2. Habilitar el procesamiento por flujo
def process_large_table_streaming(table_name):
    chunk_size = 1000
    offset = 0
    
    while True:
        query = f"""
        SELECT * FROM {table_name} 
        LIMIT {chunk_size} OFFSET {offset}
        """
        
        chunk = pd.read_sql_query(query, conn)
        if chunk.empty:
            break
            
        process_chunk(chunk)
        del chunk  # Liberar memoria
        gc.collect()
        
        offset += chunk_size
```

#### ‚ùå Velocidad de Procesamiento Demasiado Lenta

**S√≠ntoma:** El proceso de conversi√≥n se detiene en un paso durante mucho tiempo

**Diagn√≥stico de rendimiento:**
```python
import time
import cProfile

def profile_conversion():
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Ejecutar la conversi√≥n
    converter.convert(db_path, terminal_id)
    
    profiler.disable()
    profiler.dump_stats('conversion_profile.prof')

# Analizar cuellos de botella de rendimiento
# python -m cProfile -o profile.prof converter.py
# python -c "import pstats; pstats.Stats('profile.prof').sort_stats('cumulative').print_stats(10)"
```

**Sugerencias de optimizaci√≥n:**
```python
# 1. Optimizaci√≥n de rendimiento de SQLite
def optimize_sqlite_connection(conn):
    conn.execute("PRAGMA journal_mode=WAL")
    conn.execute("PRAGMA synchronous=NORMAL")
    conn.execute("PRAGMA cache_size=10000")
    conn.execute("PRAGMA temp_store=MEMORY")

# 2. Procesamiento paralelo
from concurrent.futures import ThreadPoolExecutor

def parallel_table_processing():
    tables = ['Airports', 'Runways', 'Waypoints', 'Navaids']
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for table in tables:
            future = executor.submit(process_table, table)
            futures.append(future)
        
        # Esperar a que todas las tareas se completen
        for future in futures:
            future.result()
```

### 4. Problemas de Conversi√≥n de Datos

#### ‚ùå Datos de Coordenadas An√≥malos

**Mensaje de error:**
```
ValueError: Invalid coordinate value: latitude=91.5
Coordenadas fuera del rango v√°lido
```

**Validaci√≥n y reparaci√≥n:**
```python
def validate_and_fix_coordinates(df):
    """Valida y repara los datos de coordenadas"""
    initial_count = len(df)
    
    # Verificar el rango de latitud [-90, 90]
    invalid_lat = (df['Latitude'] < -90) | (df['Latitude'] > 90)
    if invalid_lat.any():
        print(f"Se encontraron {invalid_lat.sum()} valores de latitud inv√°lidos")
        df = df[~invalid_lat]
    
    # Verificar el rango de longitud [-180, 180]
    invalid_lon = (df['Longitude'] < -180) | (df['Longitude'] > 180)
    if invalid_lon.any():
        print(f"Se encontraron {invalid_lon.sum()} valores de longitud inv√°lidos")
        df = df[~invalid_lon]
    
    removed_count = initial_count - len(df)
    if removed_count > 0:
        print(f"‚ö†Ô∏è Se eliminaron {removed_count} registros de coordenadas inv√°lidas")
    
    return df
```

#### ‚ùå Fallo de Serializaci√≥n JSON

**Mensaje de error:**
```
TypeError: Object of type 'datetime' is not JSON serializable
Error de serializaci√≥n JSON
```

**Soluci√≥n:**
```python
import json
from datetime import datetime
import numpy as np

class CustomJSONEncoder(json.JSONEncoder):
    """Codificador JSON personalizado"""
    
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

# Usar el codificador personalizado
def safe_json_dump(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, cls=CustomJSONEncoder, 
                 ensure_ascii=False, indent=2)
```

#### ‚ùå Problemas de Codificaci√≥n de Caracteres

**Mensaje de error:**
```
UnicodeDecodeError: 'utf-8' codec can't decode byte
Error de codificaci√≥n de caracteres
```

**Soluci√≥n:**
```python
import chardet

def detect_and_convert_encoding(file_path):
    """Detecta y convierte la codificaci√≥n del archivo"""
    # Detectar codificaci√≥n
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        encoding = chardet.detect(raw_data)['encoding']
    
    print(f"Codificaci√≥n detectada: {encoding}")
    
    # Convertir a UTF-8
    with open(file_path, 'r', encoding=encoding) as f:
        content = f.read()
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)

def safe_string_handling(text):
    """Manejo seguro de cadenas"""
    if isinstance(text, bytes):
        # Intentar con m√∫ltiples codificaciones
        for encoding in ['utf-8', 'gbk', 'latin1']:
            try:
                return text.decode(encoding)
            except UnicodeDecodeError:
                continue
        # Si todas fallan, usar manejo de errores
        return text.decode('utf-8', errors='replace')
    return str(text)
```

### 5. Problemas de Archivos de Salida

#### ‚ùå Fallo al Crear el Archivo Comprimido

**Mensaje de error:**
```
py7zr.exceptions.Bad7zFile: not a 7z file
Fallo al crear el archivo comprimido
```

**Soluci√≥n:**
```python
import py7zr
import shutil
from pathlib import Path

def safe_create_archive(source_dir, archive_path):
    """Crear archivo comprimido de forma segura"""
    try:
        # Asegurarse de que el directorio de origen existe
        if not Path(source_dir).exists():
            raise FileNotFoundError(f"El directorio de origen no existe: {source_dir}")
        
        # Eliminar el archivo comprimido existente
        if Path(archive_path).exists():
            Path(archive_path).unlink()
        
        # Crear el archivo comprimido
        with py7zr.SevenZipFile(archive_path, 'w') as archive:
            archive.writeall(source_dir, ".")
        
        print(f"‚úÖ Archivo comprimido creado correctamente: {archive_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå Fallo al crear el archivo comprimido: {e}")
        
        # Plan de contingencia: Crear archivo ZIP
        try:
            shutil.make_archive(
                str(Path(archive_path).with_suffix('')), 
                'zip', 
                source_dir
            )
            print("‚úÖ Archivo de respaldo en formato ZIP creado")
            return True
        except Exception as zip_error:
            print(f"‚ùå La creaci√≥n del ZIP tambi√©n fall√≥: {zip_error}")
            return False
```

#### ‚ùå Tama√±o de Archivo An√≥malo

**S√≠ntoma:** El archivo de salida es demasiado peque√±o o demasiado grande

**M√©todo de verificaci√≥n:**
```python
def validate_output_files(output_dir):
    """Valida los archivos de salida"""
    expected_files = [
        'Airports.json', 'Runways.json', 'Waypoints.json',
        'Navaids.json', 'Airways.json', 'AirwayLegs.json',
        'Terminals.json', 'ILSes.json'
    ]
    
    file_info = {}
    for file_name in expected_files:
        file_path = Path(output_dir) / file_name
        if file_path.exists():
            size = file_path.stat().st_size
            file_info[file_name] = {
                'exists': True,
                'size_mb': size / 1024 / 1024,
                'empty': size == 0
            }
        else:
            file_info[file_name] = {'exists': False}
    
    # Imprimir informaci√≥n del archivo
    print("üìÅ Verificaci√≥n de archivos de salida:")
    for file_name, info in file_info.items():
        if info['exists']:
            if info.get('empty', False):
                print(f"‚ö†Ô∏è {file_name}: Archivo vac√≠o")
            else:
                print(f"‚úÖ {file_name}: {info['size_mb']:.2f} MB")
        else:
            print(f"‚ùå {file_name}: Archivo faltante")
    
    return file_info
```

## üîç Herramientas de Diagn√≥stico

### 1. Verificaci√≥n del Entorno del Sistema

```python
def system_diagnostics():
    """Diagn√≥stico del entorno del sistema"""
    import platform
    import sys
    import psutil
    
    print("üîç Diagn√≥stico del entorno del sistema")
    print("=" * 50)
    
    # Informaci√≥n del sistema operativo
    print(f"Sistema operativo: {platform.system()} {platform.release()}")
    print(f"Arquitectura: {platform.machine()}")
    
    # Entorno de Python
    print(f"Versi√≥n de Python: {sys.version}")
    print(f"Ruta de Python: {sys.executable}")
    
    # Informaci√≥n de hardware
    print(f"N√∫mero de n√∫cleos de CPU: {psutil.cpu_count()}")
    memory = psutil.virtual_memory()
    print(f"Memoria total: {memory.total // 1024**3} GB")
    print(f"Memoria disponible: {memory.available // 1024**3} GB")
    
    # Espacio en disco
    disk = psutil.disk_usage('.')
    print(f"Espacio total en disco: {disk.total // 1024**3} GB")
    print(f"Espacio libre en disco: {disk.free // 1024**3} GB")
```

### 2. Verificaci√≥n de Paquetes de Dependencia

```python
def verify_dependencies():
    """Verifica los paquetes de dependencia"""
    required_packages = [
        'rich', 'pandas', 'py7zr', 'sqlite3'
    ]
    
    print("üì¶ Verificaci√≥n de paquetes de dependencia")
    print("=" * 30)
    
    for package in required_packages:
        try:
            module = __import__(package)
            version = getattr(module, '__version__', 'Unknown')
            print(f"‚úÖ {package}: {version}")
        except ImportError:
            print(f"‚ùå {package}: No instalado")
        except Exception as e:
            print(f"‚ö†Ô∏è {package}: Error - {e}")
```

### 3. Herramienta de Monitoreo de Rendimiento

```python
import time
import threading
from contextlib import contextmanager

class PerformanceMonitor:
    """Monitor de rendimiento"""
    
    def __init__(self):
        self.metrics = {}
        self.monitoring = False
    
    @contextmanager
    def measure(self, operation_name):
        """Mide el tiempo de operaci√≥n"""
        start_time = time.time()
        start_memory = psutil.virtual_memory().used
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.virtual_memory().used
            
            self.metrics[operation_name] = {
                'duration': end_time - start_time,
                'memory_delta': end_memory - start_memory
            }
    
    def start_monitoring(self):
        """Comienza el monitoreo en tiempo real"""
        self.monitoring = True
        
        def monitor():
            while self.monitoring:
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                
                print(f"\rüîÑ CPU: {cpu_percent:5.1f}% | "
                      f"Memoria: {memory.percent:5.1f}% | "
                      f"Disponible: {memory.available//1024**2:,} MB", 
                      end='', flush=True)
                
                time.sleep(1)
        
        monitor_thread = threading.Thread(target=monitor, daemon=True)
        monitor_thread.start()
    
    def stop_monitoring(self):
        """Detiene el monitoreo"""
        self.monitoring = False
        print()  # Nueva l√≠nea
    
    def print_summary(self):
        """Imprime el resumen de rendimiento"""
        print("\nüìä Resumen de rendimiento:")
        print("-" * 40)
        
        for operation, metrics in self.metrics.items():
            duration = metrics['duration']
            memory_mb = metrics['memory_delta'] / 1024 / 1024
            
            print(f"{operation:20s}: {duration:8.2f}s | "
                  f"{memory_mb:+8.1f}MB")

# Ejemplo de uso
monitor = PerformanceMonitor()
monitor.start_monitoring()

with monitor.measure("Validaci√≥n de base de datos"):
    validate_database(db_path)

with monitor.measure("Conversi√≥n de datos"):
    convert_data()

monitor.stop_monitoring()
monitor.print_summary()
```

## üìã Lista de Verificaci√≥n de Soluci√≥n de Problemas

### üîß Verificaciones Pre-conversi√≥n
- [ ] Versi√≥n de Python ‚â• 3.8
- [ ] Todos los paquetes de dependencia instalados y con la versi√≥n correcta
- [ ] El archivo de base de datos de Fenix existe y est√° completo
- [ ] Suficiente memoria disponible (se recomiendan 4GB+)
- [ ] Suficiente espacio en disco (se recomienda 1GB+)
- [ ] El directorio de salida tiene permisos de escritura

### üìä Verificaciones del Proceso de Conversi√≥n
- [ ] Conexi√≥n a la base de datos exitosa
- [ ] Todas las tablas requeridas existen
- [ ] Los datos de coordenadas est√°n dentro del rango v√°lido
- [ ] El uso de memoria est√° dentro de un rango razonable
- [ ] No hay errores de permisos
- [ ] Los archivos temporales se crearon correctamente

### üìÅ Validaci√≥n Post-conversi√≥n
- [ ] Todos los archivos JSON han sido generados
- [ ] El tama√±o de los archivos es razonable (no est√°n vac√≠os o son anormalmente grandes)
- [ ] El formato JSON es v√°lido
- [ ] El archivo comprimido se cre√≥ correctamente
- [ ] Los archivos temporales han sido limpiados
- [ ] No hay errores graves en los registros

## üÜò Obtener Ayuda

### Autodiagn√≥stico
1.  **Ejecutar la herramienta de diagn√≥stico**:
    ```python
    from tfdi_converter.diagnostics import run_full_diagnostics
    run_full_diagnostics()
    ```

2.  **Ver registros detallados**:
    ```bash
    tail -f converter.log
    grep -i error converter.log
    ```

3.  **Verificar los recursos del sistema**:
    ```bash
    # Windows
    taskmgr
    
    # macOS
    activity monitor
    
    # Linux
    top
    htop
    ```

### Soporte de la Comunidad
-   **GitHub Issues**: Informar errores y problemas t√©cnicos
-   **GitHub Discussions**: Compartir preguntas de uso y experiencias
-   **Documentaci√≥n del proyecto**: Consultar la gu√≠a de uso completa

### Al informar un problema, por favor proporcione:
-   **Registro de errores completo**
-   **Informaci√≥n del entorno del sistema**
-   **Versi√≥n del conversor**
-   **Informaci√≥n de la base de datos** (tama√±o, AIRAC, etc.)
-   **Pasos para reproducir**
-   **Archivos de configuraci√≥n relevantes**

---

**¬øEncontr√≥ un problema sin resolver?** 

Por favor, cree un nuevo problema en [GitHub Issues](https://github.com/your-org/tfdi-converter/issues) y le ayudaremos a resolverlo lo antes posible. üöÅ‚ú®