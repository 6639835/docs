# üèóÔ∏è Arquitectura del Convertidor de Datos de Navegaci√≥n TFDI

## Sistema General

El Convertidor de Datos de Navegaci√≥n TFDI es una herramienta profesional de conversi√≥n de datos de navegaci√≥n a√©rea, dise√±ada espec√≠ficamente para convertir la base de datos de navegaci√≥n del Fenix A320 al formato JSON compatible con el TFDI MD-11. Esta herramienta adopta un dise√±o de arquitectura moderna, proporcionando servicios de conversi√≥n de datos eficientes y fiables.

## üéØ Principios de Dise√±o

### 1. Prioridad a la Integridad de los Datos
- **Validaci√≥n estricta**: M√∫ltiples mecanismos de validaci√≥n de datos
- **Mantenimiento de relaciones**: Preservaci√≥n de las relaciones de dependencia entre los datos de navegaci√≥n
- **Garant√≠a de precisi√≥n**: Mantenimiento de alta precisi√≥n en coordenadas y c√°lculos
- **Comprobaci√≥n de coherencia**: Aseguramiento de la coherencia l√≥gica de los datos despu√©s de la conversi√≥n

### 2. Orientado a la Optimizaci√≥n del Rendimiento
- **Optimizaci√≥n de SQLite**: Modo WAL y ajuste de rendimiento
- **Procesamiento por lotes**: Estrategias de procesamiento por lotes eficientes en memoria
- **Mecanismo de cach√©**: Cach√© y reutilizaci√≥n inteligente de datos
- **Optimizaci√≥n de compresi√≥n**: Compresi√≥n y limpieza r√°pidas con 7z

### 3. Experiencia de Usuario Superior
- **Rich CLI**: Interfaz de terminal moderna y colorida
- **Retroalimentaci√≥n en tiempo real**: Visualizaci√≥n detallada del progreso y actualizaciones de estado
- **Mensajes amigables**: Manejo profesional de errores y sugerencias de recuperaci√≥n
- **Dise√±o interactivo**: Gu√≠a intuitiva del flujo de operaci√≥n

## üèóÔ∏è Arquitectura del Sistema

### Diagrama de Arquitectura General

```mermaid
graph TB
    A[Capa de Interfaz de Usuario] --> B[Capa de L√≥gica de Negocio]
    B --> C[Capa de Procesamiento de Datos]
    C --> D[Capa de Acceso a Almacenamiento]
    
    A --> A1[Interfaz Rich CLI]
    A --> A2[Gestor de Progreso]
    A --> A3[Interacci√≥n de Usuario]
    
    B --> B1[Controlador de Conversi√≥n]
    B --> B2[Gestor de Configuraci√≥n]
    B --> B3[Motor de Validaci√≥n]
    B --> B4[Detector FAF]
    
    C --> C1[Procesador SQLite]
    C --> C2[Normalizador de Coordenadas]
    C --> C3[Serializador JSON]
    C --> C4[Gestor de Compresi√≥n]
    
    D --> D1[Base de Datos Fenix]
    D --> D2[Archivos JSON]
    D --> D3[Paquete comprimido 7z]
```

### Detalles de los Componentes Clave

#### 1. Capa de Interfaz de Usuario (UI Layer)
**Responsabilidad**: Proporcionar la interfaz de interacci√≥n y retroalimentaci√≥n del usuario
```python
class RichInterface:
    """Gestor de Interfaz Rich CLI"""
    - progress_tracking: Gesti√≥n de barras de progreso
    - status_display: Visualizaci√≥n de informaci√≥n de estado
    - error_presentation: Presentaci√≥n de mensajes de error
    - user_input: Procesamiento de entrada de usuario
```

#### 2. Capa de L√≥gica de Negocio (Business Layer)
**Responsabilidad**: L√≥gica de negocio central y control de flujo
```python
class FenixToTFDIConverter:
    """Clase del conversor principal"""
    - database_validation: Validaci√≥n de base de datos
    - conversion_orchestration: Orquestaci√≥n del proceso de conversi√≥n
    - faf_detection: Detecci√≥n de puntos FAF
    - data_normalization: Normalizaci√≥n de datos
```

#### 3. Capa de Procesamiento de Datos (Data Layer)
**Responsabilidad**: Algoritmos de conversi√≥n y procesamiento de datos
```python
class DataProcessor:
    """N√∫cleo de procesamiento de datos"""
    - coordinate_precision: Gesti√≥n de precisi√≥n de coordenadas
    - column_standardization: Normalizaci√≥n de nombres de columna
    - relationship_mapping: Mapeo de relaciones
    - format_conversion: Conversi√≥n de formato
```

#### 4. Capa de Acceso a Almacenamiento (Storage Layer)
**Responsabilidad**: Acceso a base de datos y operaciones de archivo
```python
class StorageManager:
    """Gestor de almacenamiento"""
    - sqlite_optimization: Optimizaci√≥n de rendimiento de SQLite
    - file_operations: Operaciones de lectura/escritura de archivos
    - compression_handling: Manejo de archivos comprimidos
    - backup_management: Gesti√≥n de copias de seguridad
```

## üìä Arquitectura del Flujo de Datos

### Pipeline de Conversi√≥n

```mermaid
sequenceDiagram
    participant U as Usuario
    participant UI as Capa UI
    participant BL as Capa BL
    participant DL as Capa DL
    participant SL as Capa SL
    
    U->>UI: Iniciar conversi√≥n
    UI->>BL: Inicializar conversor
    BL->>SL: Validar base de datos
    SL->>BL: Devolver resultado de validaci√≥n
    BL->>DL: Iniciar procesamiento de datos
    
    loop Cada tabla de datos
        DL->>SL: Leer datos
        DL->>DL: Procesamiento de normalizaci√≥n
        DL->>DL: Ajuste de precisi√≥n de coordenadas
        DL->>SL: Escribir JSON
        DL->>UI: Actualizar progreso
    end
    
    DL->>BL: Procesamiento completado
    BL->>SL: Crear paquete comprimido
    SL->>UI: Devolver resultado
    UI->>U: Mostrar estado completado
```

### Arquitectura de Mapeo de Datos

```mermaid
graph LR
    A[Base de Datos Fenix SQLite] --> B[Capa de Extracci√≥n de Datos]
    B --> C[Capa de Normalizaci√≥n]
    C --> D[Capa de Validaci√≥n]
    D --> E[Capa de Conversi√≥n]
    E --> F[Capa de Serializaci√≥n]
    F --> G[Conjunto de Archivos JSON]
    G --> H[Capa de Compresi√≥n]
    H --> I[Paquete Compatible con TFDI]
```

## üîß Pila Tecnol√≥gica

### Tecnolog√≠as Clave

| Componente | Selecci√≥n de Tecnolog√≠a | Requisitos de Versi√≥n | Prop√≥sito |
|------------|-------------------------|-----------------------|-----------|
| **Python** | Python 3.8+             | ‚â• 3.8.0               | Lenguaje de programaci√≥n principal |
| **Rich**   | Rich Library            | ‚â• 12.0.0              | Embellecimiento de interfaz CLI |
| **SQLite3**| M√≥dulo integrado        | Integrado en Python   | Acceso a base de datos |
| **Pandas** | DataFrame               | ‚â• 1.3.0               | Procesamiento de datos |
| **JSON**   | M√≥dulo integrado        | Integrado en Python   | Serializaci√≥n de datos |
| **py7zr**  | 7-Zip Python            | ‚â• 0.18.0              | Manejo de compresi√≥n |

### Caracter√≠sticas de la Arquitectura

#### 1. Dise√±o Modular
```python
fenix_to_tfdi/
‚îú‚îÄ‚îÄ core/                  # M√≥dulo central
‚îÇ   ‚îú‚îÄ‚îÄ converter.py       # Conversor principal
‚îÇ   ‚îú‚îÄ‚îÄ validator.py       # Validador de datos
‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Gesti√≥n de configuraci√≥n
‚îú‚îÄ‚îÄ data/                  # Procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ processor.py       # Procesador de datos
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py      # Herramienta de normalizaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ serializer.py     # Herramienta de serializaci√≥n
‚îú‚îÄ‚îÄ ui/                    # Interfaz de usuario
‚îÇ   ‚îú‚îÄ‚îÄ cli.py            # Interfaz de l√≠nea de comandos
‚îÇ   ‚îî‚îÄ‚îÄ progress.py       # Gesti√≥n de progreso
‚îî‚îÄ‚îÄ utils/                 # M√≥dulo de utilidades
    ‚îú‚îÄ‚îÄ storage.py        # Utilidades de almacenamiento
    ‚îî‚îÄ‚îÄ compression.py    # Utilidades de compresi√≥n
```

#### 2. Arquitectura Orientada a la Configuraci√≥n
```python
@dataclass
class ConverterConfig:
    """Clase de configuraci√≥n del conversor"""
    output_dir: str = "Primary"
    procedure_legs_dir: str = "Primary/ProcedureLegs"
    archive_name: str = "Primary.7z"
    coordinate_precision: int = 8
    vnav_threshold: float = 2.5
    
    # Configuraci√≥n de optimizaci√≥n de SQLite
    sqlite_pragmas: Dict[str, str] = field(default_factory=lambda: {
        "journal_mode": "WAL",
        "synchronous": "NORMAL",
        "cache_size": "10000",
        "temp_store": "MEMORY"
    })
```

## üöÄ Arquitectura de Rendimiento

### Estrategia de Gesti√≥n de Memoria

#### 1. Procesamiento por Flujo
```python
def process_large_table(table_name: str, batch_size: int = 1000):
    """Procesamiento por flujo de tablas grandes"""
    offset = 0
    while True:
        query = f"""
        SELECT * FROM {table_name} 
        LIMIT {batch_size} OFFSET {offset}
        """
        
        batch = execute_query(query)
        if not batch:
            break
            
        process_batch(batch)
        offset += batch_size
```

#### 2. Optimizaci√≥n de Cach√©
```python
class WaypointCache:
    """Gesti√≥n de cach√© de puntos de ruta"""
    def __init__(self, max_size: int = 10000):
        self._cache: Dict[str, WaypointData] = {}
        self._max_size = max_size
        self._access_times: Dict[str, float] = {}
    
    def get_waypoint(self, waypoint_id: str) -> Optional[WaypointData]:
        """Obtener datos de punto de ruta en cach√©"""
        if waypoint_id in self._cache:
            self._access_times[waypoint_id] = time.time()
            return self._cache[waypoint_id]
        return None
```

### Arquitectura de Procesamiento Concurrente

#### 1. Dise√±o Multihilo
```python
class ConcurrentProcessor:
    """Procesador concurrente"""
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def process_tables_parallel(self, tables: List[str]):
        """Procesar m√∫ltiples tablas en paralelo"""
        futures = []
        for table in tables:
            future = self.executor.submit(self.process_table, table)
            futures.append(future)
        
        # Esperar a que todas las tareas se completen
        concurrent.futures.wait(futures)
```

#### 2. Gesti√≥n de Pool de Recursos
```python
class DatabaseConnectionPool:
    """Pool de conexiones de base de datos"""
    def __init__(self, db_path: str, pool_size: int = 5):
        self.db_path = db_path
        self.pool_size = pool_size
        self.connections: Queue = Queue(maxsize=pool_size)
        self._init_pool()
    
    def get_connection(self) -> sqlite3.Connection:
        """Obtener conexi√≥n a la base de datos"""
        return self.connections.get()
    
    def return_connection(self, conn: sqlite3.Connection):
        """Devolver conexi√≥n a la base de datos"""
        self.connections.put(conn)
```

## üîí Arquitectura de Seguridad

### Mecanismos de Protecci√≥n de Datos

#### 1. Validaci√≥n de Entrada
```python
class InputValidator:
    """Validador de entrada"""
    
    @staticmethod
    def validate_database_path(path: str) -> bool:
        """Validar seguridad de la ruta de la base de datos"""
        # Comprobar ataques de path traversal
        if ".." in path or path.startswith("/"):
            return False
        
        # Validar extensi√≥n de archivo
        if not path.endswith(('.db', '.db3', '.sqlite')):
            return False
        
        return True
    
    @staticmethod  
    def validate_terminal_id(terminal_id: int) -> bool:
        """Validar rango de ID de terminal"""
        return 1 <= terminal_id <= 999999
```

#### 2. Aislamiento de Errores
```python
class SafeConverter:
    """Conversor seguro"""
    
    def safe_convert_table(self, table_name: str) -> bool:
        """Conversi√≥n de tabla segura"""
        try:
            with self.create_transaction() as transaction:
                result = self.convert_table(table_name)
                transaction.commit()
                return result
        except DatabaseError as e:
            self.logger.error(f"Error de base de datos: {e}")
            transaction.rollback()
            return False
        except Exception as e:
            self.logger.error(f"Error desconocido: {e}")
            return False
```

## üìà Arquitectura Escalable

### Dise√±o del Sistema de Plugins

#### 1. Interfaz de Plugin de Conversor
```python
class ConverterPlugin(ABC):
    """Clase base abstracta para plugins de conversor"""
    
    @abstractmethod
    def get_name(self) -> str:
        """Obtener nombre del plugin"""
        pass
    
    @abstractmethod
    def get_supported_formats(self) -> List[str]:
        """Obtener formatos soportados"""
        pass
    
    @abstractmethod
    def convert_data(self, data: Any, config: ConverterConfig) -> Any:
        """Convertir datos"""
        pass
```

#### 2. Mecanismo de Extensi√≥n de Formatos
```python
class FormatRegistry:
    """Registro de formatos"""
    
    def __init__(self):
        self._converters: Dict[str, ConverterPlugin] = {}
    
    def register_converter(self, format_name: str, converter: ConverterPlugin):
        """Registrar conversor"""
        self._converters[format_name] = converter
    
    def get_converter(self, format_name: str) -> Optional[ConverterPlugin]:
        """Obtener conversor"""
        return self._converters.get(format_name)
```

### Extensi√≥n de Fuentes de Datos

#### 1. Abstracci√≥n de Fuente de Datos
```python
class DataSource(ABC):
    """Clase base abstracta de fuente de datos"""
    
    @abstractmethod
    def connect(self) -> bool:
        """Conectar a la fuente de datos"""
        pass
    
    @abstractmethod
    def get_tables(self) -> List[str]:
        """Obtener lista de tablas"""
        pass
    
    @abstractmethod
    def query_data(self, query: str) -> Iterator[Dict]:
        """Consultar datos"""
        pass
```

## üîÑ Arquitectura de Mantenibilidad

### Sistema de Registro de Eventos

#### 1. Registro Estructurado
```python
class StructuredLogger:
    """Registrador estructurado"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # Manejador de formato Rich
        rich_handler = RichHandler(rich_tracebacks=True)
        rich_handler.setFormatter(
            logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
        )
        self.logger.addHandler(rich_handler)
    
    def log_conversion_start(self, table_name: str, record_count: int):
        """Registrar inicio de conversi√≥n"""
        self.logger.info(
            f"Comenzando la conversi√≥n de la tabla {table_name}",
            extra={
                "table": table_name,
                "record_count": record_count,
                "operation": "conversion_start"
            }
        )
```

#### 2. Monitoreo del Rendimiento
```python
class PerformanceMonitor:
    """Monitor de rendimiento"""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = defaultdict(list)
    
    @contextmanager
    def measure_time(self, operation: str):
        """Medir tiempo de operaci√≥n"""
        start_time = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start_time
            self.metrics[operation].append(elapsed)
            self.logger.debug(f"Duraci√≥n de {operation}: {elapsed:.2f}s")
```

## üìä Arquitectura de Pruebas

### Estrategia de Pruebas

#### 1. Pruebas por Capas
```python
# Pruebas unitarias
class TestDataProcessor(unittest.TestCase):
    def test_coordinate_normalization(self):
        """Probar normalizaci√≥n de coordenadas"""
        processor = DataProcessor()
        result = processor.normalize_coordinate(39.916667, 8)
        self.assertEqual(result, 39.91666700)

# Pruebas de integraci√≥n  
class TestConverterIntegration(unittest.TestCase):
    def test_full_conversion_pipeline(self):
        """Probar pipeline de conversi√≥n completo"""
        converter = FenixToTFDIConverter(test_config)
        result = converter.convert(test_database_path)
        self.assertTrue(result)

# Pruebas de rendimiento
class TestPerformance(unittest.TestCase):
    def test_large_database_conversion(self):
        """Probar rendimiento de conversi√≥n de base de datos grande"""
        start_time = time.time()
        converter.convert(large_test_database)
        elapsed = time.time() - start_time
        self.assertLess(elapsed, 300)  # Debe completarse en 5 minutos
```

---

Este dise√±o arquitect√≥nico asegura la **fiabilidad**, el **rendimiento** y la **mantenibilidad** del Convertidor de Datos de Navegaci√≥n TFDI, proporcionando una soluci√≥n de conversi√≥n de datos de nivel profesional para la comunidad de simulaci√≥n de vuelo del TFDI MD-11. üöÅ‚ú®