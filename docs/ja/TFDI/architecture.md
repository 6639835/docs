# ğŸ—ï¸ TFDI èˆªæ³•ãƒ‡ãƒ¼ã‚¿å¤‰æ›å™¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

TFDI èˆªæ³•ãƒ‡ãƒ¼ã‚¿å¤‰æ›å™¨ã¯ã€Fenix A320 ã®èˆªæ³•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ TFDI MD-11 äº’æ›ã® JSON å½¢å¼ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚ŒãŸã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªèˆªç©ºèˆªæ³•ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€æœ€æ–°ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã‚’æ¡ç”¨ã—ã€åŠ¹ç‡çš„ã§ä¿¡é ¼æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

## ğŸ¯ è¨­è¨ˆåŸå‰‡

### 1. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æœ€å„ªå…ˆ
- **å³æ ¼ãªæ¤œè¨¼**: å¤šå±¤ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- **é–¢ä¿‚æ€§ã®ç¶­æŒ**: èˆªæ³•ãƒ‡ãƒ¼ã‚¿é–“ã®ä¾å­˜é–¢ä¿‚ã‚’ç¶­æŒã™ã‚‹
- **ç²¾åº¦ã®ä¿è¨¼**: åº§æ¨™ã¨è¨ˆç®—ã®é«˜ç²¾åº¦ã‚’ç¶­æŒã™ã‚‹
- **ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯**: å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ã®è«–ç†çš„ä¸€è²«æ€§ã‚’ç¢ºä¿ã™ã‚‹

### 2. æ€§èƒ½æœ€é©åŒ–æŒ‡å‘
- **SQLite ã®æœ€é©åŒ–**: WAL ãƒ¢ãƒ¼ãƒ‰ã¨æ€§èƒ½ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- **ãƒãƒƒãƒå‡¦ç†**: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®é«˜ã„ãƒãƒƒãƒå‡¦ç†æˆ¦ç•¥
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ **: ã‚¹ãƒãƒ¼ãƒˆãªãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨å†åˆ©ç”¨
- **åœ§ç¸®ã®æœ€é©åŒ–**: é«˜é€Ÿãª 7z åœ§ç¸®ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹æœ€å„ªå…ˆ
- **Rich CLI**: æœ€æ–°ã®ã‚«ãƒ©ãƒ¼ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: è©³ç´°ãªé€²æ—è¡¨ç¤ºã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
- **è¦ªåˆ‡ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨å›å¾©ææ¡ˆ
- **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³**: ç›´æ„Ÿçš„ãªæ“ä½œãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```mermaid
graph TB
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤] --> B[ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å±¤]
    B --> C[ãƒ‡ãƒ¼ã‚¿å‡¦ç†å±¤]
    C --> D[ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹å±¤]
    
    A --> A1[Rich CLI ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹]
    A --> A2[é€²æ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
    A --> A3[ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³]
    
    B --> B1[å¤‰æ›ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼]
    B --> B2[è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
    B --> B3[æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³]
    B --> B4[FAF ãƒ‡ã‚£ãƒ†ã‚¯ã‚¿ãƒ¼]
    
    C --> C1[SQLite ãƒ—ãƒ­ã‚»ãƒƒã‚µ]
    C --> C2[åº§æ¨™æ¨™æº–åŒ–å™¨]
    C --> C3[JSON ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼]
    C --> C4[åœ§ç¸®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
    
    D --> D1[Fenix ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹]
    D --> D2[JSON ãƒ•ã‚¡ã‚¤ãƒ«]
    D --> D3[7z åœ§ç¸®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸]
```

### ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

#### 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤ (UI Layer)
**å½¹å‰²**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹
```python
class RichInterface:
    """Rich CLI ç•Œé¢ç®¡ç†å™¨"""
    - progress_tracking: è¿›åº¦æ¡ç®¡ç†
    - status_display: çŠ¶æ€ä¿¡æ¯æ˜¾ç¤º
    - error_presentation: é”™è¯¯ä¿¡æ¯å±•ç¤º
    - user_input: ç”¨æˆ·è¾“å…¥å¤„ç†
```

#### 2. ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯å±¤ (Business Layer)
**å½¹å‰²**: ã‚³ã‚¢ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¨ãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡
```python
class FenixToTFDIConverter:
    """ä¸»è½¬æ¢å™¨ç±»"""
    - database_validation: æ•°æ®åº“éªŒè¯
    - conversion_orchestration: è½¬æ¢æµç¨‹ç¼–æ’
    - faf_detection: FAF ç‚¹æ£€æµ‹
    - data_normalization: æ•°æ®æ ‡å‡†åŒ–
```

#### 3. ãƒ‡ãƒ¼ã‚¿å‡¦ç†å±¤ (Data Layer)
**å½¹å‰²**: ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã¨å‡¦ç†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
```python
class DataProcessor:
    """æ•°æ®å¤„ç†æ ¸å¿ƒ"""
    - coordinate_precision: åæ ‡ç²¾åº¦å¤„ç†
    - column_standardization: åˆ—åæ ‡å‡†åŒ–
    - relationship_mapping: å…³ç³»æ˜ å°„
    - format_conversion: æ ¼å¼è½¬æ¢
```

#### 4. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹å±¤ (Storage Layer)
**å½¹å‰²**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ
```python
class StorageManager:
    """å­˜å‚¨ç®¡ç†å™¨"""
    - sqlite_optimization: SQLite æ€§èƒ½ä¼˜åŒ–
    - file_operations: æ–‡ä»¶è¯»å†™æ“ä½œ
    - compression_handling: å‹ç¼©æ–‡ä»¶å¤„ç†
    - backup_management: å¤‡ä»½ç®¡ç†
```

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
sequenceDiagram
    participant U as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant UI as UIå±¤
    participant BL as ãƒ“ã‚¸ãƒã‚¹å±¤
    participant DL as ãƒ‡ãƒ¼ã‚¿å±¤
    participant SL as ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å±¤
    
    U->>UI: å¤‰æ›é–‹å§‹
    UI->>BL: å¤‰æ›å™¨ã®åˆæœŸåŒ–
    BL->>SL: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼
    SL->>BL: æ¤œè¨¼çµæœã‚’è¿”å´
    BL->>DL: ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹
    
    loop å„ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        DL->>SL: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        DL->>DL: æ¨™æº–åŒ–å‡¦ç†
        DL->>DL: åº§æ¨™ç²¾åº¦ã®èª¿æ•´
        DL->>SL: JSONã¸ã®æ›¸ãè¾¼ã¿
        DL->>UI: é€²æ—ã®æ›´æ–°
    end
    
    DL->>BL: å‡¦ç†å®Œäº†
    BL->>SL: åœ§ç¸®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ä½œæˆ
    SL->>UI: çµæœã‚’è¿”å´
    UI->>U: å®Œäº†çŠ¶æ…‹ã®è¡¨ç¤º
```

### ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph LR
    A[Fenix SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹] --> B[ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå±¤]
    B --> C[æ¨™æº–åŒ–å±¤]
    C --> D[æ¤œè¨¼å±¤]
    D --> E[å¤‰æ›å±¤]
    E --> F[ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå±¤]
    F --> G[JSON ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ãƒƒãƒˆ]
    G --> H[åœ§ç¸®å±¤]
    H --> I[TFDI äº’æ›ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸]
```

## ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### ã‚³ã‚¢æŠ€è¡“

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | æŠ€è¡“é¸æŠ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¦ä»¶ | ç”¨é€” |
|------|----------|----------|------|
| **Python** | Python 3.8+ | â‰¥ 3.8.0 | ä¸»è¦ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª |
| **Rich** | Rich Library | â‰¥ 12.0.0 | CLI ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ç¾åŒ– |
| **SQLite3** | å†…è”µãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | Python å†…è”µ | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ |
| **Pandas** | DataFrame | â‰¥ 1.3.0 | ãƒ‡ãƒ¼ã‚¿å‡¦ç† |
| **JSON** | å†…è”µãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | Python å†…è”µ | ãƒ‡ãƒ¼ã‚¿ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º |
| **py7zr** | 7-Zip Python | â‰¥ 0.18.0 | åœ§ç¸®å‡¦ç† |

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹æ€§

#### 1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–è¨­è¨ˆ
```python
fenix_to_tfdi/
â”œâ”€â”€ core/                  # ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ converter.py       # ãƒ¡ã‚¤ãƒ³å¤‰æ›å™¨
â”‚   â”œâ”€â”€ validator.py       # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼
â”‚   â””â”€â”€ config.py         # è¨­å®šç®¡ç†
â”œâ”€â”€ data/                  # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
â”‚   â”œâ”€â”€ processor.py       # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µ
â”‚   â”œâ”€â”€ normalizer.py      # æ¨™æº–åŒ–ãƒ„ãƒ¼ãƒ«
â”‚   â””â”€â”€ serializer.py     # ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ„ãƒ¼ãƒ«
â”œâ”€â”€ ui/                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   â”œâ”€â”€ cli.py            # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   â””â”€â”€ progress.py       # é€²æ—ç®¡ç†
â””â”€â”€ utils/                 # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    â”œâ”€â”€ storage.py        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ„ãƒ¼ãƒ«
    â””â”€â”€ compression.py    # åœ§ç¸®ãƒ„ãƒ¼ãƒ«
```

#### 2. è¨­å®šé§†å‹•ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
```python
@dataclass
class ConverterConfig:
    """å¤‰æ›å™¨è¨­å®šã‚¯ãƒ©ã‚¹"""
    output_dir: str = "Primary"
    procedure_legs_dir: str = "Primary/ProcedureLegs"
    archive_name: str = "Primary.7z"
    coordinate_precision: int = 8
    vnav_threshold: float = 2.5
    
    # SQLite æœ€é©åŒ–è¨­å®š
    sqlite_pragmas: Dict[str, str] = field(default_factory=lambda: {
        "journal_mode": "WAL",
        "synchronous": "NORMAL",
        "cache_size": "10000",
        "temp_store": "MEMORY"
    })
```

## ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ¡ãƒ¢ãƒªç®¡ç†æˆ¦ç•¥

#### 1. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
```python
def process_large_table(table_name: str, batch_size: int = 1000):
    """å¤§è¦æ¨¡ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†"""
    offset = 0
    while True:
        query = f"""
        SELECT * FROM {table_name} 
        LIMIT {batch_size} OFFSET {offset}
        """
        
        batch = execute_query(query)
        if not batch:
            break
            
        process_batch(batch)
        offset += batch_size
```

#### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
```python
class WaypointCache:
    """ã‚¦ã‚§ã‚¤ãƒã‚¤ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†"""
    def __init__(self, max_size: int = 10000):
        self._cache: Dict[str, WaypointData] = {}
        self._max_size = max_size
        self._access_times: Dict[str, float] = {}
    
    def get_waypoint(self, waypoint_id: str) -> Optional[WaypointData]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¦ã‚§ã‚¤ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹"""
        if waypoint_id in self._cache:
            self._access_times[waypoint_id] = time.time()
            return self._cache[waypoint_id]
        return None
```

### ä¸¦è¡Œå‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### 1. ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰è¨­è¨ˆ
```python
class ConcurrentProcessor:
    """ä¸¦è¡Œãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def process_tables_parallel(self, tables: List[str]):
        """è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¸¦è¡Œå‡¦ç†ã™ã‚‹"""
        futures = []
        for table in tables:
            future = self.executor.submit(self.process_table, table)
            futures.append(future)
        
        # ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
        concurrent.futures.wait(futures)
```

#### 2. ãƒªã‚½ãƒ¼ã‚¹ãƒ—ãƒ¼ãƒ«ç®¡ç†
```python
class DatabaseConnectionPool:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«"""
    def __init__(self, db_path: str, pool_size: int = 5):
        self.db_path = db_path
        self.pool_size = pool_size
        self.connections: Queue = Queue(maxsize=pool_size)
        self._init_pool()
    
    def get_connection(self) -> sqlite3.Connection:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã™ã‚‹"""
        return self.connections.get()
    
    def return_connection(self, conn: sqlite3.Connection):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è¿”å´ã™ã‚‹"""
        self.connections.put(conn)
```

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ‡ãƒ¼ã‚¿ä¿è­·ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

#### 1. å…¥åŠ›æ¤œè¨¼
```python
class InputValidator:
    """å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼"""
    
    @staticmethod
    def validate_database_path(path: str) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æ¤œè¨¼ã™ã‚‹"""
        # ãƒ‘ã‚¹éæ­´æ”»æ’ƒã‚’ãƒã‚§ãƒƒã‚¯
        if ".." in path or path.startswith("/"):
            return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’æ¤œè¨¼ã™ã‚‹
        if not path.endswith(('.db', '.db3', '.sqlite')):
            return False
        
        return True
    
    @staticmethod  
    def validate_terminal_id(terminal_id: int) -> bool:
        """ç«¯æœ«IDã®ç¯„å›²ã‚’æ¤œè¨¼ã™ã‚‹"""
        return 1 <= terminal_id <= 999999
```

#### 2. ã‚¨ãƒ©ãƒ¼åˆ†é›¢
```python
class SafeConverter:
    """å®‰å…¨ãªå¤‰æ›å™¨"""
    
    def safe_convert_table(self, table_name: str) -> bool:
        """å®‰å…¨ãªãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›"""
        try:
            with self.create_transaction() as transaction:
                result = self.convert_table(table_name)
                transaction.commit()
                return result
        except DatabaseError as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            transaction.rollback()
            return False
        except Exception as e:
            self.logger.error(f"æœªçŸ¥ã®ã‚¨ãƒ©ãƒ¼: {e}")
            return False
```

## ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ

#### 1. å¤‰æ›å™¨ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
```python
class ConverterPlugin(ABC):
    """å¤‰æ›å™¨ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def get_name(self) -> str:
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åã‚’å–å¾—ã™ã‚‹"""
        pass
    
    @abstractmethod
    def get_supported_formats(self) -> List[str]:
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å½¢å¼ã‚’å–å¾—ã™ã‚‹"""
        pass
    
    @abstractmethod
    def convert_data(self, data: Any, config: ConverterConfig) -> Any:
        """ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã™ã‚‹"""
        pass
```

#### 2. å½¢å¼æ‹¡å¼µãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
```python
class FormatRegistry:
    """å½¢å¼ãƒ¬ã‚¸ã‚¹ãƒˆãƒª"""
    
    def __init__(self):
        self._converters: Dict[str, ConverterPlugin] = {}
    
    def register_converter(self, format_name: str, converter: ConverterPlugin):
        """å¤‰æ›å™¨ã‚’ç™»éŒ²ã™ã‚‹"""
        self._converters[format_name] = converter
    
    def get_converter(self, format_name: str) -> Optional[ConverterPlugin]:
        """å¤‰æ›å™¨ã‚’å–å¾—ã™ã‚‹"""
        return self._converters.get(format_name)
```

### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ‹¡å¼µ

#### 1. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æŠ½è±¡åŒ–
```python
class DataSource(ABC):
    """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def connect(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«æ¥ç¶šã™ã‚‹"""
        pass
    
    @abstractmethod
    def get_tables(self) -> List[str]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹"""
        pass
    
    @abstractmethod
    def query_data(self, query: str) -> Iterator[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹"""
        pass
```

## ğŸ”„ ä¿å®ˆæ€§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

#### 1. æ§‹é€ åŒ–ãƒ­ã‚°
```python
class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚¬ãƒ¼"""
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # Rich å½¢å¼åŒ–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        rich_handler = RichHandler(rich_tracebacks=True)
        rich_handler.setFormatter(
            logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
        )
        self.logger.addHandler(rich_handler)
    
    def log_conversion_start(self, table_name: str, record_count: int):
        """å¤‰æ›é–‹å§‹ã‚’è¨˜éŒ²ã™ã‚‹"""
        self.logger.info(
            f"é–‹å§‹å¤‰æ›è¡¨ {table_name}",
            extra={
                "table": table_name,
                "record_count": record_count,
                "operation": "conversion_start"
            }
        )
```

#### 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
```python
class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = defaultdict(list)
    
    @contextmanager
    def measure_time(self, operation: str):
        """æ“ä½œã«ã‹ã‹ã‚‹æ™‚é–“ã‚’è¨ˆæ¸¬ã™ã‚‹"""
        start_time = time.time()
        try:
            yield
        finally:
            elapsed = time.time() - start_time
            self.metrics[operation].append(elapsed)
            self.logger.debug(f"{operation} çµŒéæ™‚é–“: {elapsed:.2f}s")
```

## ğŸ“Š ãƒ†ã‚¹ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

#### 1. éšå±¤å‹ãƒ†ã‚¹ãƒˆ
```python
# å˜ä½“ãƒ†ã‚¹ãƒˆ
class TestDataProcessor(unittest.TestCase):
    def test_coordinate_normalization(self):
        """åº§æ¨™ã®æ¨™æº–åŒ–ã‚’ãƒ†ã‚¹ãƒˆ"""
        processor = DataProcessor()
        result = processor.normalize_coordinate(39.916667, 8)
        self.assertEqual(result, 39.91666700)

# çµ±åˆãƒ†ã‚¹ãƒˆ  
class TestConverterIntegration(unittest.TestCase):
    def test_full_conversion_pipeline(self):
        """å®Œå…¨ãªå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ãƒ†ã‚¹ãƒˆ"""
        converter = FenixToTFDIConverter(test_config)
        result = converter.convert(test_database_path)
        self.assertTrue(result)

# æ€§èƒ½ãƒ†ã‚¹ãƒˆ
class TestPerformance(unittest.TestCase):
    def test_large_database_conversion(self):
        """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¤‰æ›ã®æ€§èƒ½ã‚’ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        converter.convert(large_test_database)
        elapsed = time.time() - start_time
        self.assertLess(elapsed, 300)  # 5åˆ†ä»¥å†…ã«å®Œäº†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
```

---

ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã¯ã€TFDI èˆªæ³•ãƒ‡ãƒ¼ã‚¿å¤‰æ›å™¨ã®**ä¿¡é ¼æ€§**ã€**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**ã€**ä¿å®ˆæ€§**ã‚’ç¢ºä¿ã—ã€TFDI MD-11 ãƒ•ãƒ©ã‚¤ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚°ãƒ¬ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ğŸšâœ¨
